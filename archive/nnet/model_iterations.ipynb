{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# for data scaling and splitting\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for neural net\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# for evaluation\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score,\\\n",
    "    precision_score, f1_score, classification_report, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/combined_expression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th>classification</th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>TNMD</th>\n",
       "      <th>DPM1</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>C1orf112</th>\n",
       "      <th>FGR</th>\n",
       "      <th>CFH</th>\n",
       "      <th>FUCA2</th>\n",
       "      <th>...</th>\n",
       "      <th>COL15A1</th>\n",
       "      <th>C6orf10</th>\n",
       "      <th>TMEM225</th>\n",
       "      <th>NOTCH4</th>\n",
       "      <th>PBX2</th>\n",
       "      <th>AGER</th>\n",
       "      <th>RNF5</th>\n",
       "      <th>AGPAT1</th>\n",
       "      <th>DFNB59</th>\n",
       "      <th>PRRT1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240121</td>\n",
       "      <td>0</td>\n",
       "      <td>6.419526</td>\n",
       "      <td>3.182094</td>\n",
       "      <td>9.320548</td>\n",
       "      <td>3.759654</td>\n",
       "      <td>3.802619</td>\n",
       "      <td>3.215753</td>\n",
       "      <td>4.698729</td>\n",
       "      <td>7.873672</td>\n",
       "      <td>...</td>\n",
       "      <td>3.245454</td>\n",
       "      <td>2.953508</td>\n",
       "      <td>3.543429</td>\n",
       "      <td>3.352022</td>\n",
       "      <td>4.672310</td>\n",
       "      <td>3.641128</td>\n",
       "      <td>3.135310</td>\n",
       "      <td>3.737072</td>\n",
       "      <td>3.450927</td>\n",
       "      <td>3.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240122</td>\n",
       "      <td>1</td>\n",
       "      <td>7.646494</td>\n",
       "      <td>2.626819</td>\n",
       "      <td>10.153853</td>\n",
       "      <td>3.564755</td>\n",
       "      <td>3.942749</td>\n",
       "      <td>3.290760</td>\n",
       "      <td>3.551675</td>\n",
       "      <td>8.252413</td>\n",
       "      <td>...</td>\n",
       "      <td>2.786709</td>\n",
       "      <td>3.077382</td>\n",
       "      <td>3.728232</td>\n",
       "      <td>3.208882</td>\n",
       "      <td>4.586840</td>\n",
       "      <td>3.395654</td>\n",
       "      <td>3.586800</td>\n",
       "      <td>3.519128</td>\n",
       "      <td>3.115323</td>\n",
       "      <td>3.051645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240123</td>\n",
       "      <td>0</td>\n",
       "      <td>8.319417</td>\n",
       "      <td>3.111183</td>\n",
       "      <td>9.643558</td>\n",
       "      <td>4.757258</td>\n",
       "      <td>3.919757</td>\n",
       "      <td>3.602185</td>\n",
       "      <td>3.329644</td>\n",
       "      <td>9.076950</td>\n",
       "      <td>...</td>\n",
       "      <td>3.459089</td>\n",
       "      <td>3.085394</td>\n",
       "      <td>3.462811</td>\n",
       "      <td>3.339030</td>\n",
       "      <td>4.614897</td>\n",
       "      <td>3.395845</td>\n",
       "      <td>3.419193</td>\n",
       "      <td>3.971646</td>\n",
       "      <td>3.729310</td>\n",
       "      <td>3.320022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240124</td>\n",
       "      <td>0</td>\n",
       "      <td>9.006994</td>\n",
       "      <td>3.028173</td>\n",
       "      <td>9.686700</td>\n",
       "      <td>4.280504</td>\n",
       "      <td>3.147646</td>\n",
       "      <td>3.188881</td>\n",
       "      <td>3.293807</td>\n",
       "      <td>8.678790</td>\n",
       "      <td>...</td>\n",
       "      <td>2.835403</td>\n",
       "      <td>2.960303</td>\n",
       "      <td>3.415083</td>\n",
       "      <td>3.290171</td>\n",
       "      <td>4.770123</td>\n",
       "      <td>3.400821</td>\n",
       "      <td>3.383734</td>\n",
       "      <td>3.798107</td>\n",
       "      <td>2.822404</td>\n",
       "      <td>3.297547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240127</td>\n",
       "      <td>0</td>\n",
       "      <td>7.985676</td>\n",
       "      <td>2.694729</td>\n",
       "      <td>10.676134</td>\n",
       "      <td>4.159685</td>\n",
       "      <td>3.804637</td>\n",
       "      <td>3.481942</td>\n",
       "      <td>3.111261</td>\n",
       "      <td>7.555407</td>\n",
       "      <td>...</td>\n",
       "      <td>2.896523</td>\n",
       "      <td>2.849899</td>\n",
       "      <td>3.480114</td>\n",
       "      <td>3.226128</td>\n",
       "      <td>5.832710</td>\n",
       "      <td>3.612179</td>\n",
       "      <td>3.347095</td>\n",
       "      <td>4.457963</td>\n",
       "      <td>5.198524</td>\n",
       "      <td>4.553586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CELL_LINE_NAME  classification    TSPAN6      TNMD       DPM1     SCYL3  \\\n",
       "0         1240121               0  6.419526  3.182094   9.320548  3.759654   \n",
       "1         1240122               1  7.646494  2.626819  10.153853  3.564755   \n",
       "2         1240123               0  8.319417  3.111183   9.643558  4.757258   \n",
       "3         1240124               0  9.006994  3.028173   9.686700  4.280504   \n",
       "4         1240127               0  7.985676  2.694729  10.676134  4.159685   \n",
       "\n",
       "   C1orf112       FGR       CFH     FUCA2  ...   COL15A1   C6orf10   TMEM225  \\\n",
       "0  3.802619  3.215753  4.698729  7.873672  ...  3.245454  2.953508  3.543429   \n",
       "1  3.942749  3.290760  3.551675  8.252413  ...  2.786709  3.077382  3.728232   \n",
       "2  3.919757  3.602185  3.329644  9.076950  ...  3.459089  3.085394  3.462811   \n",
       "3  3.147646  3.188881  3.293807  8.678790  ...  2.835403  2.960303  3.415083   \n",
       "4  3.804637  3.481942  3.111261  7.555407  ...  2.896523  2.849899  3.480114   \n",
       "\n",
       "     NOTCH4      PBX2      AGER      RNF5    AGPAT1    DFNB59     PRRT1  \n",
       "0  3.352022  4.672310  3.641128  3.135310  3.737072  3.450927  3.168800  \n",
       "1  3.208882  4.586840  3.395654  3.586800  3.519128  3.115323  3.051645  \n",
       "2  3.339030  4.614897  3.395845  3.419193  3.971646  3.729310  3.320022  \n",
       "3  3.290171  4.770123  3.400821  3.383734  3.798107  2.822404  3.297547  \n",
       "4  3.226128  5.832710  3.612179  3.347095  4.457963  5.198524  4.553586  \n",
       "\n",
       "[5 rows x 16383 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['classification'].replace({1: 0, 2: 1}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes = pd.read_csv('cleaned/boruta-99-25-0.01.csv')\n",
    "selected_genes = selected_genes.values.tolist()\n",
    "selected_genes = list(itertools.chain(*selected_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving proper columns\n",
    "X = data.loc[:, selected_genes].values\n",
    "y = data['classification'].values\n",
    "# scaling the data\n",
    "scalar = MinMaxScaler()\n",
    "x_scaled = scalar.fit_transform(X)\n",
    "# splitting data (20% test, 80% train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch for Input and Output Layer (One Hidden Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Epochs and Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    # adding layers\n",
    "    model.add(Dense(len(selected_genes), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "513/513 [==============================] - 1s 1ms/step - loss: 0.7319 - accuracy: 0.6355\n",
      "Epoch 2/100\n",
      "513/513 [==============================] - 0s 296us/step - loss: 0.5888 - accuracy: 0.7057\n",
      "Epoch 3/100\n",
      "513/513 [==============================] - 0s 286us/step - loss: 0.5316 - accuracy: 0.7329\n",
      "Epoch 4/100\n",
      "513/513 [==============================] - 0s 283us/step - loss: 0.5268 - accuracy: 0.7310\n",
      "Epoch 5/100\n",
      "513/513 [==============================] - 0s 284us/step - loss: 0.5331 - accuracy: 0.7524\n",
      "Epoch 6/100\n",
      "513/513 [==============================] - 0s 277us/step - loss: 0.5150 - accuracy: 0.7505\n",
      "Epoch 7/100\n",
      "513/513 [==============================] - 0s 274us/step - loss: 0.5088 - accuracy: 0.7602\n",
      "Epoch 8/100\n",
      "513/513 [==============================] - 0s 277us/step - loss: 0.5125 - accuracy: 0.7446\n",
      "Epoch 9/100\n",
      "513/513 [==============================] - 0s 280us/step - loss: 0.4885 - accuracy: 0.7622\n",
      "Epoch 10/100\n",
      "513/513 [==============================] - 0s 275us/step - loss: 0.5032 - accuracy: 0.7739\n",
      "Epoch 11/100\n",
      "513/513 [==============================] - 0s 270us/step - loss: 0.4854 - accuracy: 0.7739\n",
      "Epoch 12/100\n",
      "513/513 [==============================] - 0s 274us/step - loss: 0.4901 - accuracy: 0.7758\n",
      "Epoch 13/100\n",
      "513/513 [==============================] - 0s 282us/step - loss: 0.4759 - accuracy: 0.7817\n",
      "Epoch 14/100\n",
      "513/513 [==============================] - 0s 281us/step - loss: 0.4745 - accuracy: 0.7817\n",
      "Epoch 15/100\n",
      "513/513 [==============================] - 0s 278us/step - loss: 0.4633 - accuracy: 0.7856\n",
      "Epoch 16/100\n",
      "513/513 [==============================] - 0s 277us/step - loss: 0.4584 - accuracy: 0.7973\n",
      "Epoch 17/100\n",
      "513/513 [==============================] - 0s 278us/step - loss: 0.4541 - accuracy: 0.8129\n",
      "Epoch 18/100\n",
      "513/513 [==============================] - 0s 290us/step - loss: 0.4677 - accuracy: 0.7797\n",
      "Epoch 19/100\n",
      "513/513 [==============================] - 0s 289us/step - loss: 0.4463 - accuracy: 0.7953\n",
      "Epoch 20/100\n",
      "513/513 [==============================] - 0s 302us/step - loss: 0.4478 - accuracy: 0.7953\n",
      "Epoch 21/100\n",
      "513/513 [==============================] - 0s 294us/step - loss: 0.4471 - accuracy: 0.8051\n",
      "Epoch 22/100\n",
      "513/513 [==============================] - 0s 290us/step - loss: 0.4469 - accuracy: 0.7973\n",
      "Epoch 23/100\n",
      "513/513 [==============================] - 0s 301us/step - loss: 0.4445 - accuracy: 0.8031\n",
      "Epoch 24/100\n",
      "513/513 [==============================] - 0s 295us/step - loss: 0.4388 - accuracy: 0.8031\n",
      "Epoch 25/100\n",
      "513/513 [==============================] - 0s 294us/step - loss: 0.4438 - accuracy: 0.8051\n",
      "Epoch 26/100\n",
      "513/513 [==============================] - 0s 304us/step - loss: 0.4342 - accuracy: 0.8070\n",
      "Epoch 27/100\n",
      "513/513 [==============================] - 0s 314us/step - loss: 0.4517 - accuracy: 0.7973\n",
      "Epoch 28/100\n",
      "513/513 [==============================] - 0s 304us/step - loss: 0.4186 - accuracy: 0.8246\n",
      "Epoch 29/100\n",
      "513/513 [==============================] - 0s 294us/step - loss: 0.4290 - accuracy: 0.8070\n",
      "Epoch 30/100\n",
      "513/513 [==============================] - 0s 314us/step - loss: 0.4349 - accuracy: 0.8109\n",
      "Epoch 31/100\n",
      "513/513 [==============================] - 0s 311us/step - loss: 0.4265 - accuracy: 0.8031\n",
      "Epoch 32/100\n",
      "513/513 [==============================] - 0s 310us/step - loss: 0.4151 - accuracy: 0.8246\n",
      "Epoch 33/100\n",
      "513/513 [==============================] - 0s 312us/step - loss: 0.4235 - accuracy: 0.8148\n",
      "Epoch 34/100\n",
      "513/513 [==============================] - 0s 308us/step - loss: 0.4100 - accuracy: 0.8343\n",
      "Epoch 35/100\n",
      "513/513 [==============================] - 0s 304us/step - loss: 0.4092 - accuracy: 0.8304\n",
      "Epoch 36/100\n",
      "513/513 [==============================] - 0s 310us/step - loss: 0.4102 - accuracy: 0.8109\n",
      "Epoch 37/100\n",
      "513/513 [==============================] - 0s 318us/step - loss: 0.4035 - accuracy: 0.8265\n",
      "Epoch 38/100\n",
      "513/513 [==============================] - 0s 313us/step - loss: 0.4031 - accuracy: 0.8343\n",
      "Epoch 39/100\n",
      "513/513 [==============================] - 0s 332us/step - loss: 0.4025 - accuracy: 0.8265\n",
      "Epoch 40/100\n",
      "513/513 [==============================] - 0s 322us/step - loss: 0.4023 - accuracy: 0.8304\n",
      "Epoch 41/100\n",
      "513/513 [==============================] - 0s 326us/step - loss: 0.3922 - accuracy: 0.8480\n",
      "Epoch 42/100\n",
      "513/513 [==============================] - 0s 334us/step - loss: 0.3923 - accuracy: 0.8382\n",
      "Epoch 43/100\n",
      "513/513 [==============================] - 0s 334us/step - loss: 0.3924 - accuracy: 0.8343\n",
      "Epoch 44/100\n",
      "513/513 [==============================] - 0s 341us/step - loss: 0.3906 - accuracy: 0.8324\n",
      "Epoch 45/100\n",
      "513/513 [==============================] - 0s 348us/step - loss: 0.3975 - accuracy: 0.8343\n",
      "Epoch 46/100\n",
      "513/513 [==============================] - 0s 347us/step - loss: 0.3896 - accuracy: 0.8382\n",
      "Epoch 47/100\n",
      "513/513 [==============================] - 0s 361us/step - loss: 0.3813 - accuracy: 0.8304\n",
      "Epoch 48/100\n",
      "513/513 [==============================] - 0s 362us/step - loss: 0.3836 - accuracy: 0.8421\n",
      "Epoch 49/100\n",
      "513/513 [==============================] - 0s 361us/step - loss: 0.3781 - accuracy: 0.8363\n",
      "Epoch 50/100\n",
      "513/513 [==============================] - 0s 354us/step - loss: 0.3842 - accuracy: 0.8402\n",
      "Epoch 51/100\n",
      "513/513 [==============================] - 0s 350us/step - loss: 0.3722 - accuracy: 0.8519\n",
      "Epoch 52/100\n",
      "513/513 [==============================] - 0s 350us/step - loss: 0.3706 - accuracy: 0.8499\n",
      "Epoch 53/100\n",
      "513/513 [==============================] - 0s 344us/step - loss: 0.3767 - accuracy: 0.8382\n",
      "Epoch 54/100\n",
      "513/513 [==============================] - 0s 346us/step - loss: 0.3665 - accuracy: 0.8460\n",
      "Epoch 55/100\n",
      "513/513 [==============================] - 0s 344us/step - loss: 0.3727 - accuracy: 0.8480\n",
      "Epoch 56/100\n",
      "513/513 [==============================] - 0s 361us/step - loss: 0.3593 - accuracy: 0.8441\n",
      "Epoch 57/100\n",
      "513/513 [==============================] - 0s 358us/step - loss: 0.3675 - accuracy: 0.8441\n",
      "Epoch 58/100\n",
      "513/513 [==============================] - 0s 355us/step - loss: 0.3591 - accuracy: 0.8499\n",
      "Epoch 59/100\n",
      "513/513 [==============================] - 0s 352us/step - loss: 0.3538 - accuracy: 0.8480\n",
      "Epoch 60/100\n",
      "513/513 [==============================] - 0s 350us/step - loss: 0.3539 - accuracy: 0.8519\n",
      "Epoch 61/100\n",
      "513/513 [==============================] - 0s 343us/step - loss: 0.3552 - accuracy: 0.8519\n",
      "Epoch 62/100\n",
      "513/513 [==============================] - 0s 359us/step - loss: 0.3615 - accuracy: 0.8538\n",
      "Epoch 63/100\n",
      "513/513 [==============================] - 0s 368us/step - loss: 0.3553 - accuracy: 0.8519\n",
      "Epoch 64/100\n",
      "513/513 [==============================] - 0s 657us/step - loss: 0.3546 - accuracy: 0.8674\n",
      "Epoch 65/100\n",
      "513/513 [==============================] - 0s 377us/step - loss: 0.3517 - accuracy: 0.8499\n",
      "Epoch 66/100\n",
      "513/513 [==============================] - 0s 390us/step - loss: 0.3460 - accuracy: 0.8655\n",
      "Epoch 67/100\n",
      "513/513 [==============================] - 0s 429us/step - loss: 0.3576 - accuracy: 0.8596\n",
      "Epoch 68/100\n",
      "513/513 [==============================] - 0s 462us/step - loss: 0.3497 - accuracy: 0.8441\n",
      "Epoch 69/100\n",
      "513/513 [==============================] - 0s 833us/step - loss: 0.3417 - accuracy: 0.8558\n",
      "Epoch 70/100\n",
      "513/513 [==============================] - 0s 516us/step - loss: 0.3412 - accuracy: 0.8558\n",
      "Epoch 71/100\n",
      "513/513 [==============================] - 0s 487us/step - loss: 0.3416 - accuracy: 0.8499\n",
      "Epoch 72/100\n",
      "513/513 [==============================] - 0s 477us/step - loss: 0.3447 - accuracy: 0.8635\n",
      "Epoch 73/100\n",
      "513/513 [==============================] - 0s 806us/step - loss: 0.3348 - accuracy: 0.8616\n",
      "Epoch 74/100\n",
      "513/513 [==============================] - 0s 478us/step - loss: 0.3300 - accuracy: 0.8655\n",
      "Epoch 75/100\n",
      "513/513 [==============================] - 0s 468us/step - loss: 0.3329 - accuracy: 0.8616\n",
      "Epoch 76/100\n",
      "513/513 [==============================] - 0s 485us/step - loss: 0.3304 - accuracy: 0.8694\n",
      "Epoch 77/100\n",
      "513/513 [==============================] - 0s 778us/step - loss: 0.3333 - accuracy: 0.8538\n",
      "Epoch 78/100\n",
      "513/513 [==============================] - 0s 483us/step - loss: 0.3264 - accuracy: 0.8616\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513/513 [==============================] - 0s 478us/step - loss: 0.3240 - accuracy: 0.8616\n",
      "Epoch 80/100\n",
      "513/513 [==============================] - 0s 482us/step - loss: 0.3228 - accuracy: 0.8674\n",
      "Epoch 81/100\n",
      "513/513 [==============================] - 0s 765us/step - loss: 0.3262 - accuracy: 0.8635\n",
      "Epoch 82/100\n",
      "513/513 [==============================] - 0s 498us/step - loss: 0.3298 - accuracy: 0.8577\n",
      "Epoch 83/100\n",
      "513/513 [==============================] - 0s 489us/step - loss: 0.3194 - accuracy: 0.8713\n",
      "Epoch 84/100\n",
      "513/513 [==============================] - 0s 498us/step - loss: 0.3298 - accuracy: 0.8499\n",
      "Epoch 85/100\n",
      "513/513 [==============================] - 0s 726us/step - loss: 0.3247 - accuracy: 0.8655\n",
      "Epoch 86/100\n",
      "513/513 [==============================] - 0s 541us/step - loss: 0.3127 - accuracy: 0.8869\n",
      "Epoch 87/100\n",
      "513/513 [==============================] - 0s 488us/step - loss: 0.3203 - accuracy: 0.8713\n",
      "Epoch 88/100\n",
      "513/513 [==============================] - 0s 502us/step - loss: 0.3161 - accuracy: 0.8713\n",
      "Epoch 89/100\n",
      "513/513 [==============================] - 0s 858us/step - loss: 0.3136 - accuracy: 0.8635\n",
      "Epoch 90/100\n",
      "513/513 [==============================] - 0s 571us/step - loss: 0.3076 - accuracy: 0.8713\n",
      "Epoch 91/100\n",
      "513/513 [==============================] - 0s 455us/step - loss: 0.3155 - accuracy: 0.8674\n",
      "Epoch 92/100\n",
      "513/513 [==============================] - 0s 405us/step - loss: 0.3037 - accuracy: 0.8752\n",
      "Epoch 93/100\n",
      "513/513 [==============================] - 0s 419us/step - loss: 0.3077 - accuracy: 0.8791\n",
      "Epoch 94/100\n",
      "513/513 [==============================] - 0s 403us/step - loss: 0.3039 - accuracy: 0.8967\n",
      "Epoch 95/100\n",
      "513/513 [==============================] - 0s 371us/step - loss: 0.3057 - accuracy: 0.8713\n",
      "Epoch 96/100\n",
      "513/513 [==============================] - 0s 377us/step - loss: 0.2955 - accuracy: 0.8869\n",
      "Epoch 97/100\n",
      "513/513 [==============================] - 0s 374us/step - loss: 0.2977 - accuracy: 0.8811\n",
      "Epoch 98/100\n",
      "513/513 [==============================] - 0s 363us/step - loss: 0.3002 - accuracy: 0.8772\n",
      "Epoch 99/100\n",
      "513/513 [==============================] - 0s 382us/step - loss: 0.2967 - accuracy: 0.8908\n",
      "Epoch 100/100\n",
      "513/513 [==============================] - 0s 385us/step - loss: 0.2981 - accuracy: 0.8811\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "epochs = [25, 50, 100, 150]\n",
    "batches = [16, 32, 64, 128]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(epochs=epochs, batch_size=batches, optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.750447 using {'batch_size': 16, 'epochs': 100, 'optimizer': 'Adagrad'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 4.85296779,  6.52042532,  5.42756615,  7.90591793,  7.65490971,\n",
       "         6.5323441 , 10.20223951,  9.02838345, 11.49187579, 11.39599109,\n",
       "        16.3142252 , 15.2733242 , 12.79265385, 16.83567848, 14.19800825,\n",
       "        20.1476685 , 18.51353359, 26.92441974, 24.93766327, 21.72245255,\n",
       "        25.36375413, 28.83345923, 40.76835079, 39.61854196, 49.98053532,\n",
       "        47.14785657, 39.16147728, 40.27613959,  4.9513906 ,  7.64798994,\n",
       "        10.64718614, 15.52412639,  9.20608892,  6.55431342,  9.22079315,\n",
       "         5.7566752 ,  8.59237552,  8.14730349,  9.68278985,  9.06749988,\n",
       "         7.81920104, 10.9454742 ,  9.5213398 , 13.33332181, 12.17125192,\n",
       "        15.05213199, 16.2689734 , 13.46293483, 17.90104504, 18.81385846,\n",
       "        22.59538598, 23.9940237 , 29.11310315, 27.94198818, 24.56344566,\n",
       "        24.18605661,  4.67051854,  6.53351436,  6.07374573,  8.62956052,\n",
       "         7.82396755,  6.02028341,  8.17353101,  5.69714479,  6.8679997 ,\n",
       "         6.04347858,  7.84312382,  7.37079048,  6.10352998,  7.68512664,\n",
       "         5.56057215,  7.42930923,  6.91750183, 10.80954471, 10.53116765,\n",
       "         8.50402994, 11.84190559,  9.78566761, 13.84872222, 14.46122379,\n",
       "        18.4550179 , 19.78879056, 17.02479362, 14.58076415,  3.76467581,\n",
       "         5.23122787,  5.42657971,  5.81527724,  5.36952848,  4.59835525,\n",
       "         6.37665348,  4.06559048,  5.13275261,  4.75068493,  6.25925403,\n",
       "         6.26426868,  5.33049316,  7.31171269,  5.3534564 ,  6.29090581,\n",
       "         5.61163144,  7.21399903,  7.06477237,  6.48075409,  8.72889533,\n",
       "         8.21597705,  9.02288566,  8.8380733 , 21.53817782, 23.12776971,\n",
       "        16.95714993,  8.46641583]),\n",
       " 'std_fit_time': array([0.10519399, 0.09458715, 0.36437813, 0.17509238, 0.08930392,\n",
       "        0.26786439, 0.11694287, 0.46101463, 0.58019015, 0.59170244,\n",
       "        0.35464253, 0.13576137, 1.62575837, 0.12889697, 2.24286197,\n",
       "        1.56222516, 0.46174978, 1.38478968, 1.17909646, 2.38359492,\n",
       "        0.23962393, 0.7918569 , 0.50733487, 0.13741913, 1.35888503,\n",
       "        0.4320295 , 5.03958572, 0.30817068, 0.72006403, 0.36152372,\n",
       "        2.52812685, 1.93677202, 1.0160195 , 0.46632   , 0.14502254,\n",
       "        0.3989207 , 0.18777091, 0.19451138, 0.27232107, 0.110176  ,\n",
       "        0.1555286 , 0.12309712, 0.29188303, 0.23759621, 0.07167605,\n",
       "        1.25853082, 0.24577564, 0.97687162, 0.7241261 , 0.14338179,\n",
       "        1.42415939, 0.41389042, 0.39974693, 0.3568421 , 1.29762561,\n",
       "        1.30948788, 0.12745475, 0.37164888, 0.17699594, 0.1448095 ,\n",
       "        0.6111957 , 0.48794064, 0.43300353, 0.43078364, 0.43970026,\n",
       "        0.24674846, 0.34571672, 0.25636168, 0.51979006, 0.14346818,\n",
       "        0.27648091, 0.16616806, 0.27325349, 0.75676836, 0.20025271,\n",
       "        1.14665475, 0.32704672, 0.60616587, 1.44205428, 0.34760891,\n",
       "        1.31169209, 0.3965201 , 1.71306383, 0.65700403, 0.02846323,\n",
       "        0.37691708, 0.3532463 , 0.23657692, 0.09860541, 0.13335724,\n",
       "        0.10774415, 0.02108185, 0.0597668 , 0.09944014, 0.08721664,\n",
       "        0.21446799, 0.15259298, 0.04422487, 0.08290977, 0.21750881,\n",
       "        0.10276448, 0.14101577, 0.12846719, 0.16245251, 0.19107449,\n",
       "        0.18891215, 0.39379866, 0.10576588, 2.51521212, 0.36815328,\n",
       "        3.54021189, 1.81200384]),\n",
       " 'mean_score_time': array([1.07313519, 0.56893883, 0.7471046 , 0.77306685, 0.69498868,\n",
       "        1.03978214, 0.76081381, 0.80560637, 0.98650241, 0.91005626,\n",
       "        2.07502794, 1.42979321, 1.33114314, 0.83303361, 2.71599717,\n",
       "        1.91861935, 0.85089526, 1.88480043, 1.04870853, 1.22956071,\n",
       "        0.99612389, 0.89692879, 1.00218639, 0.90244536, 1.33315973,\n",
       "        0.96506505, 1.63430319, 1.3056056 , 1.04335299, 1.78991122,\n",
       "        3.42492132, 0.92500472, 0.75545011, 0.89366102, 0.86087327,\n",
       "        1.15170355, 0.74806037, 0.73854284, 0.77152667, 0.75722003,\n",
       "        0.78326492, 0.87111673, 1.06661882, 0.88680644, 0.88839784,\n",
       "        1.00390449, 0.91083307, 0.89810338, 1.01689858, 0.77683582,\n",
       "        1.20548453, 1.1162611 , 1.05802965, 1.02830977, 0.82095761,\n",
       "        0.93324995, 0.85864787, 1.12809682, 1.06394563, 0.86254392,\n",
       "        0.72002764, 0.76708121, 0.67355819, 0.74058795, 0.93713799,\n",
       "        0.70063162, 0.83190479, 0.75122752, 0.68600159, 0.7113543 ,\n",
       "        0.91891503, 0.75036016, 0.68318324, 0.80293531, 0.84094911,\n",
       "        0.77774248, 0.76217256, 0.90604839, 0.89417458, 0.85797038,\n",
       "        0.98632264, 0.94585085, 0.80663791, 0.68589759, 0.71283832,\n",
       "        0.94936852, 0.84332328, 0.70168037, 0.70172033, 0.68382678,\n",
       "        0.6984951 , 0.69194708, 0.73643966, 0.69955893, 0.73315687,\n",
       "        0.69039884, 0.68958607, 0.72264233, 0.91543765, 0.6797533 ,\n",
       "        0.71933331, 0.68007669, 0.76434317, 0.67363815, 0.68895154,\n",
       "        0.81107616, 0.72750359, 0.84902916, 1.24714622, 0.94414158,\n",
       "        0.87016945, 0.26235809]),\n",
       " 'std_score_time': array([0.04337567, 0.00821548, 0.02314734, 0.14204961, 0.07605603,\n",
       "        0.17182154, 0.07097999, 0.06511501, 0.30066169, 0.08048733,\n",
       "        0.7060259 , 0.24249971, 0.55866816, 0.15222644, 1.14821466,\n",
       "        0.99892209, 0.23843183, 1.90601549, 0.50851013, 0.3277346 ,\n",
       "        0.10157877, 0.138737  , 0.1654165 , 0.08651319, 0.35884189,\n",
       "        0.15791946, 1.27637489, 0.16867702, 0.34645918, 1.03008323,\n",
       "        0.19219481, 0.1042783 , 0.10331417, 0.06622765, 0.12408105,\n",
       "        0.06779487, 0.05275237, 0.06000774, 0.07090525, 0.03579854,\n",
       "        0.07753336, 0.10016574, 0.124075  , 0.16805082, 0.09950803,\n",
       "        0.15008728, 0.12993855, 0.2397831 , 0.1124747 , 0.05611913,\n",
       "        0.29189771, 0.13750682, 0.11437666, 0.02589058, 0.07840952,\n",
       "        0.1016001 , 0.06995197, 0.11127375, 0.20959709, 0.06830297,\n",
       "        0.12833792, 0.09834126, 0.02747277, 0.02306943, 0.12895174,\n",
       "        0.10172568, 0.09310458, 0.09932389, 0.04492597, 0.11865822,\n",
       "        0.13694769, 0.06304683, 0.05262362, 0.1133826 , 0.10113211,\n",
       "        0.16960077, 0.12533284, 0.12032459, 0.18313002, 0.13483647,\n",
       "        0.24764456, 0.10733232, 0.18081703, 0.1125637 , 0.02510239,\n",
       "        0.04160903, 0.1213083 , 0.02496974, 0.01601666, 0.05755489,\n",
       "        0.04237507, 0.04900334, 0.05913759, 0.03353226, 0.09414228,\n",
       "        0.02193808, 0.09782376, 0.16626552, 0.14832977, 0.06762049,\n",
       "        0.06209993, 0.15082091, 0.03553207, 0.10258994, 0.14952684,\n",
       "        0.12438861, 0.14356861, 0.12574855, 0.22777417, 0.10317728,\n",
       "        0.44772048, 0.04870528]),\n",
       " 'param_batch_size': masked_array(data=[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "                    128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "                    128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "                    128, 128, 128, 128, 128, 128],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25,\n",
       "                    25, 25, 25, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 10, 10, 10, 10, 10, 10, 10, 25, 25,\n",
       "                    25, 25, 25, 25, 25, 50, 50, 50, 50, 50, 50, 50, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 25, 25, 25, 25, 25, 25, 25, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_optimizer': masked_array(data=['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam',\n",
       "                    'Adamax', 'Nadam', 'SGD', 'RMSprop', 'Adagrad',\n",
       "                    'Adadelta', 'Adam', 'Adamax', 'Nadam', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax',\n",
       "                    'Nadam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta',\n",
       "                    'Adam', 'Adamax', 'Nadam', 'SGD', 'RMSprop', 'Adagrad',\n",
       "                    'Adadelta', 'Adam', 'Adamax', 'Nadam', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax',\n",
       "                    'Nadam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta',\n",
       "                    'Adam', 'Adamax', 'Nadam', 'SGD', 'RMSprop', 'Adagrad',\n",
       "                    'Adadelta', 'Adam', 'Adamax', 'Nadam', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax',\n",
       "                    'Nadam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta',\n",
       "                    'Adam', 'Adamax', 'Nadam', 'SGD', 'RMSprop', 'Adagrad',\n",
       "                    'Adadelta', 'Adam', 'Adamax', 'Nadam', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax',\n",
       "                    'Nadam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta',\n",
       "                    'Adam', 'Adamax', 'Nadam', 'SGD', 'RMSprop', 'Adagrad',\n",
       "                    'Adadelta', 'Adam', 'Adamax', 'Nadam', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax',\n",
       "                    'Nadam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta',\n",
       "                    'Adam', 'Adamax', 'Nadam'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'batch_size': 16, 'epochs': 10, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'Nadam'}],\n",
       " 'split0_test_score': array([0.71844661, 0.66990292, 0.73786408, 0.74757284, 0.68932039,\n",
       "        0.78640777, 0.78640777, 0.78640777, 0.71844661, 0.80582523,\n",
       "        0.71844661, 0.77669901, 0.77669901, 0.7669903 , 0.74757284,\n",
       "        0.73786408, 0.7669903 , 0.80582523, 0.73786408, 0.73786408,\n",
       "        0.72815531, 0.7669903 , 0.75728154, 0.75728154, 0.75728154,\n",
       "        0.7669903 , 0.74757284, 0.75728154, 0.69902915, 0.74757284,\n",
       "        0.71844661, 0.77669901, 0.75728154, 0.74757284, 0.78640777,\n",
       "        0.69902915, 0.67961162, 0.73786408, 0.77669901, 0.73786408,\n",
       "        0.78640777, 0.73786408, 0.77669901, 0.77669901, 0.77669901,\n",
       "        0.60194176, 0.74757284, 0.73786408, 0.73786408, 0.77669901,\n",
       "        0.75728154, 0.77669901, 0.7669903 , 0.74757284, 0.75728154,\n",
       "        0.73786408, 0.68932039, 0.77669901, 0.69902915, 0.74757284,\n",
       "        0.77669901, 0.79611653, 0.75728154, 0.67961162, 0.68932039,\n",
       "        0.75728154, 0.62135923, 0.77669901, 0.74757284, 0.69902915,\n",
       "        0.73786408, 0.77669901, 0.73786408, 0.66990292, 0.78640777,\n",
       "        0.75728154, 0.77669901, 0.75728154, 0.72815531, 0.74757284,\n",
       "        0.71844661, 0.78640777, 0.75728154, 0.73786408, 0.68932039,\n",
       "        0.43689319, 0.7669903 , 0.75728154, 0.7669903 , 0.74757284,\n",
       "        0.36893204, 0.68932039, 0.72815531, 0.75728154, 0.77669901,\n",
       "        0.7669903 , 0.7669903 , 0.67961162, 0.73786408, 0.71844661,\n",
       "        0.75728154, 0.74757284, 0.75728154, 0.74757284, 0.75728154,\n",
       "        0.73786408, 0.67961162, 0.7669903 , 0.7669903 , 0.73786408,\n",
       "        0.78640777, 0.72815531]),\n",
       " 'split1_test_score': array([0.68932039, 0.72815531, 0.72815531, 0.72815531, 0.73786408,\n",
       "        0.72815531, 0.49514562, 0.69902915, 0.71844661, 0.71844661,\n",
       "        0.70873785, 0.73786408, 0.69902915, 0.75728154, 0.65048546,\n",
       "        0.7669903 , 0.74757284, 0.69902915, 0.75728154, 0.75728154,\n",
       "        0.73786408, 0.71844661, 0.72815531, 0.77669901, 0.74757284,\n",
       "        0.7669903 , 0.7669903 , 0.75728154, 0.66019416, 0.69902915,\n",
       "        0.67961162, 0.73786408, 0.72815531, 0.71844661, 0.69902915,\n",
       "        0.70873785, 0.71844661, 0.71844661, 0.70873785, 0.62135923,\n",
       "        0.71844661, 0.71844661, 0.72815531, 0.72815531, 0.71844661,\n",
       "        0.72815531, 0.75728154, 0.73786408, 0.75728154, 0.71844661,\n",
       "        0.73786408, 0.75728154, 0.70873785, 0.73786408, 0.78640777,\n",
       "        0.73786408, 0.64077669, 0.69902915, 0.69902915, 0.70873785,\n",
       "        0.71844661, 0.69902915, 0.70873785, 0.66990292, 0.70873785,\n",
       "        0.72815531, 0.69902915, 0.71844661, 0.70873785, 0.71844661,\n",
       "        0.68932039, 0.71844661, 0.71844661, 0.71844661, 0.73786408,\n",
       "        0.7669903 , 0.71844661, 0.72815531, 0.71844661, 0.72815531,\n",
       "        0.53398061, 0.77669901, 0.74757284, 0.71844661, 0.64077669,\n",
       "        0.60194176, 0.66019416, 0.67961162, 0.69902915, 0.70873785,\n",
       "        0.68932039, 0.64077669, 0.71844661, 0.71844661, 0.72815531,\n",
       "        0.70873785, 0.69902915, 0.5825243 , 0.64077669, 0.71844661,\n",
       "        0.68932039, 0.72815531, 0.71844661, 0.73786408, 0.68932039,\n",
       "        0.71844661, 0.69902915, 0.68932039, 0.57281554, 0.7669903 ,\n",
       "        0.74757284, 0.73786408]),\n",
       " 'split2_test_score': array([0.68932039, 0.69902915, 0.65048546, 0.65048546, 0.77669901,\n",
       "        0.77669901, 0.74757284, 0.71844661, 0.77669901, 0.71844661,\n",
       "        0.75728154, 0.78640777, 0.75728154, 0.67961162, 0.70873785,\n",
       "        0.66990292, 0.77669901, 0.72815531, 0.70873785, 0.75728154,\n",
       "        0.68932039, 0.73786408, 0.72815531, 0.73786408, 0.74757284,\n",
       "        0.65048546, 0.71844661, 0.71844661, 0.64077669, 0.73786408,\n",
       "        0.71844661, 0.73786408, 0.69902915, 0.73786408, 0.71844661,\n",
       "        0.68932039, 0.73786408, 0.77669901, 0.67961162, 0.7669903 ,\n",
       "        0.75728154, 0.72815531, 0.69902915, 0.7669903 , 0.77669901,\n",
       "        0.66990292, 0.71844661, 0.72815531, 0.75728154, 0.7669903 ,\n",
       "        0.65048546, 0.75728154, 0.72815531, 0.72815531, 0.71844661,\n",
       "        0.68932039, 0.63106793, 0.70873785, 0.69902915, 0.64077669,\n",
       "        0.73786408, 0.74757284, 0.66019416, 0.64077669, 0.65048546,\n",
       "        0.74757284, 0.63106793, 0.73786408, 0.77669901, 0.72815531,\n",
       "        0.66990292, 0.77669901, 0.66990292, 0.63106793, 0.71844661,\n",
       "        0.72815531, 0.64077669, 0.70873785, 0.74757284, 0.75728154,\n",
       "        0.75728154, 0.72815531, 0.73786408, 0.74757284, 0.63106793,\n",
       "        0.68932039, 0.66019416, 0.67961162, 0.73786408, 0.73786408,\n",
       "        0.66019416, 0.63106793, 0.60194176, 0.74757284, 0.73786408,\n",
       "        0.7669903 , 0.75728154, 0.75728154, 0.64077669, 0.71844661,\n",
       "        0.77669901, 0.70873785, 0.75728154, 0.73786408, 0.70873785,\n",
       "        0.68932039, 0.64077669, 0.73786408, 0.55339807, 0.71844661,\n",
       "        0.74757284, 0.70873785]),\n",
       " 'split3_test_score': array([0.67647058, 0.7647059 , 0.7352941 , 0.55882353, 0.78431374,\n",
       "        0.77450979, 0.72549021, 0.71568626, 0.77450979, 0.79411763,\n",
       "        0.64705884, 0.78431374, 0.77450979, 0.7352941 , 0.78431374,\n",
       "        0.7647059 , 0.77450979, 0.74509805, 0.74509805, 0.7647059 ,\n",
       "        0.7647059 , 0.7647059 , 0.70588237, 0.78431374, 0.7647059 ,\n",
       "        0.75490195, 0.74509805, 0.75490195, 0.68627453, 0.67647058,\n",
       "        0.77450979, 0.69607842, 0.74509805, 0.79411763, 0.75490195,\n",
       "        0.66666669, 0.71568626, 0.7352941 , 0.79411763, 0.70588237,\n",
       "        0.7647059 , 0.70588237, 0.72549021, 0.7647059 , 0.7352941 ,\n",
       "        0.7647059 , 0.74509805, 0.74509805, 0.74509805, 0.72549021,\n",
       "        0.70588237, 0.75490195, 0.75490195, 0.7647059 , 0.74509805,\n",
       "        0.74509805, 0.68627453, 0.61764705, 0.71568626, 0.67647058,\n",
       "        0.75490195, 0.7352941 , 0.71568626, 0.67647058, 0.60784316,\n",
       "        0.75490195, 0.7352941 , 0.78431374, 0.77450979, 0.72549021,\n",
       "        0.7352941 , 0.74509805, 0.75490195, 0.7352941 , 0.77450979,\n",
       "        0.75490195, 0.75490195, 0.79411763, 0.75490195, 0.74509805,\n",
       "        0.7352941 , 0.77450979, 0.7647059 , 0.72549021, 0.68627453,\n",
       "        0.68627453, 0.40196079, 0.7647059 , 0.75490195, 0.75490195,\n",
       "        0.70588237, 0.68627453, 0.627451  , 0.72549021, 0.57843137,\n",
       "        0.78431374, 0.78431374, 0.70588237, 0.69607842, 0.77450979,\n",
       "        0.74509805, 0.44117647, 0.74509805, 0.75490195, 0.75490195,\n",
       "        0.72549021, 0.72549021, 0.7352941 , 0.75490195, 0.7647059 ,\n",
       "        0.75490195, 0.77450979]),\n",
       " 'split4_test_score': array([0.72549021, 0.61764705, 0.68627453, 0.60784316, 0.66666669,\n",
       "        0.66666669, 0.66666669, 0.72549021, 0.64705884, 0.66666669,\n",
       "        0.67647058, 0.65686274, 0.66666669, 0.66666669, 0.69607842,\n",
       "        0.63725489, 0.67647058, 0.63725489, 0.61764705, 0.67647058,\n",
       "        0.64705884, 0.66666669, 0.63725489, 0.69607842, 0.65686274,\n",
       "        0.61764705, 0.63725489, 0.63725489, 0.65686274, 0.68627453,\n",
       "        0.65686274, 0.51960784, 0.66666669, 0.69607842, 0.69607842,\n",
       "        0.69607842, 0.67647058, 0.68627453, 0.67647058, 0.71568626,\n",
       "        0.68627453, 0.63725489, 0.7352941 , 0.63725489, 0.67647058,\n",
       "        0.67647058, 0.66666669, 0.69607842, 0.69607842, 0.65686274,\n",
       "        0.66666669, 0.67647058, 0.68627453, 0.63725489, 0.66666669,\n",
       "        0.627451  , 0.65686274, 0.68627453, 0.67647058, 0.69607842,\n",
       "        0.70588237, 0.70588237, 0.68627453, 0.66666669, 0.60784316,\n",
       "        0.69607842, 0.68627453, 0.69607842, 0.67647058, 0.67647058,\n",
       "        0.69607842, 0.64705884, 0.67647058, 0.66666669, 0.63725489,\n",
       "        0.67647058, 0.63725489, 0.70588237, 0.65686274, 0.65686274,\n",
       "        0.67647058, 0.67647058, 0.65686274, 0.68627453, 0.65686274,\n",
       "        0.67647058, 0.72549021, 0.68627453, 0.69607842, 0.71568626,\n",
       "        0.71568626, 0.65686274, 0.68627453, 0.69607842, 0.71568626,\n",
       "        0.70588237, 0.68627453, 0.69607842, 0.69607842, 0.69607842,\n",
       "        0.66666669, 0.68627453, 0.69607842, 0.66666669, 0.63725489,\n",
       "        0.7352941 , 0.66666669, 0.66666669, 0.64705884, 0.63725489,\n",
       "        0.70588237, 0.71568626]),\n",
       " 'mean_test_score': array([0.69980963, 0.69588807, 0.7076147 , 0.65857606, 0.73097278,\n",
       "        0.74648771, 0.68425663, 0.729012  , 0.72703217, 0.74070055,\n",
       "        0.70159909, 0.74842947, 0.73483723, 0.72116885, 0.71743766,\n",
       "        0.71534362, 0.7484485 , 0.72307253, 0.71332572, 0.73872073,\n",
       "        0.7134209 , 0.73093472, 0.71134589, 0.75044736, 0.73479917,\n",
       "        0.71140301, 0.72307254, 0.72503331, 0.66862745, 0.70944223,\n",
       "        0.70957547, 0.69362268, 0.71924615, 0.73881592, 0.73097278,\n",
       "        0.6919665 , 0.70561583, 0.73091567, 0.72712734, 0.70955645,\n",
       "        0.74262327, 0.70552065, 0.73293356, 0.73476108, 0.73672186,\n",
       "        0.68823529, 0.72701315, 0.72901199, 0.73872073, 0.72889777,\n",
       "        0.70363603, 0.74452692, 0.72901199, 0.7231106 , 0.73478013,\n",
       "        0.70751952, 0.66086046, 0.69767752, 0.69784886, 0.69392728,\n",
       "        0.7387588 , 0.736779  , 0.70563487, 0.6666857 , 0.652846  ,\n",
       "        0.73679801, 0.67460499, 0.74268037, 0.73679801, 0.70951837,\n",
       "        0.70569198, 0.7328003 , 0.71151723, 0.68427565, 0.73089663,\n",
       "        0.73675994, 0.70561583, 0.73883494, 0.72118789, 0.7269941 ,\n",
       "        0.68429469, 0.74844849, 0.73285742, 0.72312965, 0.66086046,\n",
       "        0.61818009, 0.64296592, 0.71349704, 0.73097278, 0.73295259,\n",
       "        0.62800304, 0.66086046, 0.67245384, 0.72897393, 0.70736721,\n",
       "        0.74658291, 0.73877785, 0.68427565, 0.68231486, 0.72518561,\n",
       "        0.72701313, 0.6623834 , 0.73483723, 0.72897393, 0.70949932,\n",
       "        0.72128308, 0.68231487, 0.71922711, 0.65903294, 0.72505236,\n",
       "        0.74846755, 0.73299066]),\n",
       " 'std_test_score': array([0.01882333, 0.05016736, 0.03412402, 0.07120611, 0.04659148,\n",
       "        0.04471922, 0.10219235, 0.02998283, 0.04746383, 0.05208857,\n",
       "        0.0375271 , 0.0490414 , 0.04418033, 0.04074492, 0.04559614,\n",
       "        0.05248598, 0.0374237 , 0.05532037, 0.05043646, 0.03237299,\n",
       "        0.04105966, 0.03680991, 0.04048339, 0.03161363, 0.03949757,\n",
       "        0.06414543, 0.04560751, 0.04630436, 0.02107546, 0.02826322,\n",
       "        0.04012561, 0.09066805, 0.03276496, 0.03279412, 0.03475791,\n",
       "        0.0141078 , 0.02379772, 0.02936622, 0.04920787, 0.04884627,\n",
       "        0.03571913, 0.03573752, 0.02509474, 0.05146901, 0.03784861,\n",
       "        0.05542999, 0.03280555, 0.01732532, 0.02257777, 0.04253442,\n",
       "        0.04061074, 0.03492767, 0.02949884, 0.04459347, 0.0404584 ,\n",
       "        0.04471221, 0.02350649, 0.05080051, 0.01248506, 0.03530311,\n",
       "        0.0252757 , 0.03469671, 0.03230393, 0.01374373, 0.04125618,\n",
       "        0.02278686, 0.04277025, 0.03368329, 0.03887708, 0.01941303,\n",
       "        0.02665572, 0.04808961, 0.03341983, 0.03773129, 0.05283165,\n",
       "        0.03278106, 0.05748721, 0.03317292, 0.03471768, 0.03629965,\n",
       "        0.07968678, 0.0412573 , 0.03905807, 0.02097797, 0.02350649,\n",
       "        0.09615009, 0.12717657, 0.03892798, 0.02882835, 0.01791161,\n",
       "        0.13089492, 0.02350649, 0.04981206, 0.02169016, 0.06762065,\n",
       "        0.03269655, 0.03885461, 0.05711586, 0.03718985, 0.02613942,\n",
       "        0.0418912 , 0.11245907, 0.02401531, 0.03180705, 0.04465773,\n",
       "        0.01742755, 0.02870913, 0.03617684, 0.08897326, 0.04742861,\n",
       "        0.02567474, 0.0230591 ]),\n",
       " 'rank_test_score': array([ 85,  88,  75, 108,  33,   7,  96,  39,  46,  11,  84,   5,  23,\n",
       "         59,  62,  63,   3,  56,  66,  16,  65,  36,  69,   1,  25,  68,\n",
       "         55,  52, 101,  74,  70,  90,  60,  13,  33,  91,  80,  37,  45,\n",
       "         71,  10,  82,  30,  27,  22,  92,  47,  40,  16,  44,  83,   8,\n",
       "         40,  54,  26,  76, 104,  87,  86,  89,  15,  20,  79, 102, 109,\n",
       "         18,  99,   9,  18,  72,  78,  32,  67,  94,  38,  21,  80,  12,\n",
       "         58,  49,  93,   4,  31,  53, 104, 112, 110,  64,  33,  29, 111,\n",
       "        104, 100,  42,  77,   6,  14,  94,  98,  50,  48, 103,  23,  42,\n",
       "         73,  57,  97,  61, 107,  51,   2,  28], dtype=int32)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.79        75\n",
      "           1       0.75      0.50      0.60        54\n",
      "\n",
      "    accuracy                           0.72       129\n",
      "   macro avg       0.73      0.69      0.69       129\n",
      "weighted avg       0.73      0.72      0.71       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66  9]\n",
      " [27 27]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "plot_confusion_matrix only supports classifiers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-108728807c35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fixed_comp/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fixed_comp/lib/python3.6/site-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(estimator, X, y_true, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"plot_confusion_matrix only supports classifiers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: plot_confusion_matrix only supports classifiers"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(grid, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/model_1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
