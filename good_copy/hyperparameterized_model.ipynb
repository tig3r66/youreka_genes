{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# for data scaling and splitting\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "# for neural net\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# for evaluation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th>cluster</th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>TNMD</th>\n",
       "      <th>DPM1</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>C1orf112</th>\n",
       "      <th>FGR</th>\n",
       "      <th>CFH</th>\n",
       "      <th>FUCA2</th>\n",
       "      <th>...</th>\n",
       "      <th>C6orf10</th>\n",
       "      <th>TMEM225</th>\n",
       "      <th>NOTCH4</th>\n",
       "      <th>PBX2</th>\n",
       "      <th>AGER</th>\n",
       "      <th>RNF5</th>\n",
       "      <th>AGPAT1</th>\n",
       "      <th>DFNB59</th>\n",
       "      <th>PRRT1</th>\n",
       "      <th>FKBPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240123</td>\n",
       "      <td>2</td>\n",
       "      <td>8.319417</td>\n",
       "      <td>3.111183</td>\n",
       "      <td>9.643558</td>\n",
       "      <td>4.757258</td>\n",
       "      <td>3.919757</td>\n",
       "      <td>3.602185</td>\n",
       "      <td>3.329644</td>\n",
       "      <td>9.076950</td>\n",
       "      <td>...</td>\n",
       "      <td>3.085394</td>\n",
       "      <td>3.462811</td>\n",
       "      <td>3.339030</td>\n",
       "      <td>4.614897</td>\n",
       "      <td>3.395845</td>\n",
       "      <td>3.419193</td>\n",
       "      <td>3.971646</td>\n",
       "      <td>3.729310</td>\n",
       "      <td>3.320022</td>\n",
       "      <td>6.447316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240131</td>\n",
       "      <td>3</td>\n",
       "      <td>7.611268</td>\n",
       "      <td>2.704739</td>\n",
       "      <td>10.276079</td>\n",
       "      <td>3.650299</td>\n",
       "      <td>3.481567</td>\n",
       "      <td>3.145538</td>\n",
       "      <td>3.565127</td>\n",
       "      <td>7.861068</td>\n",
       "      <td>...</td>\n",
       "      <td>2.801456</td>\n",
       "      <td>2.985889</td>\n",
       "      <td>3.180068</td>\n",
       "      <td>5.415729</td>\n",
       "      <td>3.299858</td>\n",
       "      <td>3.028414</td>\n",
       "      <td>3.877889</td>\n",
       "      <td>3.911516</td>\n",
       "      <td>3.379405</td>\n",
       "      <td>4.729557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240132</td>\n",
       "      <td>3</td>\n",
       "      <td>7.678658</td>\n",
       "      <td>2.845781</td>\n",
       "      <td>10.180954</td>\n",
       "      <td>3.573048</td>\n",
       "      <td>3.431235</td>\n",
       "      <td>3.090781</td>\n",
       "      <td>4.116643</td>\n",
       "      <td>8.121190</td>\n",
       "      <td>...</td>\n",
       "      <td>2.934962</td>\n",
       "      <td>2.952937</td>\n",
       "      <td>3.164655</td>\n",
       "      <td>5.707506</td>\n",
       "      <td>3.434295</td>\n",
       "      <td>2.961345</td>\n",
       "      <td>4.272194</td>\n",
       "      <td>3.085696</td>\n",
       "      <td>3.002557</td>\n",
       "      <td>5.653588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240134</td>\n",
       "      <td>3</td>\n",
       "      <td>3.265063</td>\n",
       "      <td>3.063746</td>\n",
       "      <td>10.490285</td>\n",
       "      <td>3.340791</td>\n",
       "      <td>3.676912</td>\n",
       "      <td>3.512821</td>\n",
       "      <td>3.873922</td>\n",
       "      <td>8.790851</td>\n",
       "      <td>...</td>\n",
       "      <td>3.041839</td>\n",
       "      <td>3.398847</td>\n",
       "      <td>3.106710</td>\n",
       "      <td>5.773963</td>\n",
       "      <td>3.412641</td>\n",
       "      <td>3.136110</td>\n",
       "      <td>4.422262</td>\n",
       "      <td>3.522122</td>\n",
       "      <td>3.509437</td>\n",
       "      <td>5.953242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240140</td>\n",
       "      <td>3</td>\n",
       "      <td>7.090138</td>\n",
       "      <td>2.988043</td>\n",
       "      <td>10.264692</td>\n",
       "      <td>4.119555</td>\n",
       "      <td>3.432585</td>\n",
       "      <td>3.308033</td>\n",
       "      <td>3.318371</td>\n",
       "      <td>6.927761</td>\n",
       "      <td>...</td>\n",
       "      <td>3.028787</td>\n",
       "      <td>3.225982</td>\n",
       "      <td>3.275820</td>\n",
       "      <td>5.334283</td>\n",
       "      <td>3.864678</td>\n",
       "      <td>3.259242</td>\n",
       "      <td>3.840581</td>\n",
       "      <td>5.809553</td>\n",
       "      <td>3.674587</td>\n",
       "      <td>5.577503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CELL_LINE_NAME  cluster    TSPAN6      TNMD       DPM1     SCYL3  C1orf112  \\\n",
       "0         1240123        2  8.319417  3.111183   9.643558  4.757258  3.919757   \n",
       "1         1240131        3  7.611268  2.704739  10.276079  3.650299  3.481567   \n",
       "2         1240132        3  7.678658  2.845781  10.180954  3.573048  3.431235   \n",
       "3         1240134        3  3.265063  3.063746  10.490285  3.340791  3.676912   \n",
       "4         1240140        3  7.090138  2.988043  10.264692  4.119555  3.432585   \n",
       "\n",
       "        FGR       CFH     FUCA2  ...   C6orf10   TMEM225    NOTCH4      PBX2  \\\n",
       "0  3.602185  3.329644  9.076950  ...  3.085394  3.462811  3.339030  4.614897   \n",
       "1  3.145538  3.565127  7.861068  ...  2.801456  2.985889  3.180068  5.415729   \n",
       "2  3.090781  4.116643  8.121190  ...  2.934962  2.952937  3.164655  5.707506   \n",
       "3  3.512821  3.873922  8.790851  ...  3.041839  3.398847  3.106710  5.773963   \n",
       "4  3.308033  3.318371  6.927761  ...  3.028787  3.225982  3.275820  5.334283   \n",
       "\n",
       "       AGER      RNF5    AGPAT1    DFNB59     PRRT1     FKBPL  \n",
       "0  3.395845  3.419193  3.971646  3.729310  3.320022  6.447316  \n",
       "1  3.299858  3.028414  3.877889  3.911516  3.379405  4.729557  \n",
       "2  3.434295  2.961345  4.272194  3.085696  3.002557  5.653588  \n",
       "3  3.412641  3.136110  4.422262  3.522122  3.509437  5.953242  \n",
       "4  3.864678  3.259242  3.840581  5.809553  3.674587  5.577503  \n",
       "\n",
       "[5 rows x 16384 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/combined_expression.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541, 16384)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes = pd.read_csv('cleaned/boruta.csv')\n",
    "selected_genes = selected_genes.values.tolist()\n",
    "selected_genes = list(itertools.chain(*selected_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving proper columns\n",
    "X = data.loc[:, selected_genes]\n",
    "y = data['cluster'].values\n",
    "\n",
    "# scaling the data\n",
    "scalar = MinMaxScaler()\n",
    "x_scaled = scalar.fit_transform(X)\n",
    "\n",
    "# splitting data (20% test, 80% train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch for Input and Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='rmsprop', init='glorot_uniform', dropout=0.3):\n",
    "    model = Sequential()\n",
    "    # adding layers and adding droplayers to avoid overfitting\n",
    "    hidden_layers = len(selected_genes)\n",
    "\n",
    "    # first hidden layer\n",
    "    model.add(Dense(hidden_layers, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    # second hidden layer\n",
    "    model.add(Dense((hidden_layers*1.5), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    # third hidden layer\n",
    "    model.add(Dense((hidden_layers), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    # fourth hidden layer\n",
    "    model.add(Dense((hidden_layers*0.25), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 36.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 432 samples\n",
      "Epoch 1/75\n",
      "432/432 [==============================] - 3s 7ms/sample - loss: 1.4495 - accuracy: 0.3958\n",
      "Epoch 2/75\n",
      "432/432 [==============================] - 0s 268us/sample - loss: 1.2077 - accuracy: 0.4838\n",
      "Epoch 3/75\n",
      "432/432 [==============================] - 0s 272us/sample - loss: 1.1131 - accuracy: 0.5278\n",
      "Epoch 4/75\n",
      "432/432 [==============================] - 0s 270us/sample - loss: 1.0781 - accuracy: 0.5532\n",
      "Epoch 5/75\n",
      "432/432 [==============================] - 0s 273us/sample - loss: 1.0740 - accuracy: 0.5579\n",
      "Epoch 6/75\n",
      "432/432 [==============================] - 0s 271us/sample - loss: 1.1426 - accuracy: 0.5532\n",
      "Epoch 7/75\n",
      "432/432 [==============================] - 0s 268us/sample - loss: 1.0807 - accuracy: 0.5556\n",
      "Epoch 8/75\n",
      "432/432 [==============================] - 0s 270us/sample - loss: 1.0379 - accuracy: 0.5648\n",
      "Epoch 9/75\n",
      "432/432 [==============================] - 0s 269us/sample - loss: 0.9879 - accuracy: 0.5833\n",
      "Epoch 10/75\n",
      "432/432 [==============================] - 0s 279us/sample - loss: 1.0112 - accuracy: 0.5833\n",
      "Epoch 11/75\n",
      "432/432 [==============================] - 0s 278us/sample - loss: 0.9804 - accuracy: 0.5810\n",
      "Epoch 12/75\n",
      "432/432 [==============================] - 0s 273us/sample - loss: 0.8980 - accuracy: 0.6389\n",
      "Epoch 13/75\n",
      "432/432 [==============================] - 0s 269us/sample - loss: 0.9644 - accuracy: 0.5718\n",
      "Epoch 14/75\n",
      "432/432 [==============================] - 0s 273us/sample - loss: 0.9468 - accuracy: 0.5995\n",
      "Epoch 15/75\n",
      "432/432 [==============================] - 0s 271us/sample - loss: 0.9048 - accuracy: 0.6181\n",
      "Epoch 16/75\n",
      "432/432 [==============================] - 0s 269us/sample - loss: 0.9871 - accuracy: 0.5926\n",
      "Epoch 17/75\n",
      "432/432 [==============================] - 0s 272us/sample - loss: 0.8651 - accuracy: 0.6343\n",
      "Epoch 18/75\n",
      "432/432 [==============================] - 0s 271us/sample - loss: 0.9537 - accuracy: 0.5903\n",
      "Epoch 19/75\n",
      "432/432 [==============================] - 0s 270us/sample - loss: 0.9448 - accuracy: 0.5972\n",
      "Epoch 20/75\n",
      "432/432 [==============================] - 0s 269us/sample - loss: 0.9359 - accuracy: 0.5949\n",
      "Epoch 21/75\n",
      "432/432 [==============================] - 0s 270us/sample - loss: 0.8619 - accuracy: 0.6435\n",
      "Epoch 22/75\n",
      "432/432 [==============================] - 0s 269us/sample - loss: 0.9402 - accuracy: 0.6157\n",
      "Epoch 23/75\n",
      "432/432 [==============================] - 0s 276us/sample - loss: 0.8797 - accuracy: 0.6273\n",
      "Epoch 24/75\n",
      "432/432 [==============================] - 0s 273us/sample - loss: 0.9241 - accuracy: 0.6366\n",
      "Epoch 25/75\n",
      "432/432 [==============================] - 0s 278us/sample - loss: 0.8398 - accuracy: 0.6505\n",
      "Epoch 26/75\n",
      "432/432 [==============================] - 0s 272us/sample - loss: 0.8727 - accuracy: 0.6366\n",
      "Epoch 27/75\n",
      "432/432 [==============================] - 0s 279us/sample - loss: 0.8682 - accuracy: 0.6458\n",
      "Epoch 28/75\n",
      "432/432 [==============================] - 0s 286us/sample - loss: 0.9133 - accuracy: 0.6389\n",
      "Epoch 29/75\n",
      "432/432 [==============================] - 0s 291us/sample - loss: 0.8509 - accuracy: 0.6250\n",
      "Epoch 30/75\n",
      "432/432 [==============================] - 0s 291us/sample - loss: 0.8558 - accuracy: 0.6551\n",
      "Epoch 31/75\n",
      "432/432 [==============================] - 0s 290us/sample - loss: 0.9110 - accuracy: 0.6458\n",
      "Epoch 32/75\n",
      "432/432 [==============================] - 0s 298us/sample - loss: 0.8596 - accuracy: 0.6412\n",
      "Epoch 33/75\n",
      "432/432 [==============================] - 0s 300us/sample - loss: 0.8608 - accuracy: 0.6551\n",
      "Epoch 34/75\n",
      "432/432 [==============================] - 0s 300us/sample - loss: 0.8486 - accuracy: 0.6481\n",
      "Epoch 35/75\n",
      "432/432 [==============================] - 0s 300us/sample - loss: 0.8709 - accuracy: 0.6389\n",
      "Epoch 36/75\n",
      "432/432 [==============================] - 0s 300us/sample - loss: 0.8610 - accuracy: 0.6644\n",
      "Epoch 37/75\n",
      "432/432 [==============================] - 0s 299us/sample - loss: 0.8357 - accuracy: 0.6644\n",
      "Epoch 38/75\n",
      "432/432 [==============================] - 0s 301us/sample - loss: 0.8010 - accuracy: 0.6620\n",
      "Epoch 39/75\n",
      "432/432 [==============================] - 0s 301us/sample - loss: 0.8351 - accuracy: 0.6574\n",
      "Epoch 40/75\n",
      "432/432 [==============================] - 0s 302us/sample - loss: 0.8912 - accuracy: 0.6412\n",
      "Epoch 41/75\n",
      "432/432 [==============================] - 0s 302us/sample - loss: 0.8883 - accuracy: 0.6273\n",
      "Epoch 42/75\n",
      "432/432 [==============================] - 0s 298us/sample - loss: 0.8814 - accuracy: 0.6713\n",
      "Epoch 43/75\n",
      "432/432 [==============================] - 0s 299us/sample - loss: 0.8585 - accuracy: 0.6412\n",
      "Epoch 44/75\n",
      "432/432 [==============================] - 0s 301us/sample - loss: 0.8158 - accuracy: 0.6366\n",
      "Epoch 45/75\n",
      "432/432 [==============================] - 0s 302us/sample - loss: 0.8286 - accuracy: 0.6458\n",
      "Epoch 46/75\n",
      "432/432 [==============================] - 0s 318us/sample - loss: 0.8476 - accuracy: 0.6667\n",
      "Epoch 47/75\n",
      "432/432 [==============================] - 0s 314us/sample - loss: 0.8462 - accuracy: 0.6343\n",
      "Epoch 48/75\n",
      "432/432 [==============================] - 0s 316us/sample - loss: 0.8858 - accuracy: 0.6574\n",
      "Epoch 49/75\n",
      "432/432 [==============================] - 0s 312us/sample - loss: 0.7951 - accuracy: 0.6806\n",
      "Epoch 50/75\n",
      "432/432 [==============================] - 0s 312us/sample - loss: 0.7881 - accuracy: 0.6736\n",
      "Epoch 51/75\n",
      "432/432 [==============================] - 0s 300us/sample - loss: 0.7741 - accuracy: 0.6782\n",
      "Epoch 52/75\n",
      "432/432 [==============================] - 0s 299us/sample - loss: 0.8141 - accuracy: 0.6806\n",
      "Epoch 53/75\n",
      "432/432 [==============================] - 0s 314us/sample - loss: 0.8613 - accuracy: 0.6667\n",
      "Epoch 54/75\n",
      "432/432 [==============================] - 0s 310us/sample - loss: 0.8790 - accuracy: 0.6505\n",
      "Epoch 55/75\n",
      "432/432 [==============================] - 0s 314us/sample - loss: 0.8693 - accuracy: 0.6574\n",
      "Epoch 56/75\n",
      "432/432 [==============================] - 0s 316us/sample - loss: 0.8653 - accuracy: 0.6412\n",
      "Epoch 57/75\n",
      "432/432 [==============================] - 0s 312us/sample - loss: 0.8925 - accuracy: 0.6250\n",
      "Epoch 58/75\n",
      "432/432 [==============================] - 0s 305us/sample - loss: 0.7791 - accuracy: 0.6991\n",
      "Epoch 59/75\n",
      "432/432 [==============================] - 0s 299us/sample - loss: 0.8049 - accuracy: 0.6597\n",
      "Epoch 60/75\n",
      "432/432 [==============================] - 0s 298us/sample - loss: 0.8178 - accuracy: 0.6574\n",
      "Epoch 61/75\n",
      "432/432 [==============================] - 0s 297us/sample - loss: 0.8255 - accuracy: 0.6620\n",
      "Epoch 62/75\n",
      "432/432 [==============================] - 0s 299us/sample - loss: 0.8602 - accuracy: 0.6574\n",
      "Epoch 63/75\n",
      "432/432 [==============================] - 0s 300us/sample - loss: 0.8788 - accuracy: 0.6458\n",
      "Epoch 64/75\n",
      "432/432 [==============================] - 0s 311us/sample - loss: 0.7994 - accuracy: 0.6551\n",
      "Epoch 65/75\n",
      "432/432 [==============================] - 0s 311us/sample - loss: 0.8036 - accuracy: 0.6505\n",
      "Epoch 66/75\n",
      "432/432 [==============================] - 0s 301us/sample - loss: 0.8099 - accuracy: 0.6574\n",
      "Epoch 67/75\n",
      "432/432 [==============================] - 0s 301us/sample - loss: 0.7704 - accuracy: 0.6644\n",
      "Epoch 68/75\n",
      "432/432 [==============================] - 0s 297us/sample - loss: 0.8020 - accuracy: 0.6597\n",
      "Epoch 69/75\n",
      "432/432 [==============================] - 0s 297us/sample - loss: 0.8074 - accuracy: 0.6759\n",
      "Epoch 70/75\n",
      "432/432 [==============================] - 0s 299us/sample - loss: 0.7534 - accuracy: 0.6528\n",
      "Epoch 71/75\n",
      "432/432 [==============================] - 0s 299us/sample - loss: 0.7253 - accuracy: 0.6829\n",
      "Epoch 72/75\n",
      "432/432 [==============================] - 0s 310us/sample - loss: 0.8036 - accuracy: 0.6690\n",
      "Epoch 73/75\n",
      "432/432 [==============================] - 0s 306us/sample - loss: 0.7769 - accuracy: 0.6829\n",
      "Epoch 74/75\n",
      "432/432 [==============================] - 0s 297us/sample - loss: 0.7648 - accuracy: 0.6944\n",
      "Epoch 75/75\n",
      "432/432 [==============================] - 0s 297us/sample - loss: 0.8336 - accuracy: 0.6389\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "# parameters\n",
    "epochs = [50, 75, 100, 150]\n",
    "batches = [16, 32, 64, 128]\n",
    "optimizers = ['SGD', 'RMSprop', 'Adagrad', 'Adam', 'Adamax']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "# grid search\n",
    "param_grid = dict(epochs=epochs, batch_size=batches,optimizer=optimizers,init=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.717593 using {'batch_size': 64, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adagrad'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([29.82347385, 37.74450461, 35.22818104, 33.04543535, 24.96807607,\n",
       "        21.58027943, 32.26096543, 30.20425502, 29.15370663, 30.0019455 ,\n",
       "        27.36595496, 34.31726933, 32.10289224, 29.20354907, 29.91525769,\n",
       "        33.77772776, 45.74009275, 40.60837603, 39.95916279, 42.66015267,\n",
       "        29.5885663 , 42.77599263, 38.91595801, 40.21461463, 38.98714749,\n",
       "        31.22201371, 41.63639577, 41.12591434, 39.31136401, 41.82191714,\n",
       "        42.72427487, 57.80267223, 51.43229238, 51.02590537, 51.8656443 ,\n",
       "        42.83516129, 60.21969334, 56.94429874, 55.70062669, 52.36726491,\n",
       "        42.6482842 , 54.9538513 , 51.80941931, 49.99627304, 50.91359949,\n",
       "        61.86388334, 81.02049271, 78.52006475, 72.58623608, 67.39916913,\n",
       "        58.84941808, 80.84872238, 74.53146919, 72.15816601, 69.82273014,\n",
       "        59.62388563, 80.52583996, 75.09343799, 69.35380491, 68.72098303,\n",
       "        24.83556604, 29.24116723, 23.31435672, 22.01664575, 21.57369796,\n",
       "        18.20750999, 22.82201401, 20.81949099, 19.83141041, 20.46308533,\n",
       "        17.15962474, 22.92965754, 19.81063016, 18.74108505, 20.77765155,\n",
       "        19.5370814 , 28.47118235, 25.24059097, 26.28877648, 26.56496263,\n",
       "        19.87780229, 27.32234279, 26.23860192, 25.5801096 , 26.59527302,\n",
       "        23.1210204 , 30.3276302 , 27.11241961, 26.06540028, 27.31355294,\n",
       "        26.18133855, 37.91229606, 33.79442032, 34.18631156, 33.79653247,\n",
       "        25.73127945, 35.00530926, 32.28511278, 31.9889156 , 31.76198538,\n",
       "        28.40559737, 35.33327007, 34.21028582, 30.89644774, 32.85370096,\n",
       "        39.02022664, 53.72828571, 48.38400459, 46.93497602, 48.45809301,\n",
       "        36.53449543, 50.19610397, 46.17727335, 45.38805636, 45.2328852 ,\n",
       "        39.17371933, 51.09189471, 45.50699409, 43.40786425, 43.05459563,\n",
       "        26.6693484 , 27.7753605 , 19.72645934, 18.54134576, 19.76736331,\n",
       "        19.18164388, 21.7077961 , 19.39382418, 19.21706327, 21.13053465,\n",
       "        15.7618076 , 20.7567366 , 19.33382909, 19.15261698, 18.62098734,\n",
       "        20.8051614 , 26.60765719, 24.73114951, 23.43061233, 24.33466697,\n",
       "        22.62691991, 25.43180736, 22.96994495, 24.11965632, 25.47031967,\n",
       "        20.3505005 , 25.73594236, 23.74360323, 23.84630291, 23.99870936,\n",
       "        24.23280327, 31.08958093, 28.34206303, 27.22935669, 29.89457798,\n",
       "        25.1130348 , 29.94196534, 27.86796848, 29.60189025, 28.82650797,\n",
       "        23.88616459, 30.98783596, 29.64787769, 28.38309566, 29.951497  ,\n",
       "        37.20541803, 45.00308545, 40.70560964, 39.07544494, 44.23001893,\n",
       "        33.08852164, 41.46835232, 39.28923996, 38.5244503 , 37.38670166,\n",
       "        34.26328278, 45.14816268, 39.55280002, 36.64148498, 38.8599418 ,\n",
       "        25.07408913, 19.694031  , 17.2979823 , 17.21118236, 17.92417987,\n",
       "        14.57774639, 19.81885441, 17.77575318, 17.722296  , 17.98362589,\n",
       "        14.74406234, 19.44349694, 17.76998313, 17.27611995, 16.85005522,\n",
       "        17.64098978, 22.58135939, 20.77630401, 19.68849397, 21.02841338,\n",
       "        20.15357916, 23.98005223, 21.69441255, 21.76473641, 21.01578498,\n",
       "        17.42403944, 22.49373404, 20.79106808, 20.34826374, 20.44220408,\n",
       "        19.96176593, 25.4882551 , 24.08575074, 23.21749926, 24.87357004,\n",
       "        21.02378305, 25.97453817, 23.45992772, 25.14706834, 25.33613801,\n",
       "        20.52555394, 26.26021139, 25.45452611, 24.0305593 , 24.47399394,\n",
       "        26.67439365, 34.79537606, 32.25815495, 32.50332403, 36.05607104,\n",
       "        26.42836054, 35.24039658, 33.60911767, 34.83465298, 32.90327668,\n",
       "        30.05069931, 38.81783223, 34.80908203, 32.79640818, 31.37405912]),\n",
       " 'std_fit_time': array([0.38371409, 0.16545278, 0.37448044, 0.12359149, 0.29378958,\n",
       "        0.18464648, 0.15127976, 0.31765312, 0.26639512, 0.13209075,\n",
       "        0.41307545, 0.20696781, 0.24938857, 0.27283986, 0.19167017,\n",
       "        0.1371945 , 0.17141995, 0.19379031, 0.51863011, 0.23551368,\n",
       "        0.12633096, 0.13514584, 0.28827868, 0.49992925, 0.15617927,\n",
       "        0.19870183, 0.16937841, 1.07235875, 0.39980733, 0.12249754,\n",
       "        0.14051866, 0.31508627, 0.55035396, 0.35707047, 0.27888059,\n",
       "        0.14126343, 0.37973219, 0.35268265, 0.36803508, 0.51641422,\n",
       "        0.32712934, 0.51081337, 1.23087864, 1.0607242 , 1.02661028,\n",
       "        0.40005635, 1.12722196, 0.95197229, 0.10130382, 0.25318799,\n",
       "        0.22365052, 1.82345344, 1.2150541 , 0.08263112, 0.89921629,\n",
       "        0.69578104, 0.4972184 , 0.53271301, 0.27475843, 0.21281479,\n",
       "        0.14196875, 0.08370572, 0.19851102, 0.25268722, 0.22632821,\n",
       "        1.16295716, 0.63630016, 0.16685664, 0.1269134 , 0.11213805,\n",
       "        0.22711788, 0.40910961, 0.26646315, 0.37603084, 0.31551906,\n",
       "        0.25157447, 0.41276987, 0.67799391, 0.99311056, 0.23639228,\n",
       "        0.1353364 , 0.08747473, 0.89148293, 0.16442189, 0.2886765 ,\n",
       "        0.14355492, 0.90426549, 0.20798816, 0.14534065, 0.11865073,\n",
       "        1.23166636, 0.41053835, 0.38136083, 0.04592283, 0.70359959,\n",
       "        0.0328009 , 0.12514023, 0.01334611, 0.16186021, 0.03765901,\n",
       "        0.0534131 , 0.14075689, 0.21297359, 0.18329928, 0.09734889,\n",
       "        0.18729604, 0.34201122, 0.75756437, 0.30730304, 0.55731116,\n",
       "        0.53595775, 0.33324683, 0.6557179 , 0.1988637 , 0.50179889,\n",
       "        0.74362108, 0.48365201, 0.68226882, 0.29676441, 0.32539668,\n",
       "        0.434787  , 0.49331217, 0.05667717, 0.17442759, 0.71146421,\n",
       "        0.8150647 , 0.24794434, 0.11223682, 1.5453288 , 0.66031748,\n",
       "        0.00920628, 0.12208557, 1.03288002, 0.27493992, 0.03874319,\n",
       "        0.12655817, 0.47974726, 0.09677869, 0.07943216, 0.10299249,\n",
       "        1.6963822 , 0.46285383, 0.11329271, 0.12227021, 0.66248753,\n",
       "        0.12275189, 0.1228833 , 0.14252887, 0.13707952, 0.04362797,\n",
       "        0.1957823 , 0.55594954, 0.21822702, 0.17225426, 0.60220431,\n",
       "        0.28671263, 0.49605973, 0.35401577, 0.98137558, 0.34245909,\n",
       "        0.08727524, 0.20326999, 0.21323342, 0.20767691, 0.29473059,\n",
       "        0.31117108, 0.7404387 , 0.14368095, 0.58442474, 0.85362456,\n",
       "        0.3044903 , 0.23841258, 0.7072671 , 0.26651699, 0.17541189,\n",
       "        0.3628311 , 0.98171445, 0.07998203, 0.15392627, 0.22229114,\n",
       "        1.16988237, 0.10611108, 0.10125086, 0.29534303, 0.37086065,\n",
       "        0.02761633, 0.10543593, 0.27068319, 0.47363986, 0.0752489 ,\n",
       "        0.06158626, 0.06399806, 0.70719794, 0.07111678, 0.06463473,\n",
       "        0.22066979, 0.16719119, 0.02150409, 0.31345858, 0.05848533,\n",
       "        0.60245985, 0.33280091, 0.21868919, 0.08554686, 0.81326458,\n",
       "        0.16274604, 0.07203764, 0.28079535, 0.07328257, 0.14101161,\n",
       "        0.17258847, 0.29525939, 0.26019543, 0.16867416, 0.27426906,\n",
       "        0.26052719, 0.27824658, 0.21792748, 0.196612  , 0.24878734,\n",
       "        0.14657406, 0.12064482, 0.08929452, 0.37680577, 0.09186953,\n",
       "        0.07753721, 0.27039727, 0.55917556, 0.95617334, 0.8921667 ,\n",
       "        0.39463355, 0.41040262, 1.33610051, 0.33726156, 0.05218261,\n",
       "        0.2100423 , 2.26230959, 0.09099611, 0.35451328, 0.25229384]),\n",
       " 'mean_score_time': array([3.84463612, 1.51668231, 2.13390501, 3.20728477, 3.19573458,\n",
       "        3.40403191, 1.95020906, 1.98783811, 3.50721399, 3.12735915,\n",
       "        2.51448496, 1.92732795, 3.0057141 , 3.21983965, 1.93613362,\n",
       "        3.15096132, 2.14513501, 4.17493987, 2.59824371, 2.2467742 ,\n",
       "        2.83616598, 2.29664644, 2.79144994, 2.8910234 , 2.85914175,\n",
       "        2.32824334, 2.45049755, 3.34905362, 2.77859831, 1.95442462,\n",
       "        3.85030945, 3.45600565, 3.23857093, 2.0874157 , 3.5120403 ,\n",
       "        3.88722157, 3.20065228, 3.09533962, 2.68345555, 3.29084436,\n",
       "        2.94062535, 3.15965263, 3.21497965, 2.83197498, 3.00986052,\n",
       "        4.25985328, 3.90617029, 3.14903792, 2.80229362, 3.46930854,\n",
       "        4.40875737, 3.28253969, 3.87151043, 3.2323974 , 4.8050468 ,\n",
       "        3.82712348, 3.75733733, 3.37392632, 2.30264672, 2.64884782,\n",
       "        3.05827951, 2.44795863, 2.18564256, 2.00610375, 2.04713178,\n",
       "        2.12108596, 2.44356998, 1.95341221, 2.21265825, 2.08383934,\n",
       "        1.94134665, 4.16614405, 2.10566568, 1.91826399, 2.0483853 ,\n",
       "        3.40424633, 2.36690466, 3.16117899, 1.92711131, 2.74768241,\n",
       "        2.64558911, 1.9659969 , 2.48911603, 3.04343931, 2.27226106,\n",
       "        1.76761556, 3.6120348 , 2.95518017, 2.23565435, 1.68306502,\n",
       "        4.05001616, 2.64134796, 2.99208538, 1.81825638, 2.80974857,\n",
       "        3.65652021, 2.07910403, 1.94833875, 3.30157757, 2.97844466,\n",
       "        2.19550538, 2.26662771, 3.59081443, 2.81972988, 1.92716265,\n",
       "        3.94875669, 2.98984591, 3.74593099, 2.88337223, 3.07276074,\n",
       "        3.33428264, 2.28906695, 3.24741538, 2.99785264, 3.58154885,\n",
       "        3.03010408, 2.9893887 , 3.15829166, 2.76967208, 1.74411178,\n",
       "        2.01844001, 2.13600365, 2.258811  , 1.96755242, 1.63197954,\n",
       "        1.95366112, 1.87678663, 2.04417642, 1.75523162, 1.92965508,\n",
       "        1.93573864, 1.71337207, 1.88784266, 2.03061366, 1.71110336,\n",
       "        1.91519602, 1.96229951, 2.371375  , 1.8259143 , 1.77172772,\n",
       "        1.94715897, 2.13382395, 2.51501679, 1.75215189, 2.11972729,\n",
       "        1.91120569, 1.92734996, 1.83200701, 2.25814605, 1.77888751,\n",
       "        1.83628909, 2.98332262, 2.26963965, 1.8928469 , 1.81243237,\n",
       "        3.18729011, 2.35032336, 2.02856835, 2.19734255, 1.9784135 ,\n",
       "        1.92538977, 2.10426323, 3.33848556, 2.10745398, 2.06436133,\n",
       "        4.05326287, 2.97247219, 2.16120831, 1.74802287, 3.54777129,\n",
       "        2.95617811, 1.80556957, 1.94355043, 3.48737804, 2.43568397,\n",
       "        1.89920195, 3.7048889 , 1.86459764, 2.10545492, 1.72450121,\n",
       "        1.62738959, 2.28531567, 2.36985461, 1.90082558, 1.71591544,\n",
       "        1.97558856, 2.0231092 , 2.12466804, 1.94028997, 1.87505873,\n",
       "        2.06953136, 1.81516075, 1.84743889, 1.95500247, 1.97450924,\n",
       "        1.79555806, 2.18088595, 1.97848972, 2.05771446, 2.49891106,\n",
       "        2.27834344, 2.00767597, 2.01341836, 1.86642194, 1.94632562,\n",
       "        1.91933123, 1.97809895, 1.8930467 , 2.16390125, 1.95651706,\n",
       "        1.75147756, 2.69855698, 2.24214133, 1.91294813, 1.84371336,\n",
       "        1.97294895, 2.49495546, 2.21617111, 2.08803892, 2.03263799,\n",
       "        2.10507059, 2.07776395, 2.40780298, 2.10562078, 1.97687173,\n",
       "        2.68732707, 3.38740571, 2.36362306, 1.96078165, 2.99732931,\n",
       "        3.5332733 , 1.94978642, 2.20801838, 3.27230899, 2.48495905,\n",
       "        2.0766751 , 2.87818344, 2.33379134, 1.56642795, 0.50207051]),\n",
       " 'std_score_time': array([0.15605706, 0.00488061, 0.12321692, 0.0412116 , 0.06019653,\n",
       "        0.0780097 , 0.01132863, 0.02737641, 0.07768417, 0.05406054,\n",
       "        0.10690415, 0.04750054, 0.10929222, 0.13343933, 0.10671253,\n",
       "        0.35867602, 0.05916833, 0.13268652, 0.371383  , 0.12597484,\n",
       "        0.05016541, 0.21454149, 0.09680688, 0.09536242, 0.09634096,\n",
       "        0.01877447, 0.15759663, 0.0274585 , 0.05587444, 0.0666712 ,\n",
       "        0.18332302, 0.40918419, 0.23532205, 0.11625984, 0.24264162,\n",
       "        0.43217315, 0.13111192, 0.15036226, 0.07201452, 0.33106542,\n",
       "        0.08756771, 0.12697639, 0.11433038, 0.11611263, 0.03195318,\n",
       "        0.30836504, 0.05002336, 0.63476224, 0.23634214, 0.25632333,\n",
       "        0.37319409, 0.57887753, 0.45456891, 0.05974222, 0.04814349,\n",
       "        0.20614672, 0.10738462, 0.08922674, 0.34656993, 0.24035899,\n",
       "        0.12883224, 0.06472669, 0.40509992, 0.19670266, 0.03875428,\n",
       "        0.08268382, 0.17390103, 0.06901547, 0.05892741, 0.07624434,\n",
       "        0.02192281, 0.32514453, 0.1911145 , 0.05046846, 0.07344923,\n",
       "        0.35741113, 0.25220427, 0.63144258, 0.06748202, 0.4033662 ,\n",
       "        0.22341065, 0.05709823, 0.38428872, 0.33599027, 0.0500001 ,\n",
       "        0.03913167, 0.43140004, 0.25575411, 0.07272855, 0.04515104,\n",
       "        0.10087926, 0.28444134, 0.11683149, 0.02292209, 0.09153839,\n",
       "        0.21868723, 0.09636438, 0.11192527, 0.05910556, 0.12925648,\n",
       "        0.06480854, 0.32944711, 0.6418659 , 0.06039297, 0.05531932,\n",
       "        0.0276501 , 0.64834754, 0.41969054, 0.20699633, 0.19997397,\n",
       "        0.11300584, 0.11029339, 0.35114788, 0.07451338, 0.13690677,\n",
       "        0.12500352, 0.06524314, 0.3204183 , 0.0483394 , 0.09002275,\n",
       "        0.20713951, 0.36619125, 0.20570096, 0.20806451, 0.11938383,\n",
       "        0.17357516, 0.01616687, 0.1318032 , 0.18728213, 0.18307421,\n",
       "        0.02916793, 0.01175734, 0.09028569, 0.05690485, 0.01767825,\n",
       "        0.07954217, 0.40876851, 0.39279436, 0.01183996, 0.0497234 ,\n",
       "        0.34665702, 0.1132505 , 0.06560741, 0.09339026, 0.26154729,\n",
       "        0.01789014, 0.12279271, 0.0794992 , 0.19589999, 0.01949083,\n",
       "        0.07510915, 0.49150075, 0.18928032, 0.05106753, 0.05632702,\n",
       "        0.20228473, 0.31468356, 0.12152334, 0.17825368, 0.04041271,\n",
       "        0.05851476, 0.22329583, 0.33806998, 0.05233304, 0.1248504 ,\n",
       "        0.22350994, 0.89647969, 0.10758836, 0.11272118, 0.11744758,\n",
       "        0.34839088, 0.02395362, 0.26484078, 0.28744218, 0.07683539,\n",
       "        0.21032596, 0.30346937, 0.05368393, 0.38646678, 0.15259001,\n",
       "        0.06725574, 0.07758165, 0.04309181, 0.0875402 , 0.03623163,\n",
       "        0.01617196, 0.16172476, 0.13574585, 0.19649762, 0.04656584,\n",
       "        0.12602386, 0.05629325, 0.10508384, 0.01807155, 0.03616054,\n",
       "        0.01349369, 0.47705173, 0.03557049, 0.10072869, 0.13284437,\n",
       "        0.39029402, 0.03726689, 0.06351443, 0.05524077, 0.15127679,\n",
       "        0.02650992, 0.03944767, 0.15198212, 0.32941476, 0.0723844 ,\n",
       "        0.07704685, 0.11386185, 0.19319325, 0.02350824, 0.02729388,\n",
       "        0.13086776, 0.38300255, 0.11965653, 0.05228535, 0.15373354,\n",
       "        0.22169523, 0.09384336, 0.14004873, 0.2009215 , 0.18041448,\n",
       "        0.44054002, 0.60824211, 0.36693949, 0.04644009, 0.26211543,\n",
       "        0.25697601, 0.07087929, 0.2158455 , 0.20943253, 0.12025491,\n",
       "        0.03442518, 1.24336491, 0.27976704, 0.21040703, 0.0192862 ]),\n",
       " 'param_batch_size': masked_array(data=[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 32, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64,\n",
       "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 128,\n",
       "                    128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "                    128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "                    128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "                    128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "                    128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "                    128, 128, 128, 128],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75,\n",
       "                    75, 75, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 150, 150, 150, 150, 150,\n",
       "                    150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75,\n",
       "                    75, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 150, 150, 150, 150, 150, 150,\n",
       "                    150, 150, 150, 150, 150, 150, 150, 150, 150, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 75,\n",
       "                    75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 150, 150, 150, 150, 150, 150, 150,\n",
       "                    150, 150, 150, 150, 150, 150, 150, 150, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 75, 75, 75,\n",
       "                    75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 150, 150, 150, 150, 150, 150, 150, 150,\n",
       "                    150, 150, 150, 150, 150, 150, 150],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_init': masked_array(data=['glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'normal', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'glorot_uniform', 'glorot_uniform',\n",
       "                    'glorot_uniform', 'normal', 'normal', 'normal',\n",
       "                    'normal', 'normal', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_optimizer': masked_array(data=['SGD', 'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adam', 'Adamax'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'batch_size': 16,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 75, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 75, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 75, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 75, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 16,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 150, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 150, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 150, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 150, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 150, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 150, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 150, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 75, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 75, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 75, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 75, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 150, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 150, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 150, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 150, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 150, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 150, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 150, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 75, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 75, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 75, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 75, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 150, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 150, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 150, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 150, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 150, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 150, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 150, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 50,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 75,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 75, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 75, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 75, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 75, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 75, 'init': 'uniform', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 75, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 100,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 100,\n",
       "   'init': 'uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 100,\n",
       "   'init': 'uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'init': 'uniform', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'SGD'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adam'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 150,\n",
       "   'init': 'glorot_uniform',\n",
       "   'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 150, 'init': 'normal', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 150, 'init': 'normal', 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 150, 'init': 'normal', 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 150, 'init': 'uniform', 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 150,\n",
       "   'init': 'uniform',\n",
       "   'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 150,\n",
       "   'init': 'uniform',\n",
       "   'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 150, 'init': 'uniform', 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128,\n",
       "   'epochs': 150,\n",
       "   'init': 'uniform',\n",
       "   'optimizer': 'Adamax'}],\n",
       " 'split0_test_score': array([0.6388889 , 0.68055558, 0.65277779, 0.64583331, 0.60416669,\n",
       "        0.68055558, 0.6111111 , 0.66666669, 0.6111111 , 0.66666669,\n",
       "        0.65277779, 0.65972221, 0.6388889 , 0.65277779, 0.6388889 ,\n",
       "        0.65277779, 0.6736111 , 0.68055558, 0.64583331, 0.65277779,\n",
       "        0.70833331, 0.61805558, 0.625     , 0.6875    , 0.7013889 ,\n",
       "        0.70833331, 0.6388889 , 0.65972221, 0.66666669, 0.625     ,\n",
       "        0.6736111 , 0.65972221, 0.71527779, 0.59722221, 0.65972221,\n",
       "        0.7013889 , 0.5625    , 0.59722221, 0.59027779, 0.66666669,\n",
       "        0.65972221, 0.6875    , 0.63194442, 0.65972221, 0.7013889 ,\n",
       "        0.64583331, 0.60416669, 0.65972221, 0.66666669, 0.65277779,\n",
       "        0.65277779, 0.6111111 , 0.63194442, 0.6736111 , 0.64583331,\n",
       "        0.65277779, 0.625     , 0.66666669, 0.65972221, 0.7013889 ,\n",
       "        0.65972221, 0.6875    , 0.6875    , 0.65972221, 0.64583331,\n",
       "        0.65972221, 0.64583331, 0.66666669, 0.68055558, 0.7013889 ,\n",
       "        0.7013889 , 0.59027779, 0.69444442, 0.56944442, 0.6388889 ,\n",
       "        0.64583331, 0.6388889 , 0.6875    , 0.58333331, 0.68055558,\n",
       "        0.65277779, 0.65277779, 0.60416669, 0.5763889 , 0.6736111 ,\n",
       "        0.7013889 , 0.65277779, 0.58333331, 0.6875    , 0.65277779,\n",
       "        0.70833331, 0.66666669, 0.65277779, 0.64583331, 0.6111111 ,\n",
       "        0.6388889 , 0.52083331, 0.65972221, 0.5625    , 0.60416669,\n",
       "        0.63194442, 0.70833331, 0.6111111 , 0.59027779, 0.65277779,\n",
       "        0.65277779, 0.6111111 , 0.625     , 0.65277779, 0.68055558,\n",
       "        0.65277779, 0.59722221, 0.60416669, 0.68055558, 0.6388889 ,\n",
       "        0.66666669, 0.59722221, 0.65277779, 0.63194442, 0.625     ,\n",
       "        0.6111111 , 0.6388889 , 0.5625    , 0.5138889 , 0.7013889 ,\n",
       "        0.6111111 , 0.58333331, 0.64583331, 0.6875    , 0.61805558,\n",
       "        0.6388889 , 0.65277779, 0.5       , 0.6388889 , 0.64583331,\n",
       "        0.65277779, 0.65972221, 0.64583331, 0.66666669, 0.6736111 ,\n",
       "        0.65277779, 0.66666669, 0.71527779, 0.59722221, 0.6736111 ,\n",
       "        0.6875    , 0.69444442, 0.64583331, 0.65277779, 0.63194442,\n",
       "        0.63194442, 0.6875    , 0.65972221, 0.65277779, 0.65277779,\n",
       "        0.66666669, 0.625     , 0.63194442, 0.5763889 , 0.68055558,\n",
       "        0.6388889 , 0.66666669, 0.6875    , 0.65277779, 0.65277779,\n",
       "        0.6875    , 0.65277779, 0.69444442, 0.64583331, 0.69444442,\n",
       "        0.6111111 , 0.56944442, 0.66666669, 0.63194442, 0.64583331,\n",
       "        0.65277779, 0.61805558, 0.625     , 0.65277779, 0.6736111 ,\n",
       "        0.59722221, 0.5       , 0.59027779, 0.54166669, 0.6388889 ,\n",
       "        0.5625    , 0.59722221, 0.2986111 , 0.64583331, 0.5625    ,\n",
       "        0.6388889 , 0.4861111 , 0.35416666, 0.61805558, 0.6111111 ,\n",
       "        0.66666669, 0.7013889 , 0.53472221, 0.625     , 0.54166669,\n",
       "        0.5625    , 0.55555558, 0.63194442, 0.56944442, 0.68055558,\n",
       "        0.56944442, 0.5486111 , 0.40972221, 0.68055558, 0.5486111 ,\n",
       "        0.65972221, 0.71527779, 0.63194442, 0.6388889 , 0.65277779,\n",
       "        0.58333331, 0.7013889 , 0.58333331, 0.68055558, 0.63194442,\n",
       "        0.6875    , 0.59722221, 0.59722221, 0.65972221, 0.63194442,\n",
       "        0.65972221, 0.65972221, 0.64583331, 0.66666669, 0.66666669,\n",
       "        0.63194442, 0.63194442, 0.61805558, 0.64583331, 0.65972221,\n",
       "        0.65277779, 0.65972221, 0.64583331, 0.6875    , 0.6875    ]),\n",
       " 'split1_test_score': array([0.6875    , 0.72916669, 0.69444442, 0.66666669, 0.70833331,\n",
       "        0.7013889 , 0.7013889 , 0.72222221, 0.59027779, 0.65972221,\n",
       "        0.74305558, 0.65277779, 0.7013889 , 0.69444442, 0.68055558,\n",
       "        0.6875    , 0.63194442, 0.65277779, 0.65972221, 0.7361111 ,\n",
       "        0.74305558, 0.61805558, 0.64583331, 0.63194442, 0.72222221,\n",
       "        0.72916669, 0.71527779, 0.6875    , 0.70833331, 0.72916669,\n",
       "        0.6875    , 0.63194442, 0.7013889 , 0.65277779, 0.68055558,\n",
       "        0.71527779, 0.59722221, 0.6875    , 0.7013889 , 0.7013889 ,\n",
       "        0.75694442, 0.65972221, 0.7013889 , 0.6875    , 0.6875    ,\n",
       "        0.625     , 0.71527779, 0.71527779, 0.66666669, 0.7013889 ,\n",
       "        0.66666669, 0.6388889 , 0.72222221, 0.68055558, 0.6736111 ,\n",
       "        0.75694442, 0.6736111 , 0.7361111 , 0.6736111 , 0.65277779,\n",
       "        0.75694442, 0.7361111 , 0.55555558, 0.6875    , 0.65277779,\n",
       "        0.69444442, 0.70833331, 0.6736111 , 0.71527779, 0.69444442,\n",
       "        0.71527779, 0.64583331, 0.69444442, 0.68055558, 0.72916669,\n",
       "        0.6875    , 0.6736111 , 0.7013889 , 0.65277779, 0.75      ,\n",
       "        0.72222221, 0.72222221, 0.6736111 , 0.6875    , 0.65277779,\n",
       "        0.72916669, 0.6875    , 0.6111111 , 0.6875    , 0.7361111 ,\n",
       "        0.72222221, 0.65277779, 0.7013889 , 0.6875    , 0.70833331,\n",
       "        0.71527779, 0.71527779, 0.69444442, 0.61805558, 0.7013889 ,\n",
       "        0.72916669, 0.65972221, 0.69444442, 0.64583331, 0.69444442,\n",
       "        0.69444442, 0.65277779, 0.64583331, 0.65972221, 0.74305558,\n",
       "        0.7013889 , 0.68055558, 0.70833331, 0.66666669, 0.6875    ,\n",
       "        0.72916669, 0.66666669, 0.68055558, 0.65277779, 0.69444442,\n",
       "        0.6736111 , 0.7361111 , 0.65972221, 0.65972221, 0.6875    ,\n",
       "        0.6736111 , 0.70833331, 0.64583331, 0.70833331, 0.66666669,\n",
       "        0.68055558, 0.7013889 , 0.65972221, 0.65277779, 0.6875    ,\n",
       "        0.71527779, 0.59027779, 0.71527779, 0.68055558, 0.72222221,\n",
       "        0.70833331, 0.7361111 , 0.7361111 , 0.69444442, 0.7013889 ,\n",
       "        0.63194442, 0.68055558, 0.6875    , 0.7013889 , 0.72222221,\n",
       "        0.6875    , 0.65277779, 0.68055558, 0.6875    , 0.7013889 ,\n",
       "        0.70833331, 0.64583331, 0.6736111 , 0.70833331, 0.71527779,\n",
       "        0.70833331, 0.6736111 , 0.69444442, 0.69444442, 0.75694442,\n",
       "        0.74305558, 0.65972221, 0.69444442, 0.7013889 , 0.65972221,\n",
       "        0.68055558, 0.64583331, 0.72222221, 0.70833331, 0.71527779,\n",
       "        0.72222221, 0.68055558, 0.72222221, 0.68055558, 0.68055558,\n",
       "        0.64583331, 0.625     , 0.72222221, 0.6736111 , 0.65972221,\n",
       "        0.65277779, 0.60416669, 0.44444445, 0.6875    , 0.58333331,\n",
       "        0.6111111 , 0.52777779, 0.6388889 , 0.50694442, 0.53472221,\n",
       "        0.70833331, 0.65277779, 0.49305555, 0.50694442, 0.4861111 ,\n",
       "        0.6875    , 0.65277779, 0.7013889 , 0.5763889 , 0.5486111 ,\n",
       "        0.69444442, 0.70833331, 0.66666669, 0.70833331, 0.59027779,\n",
       "        0.71527779, 0.6875    , 0.61805558, 0.68055558, 0.64583331,\n",
       "        0.6875    , 0.72916669, 0.5       , 0.71527779, 0.69444442,\n",
       "        0.68055558, 0.66666669, 0.65277779, 0.69444442, 0.65972221,\n",
       "        0.74305558, 0.6388889 , 0.65972221, 0.625     , 0.70833331,\n",
       "        0.61805558, 0.65277779, 0.64583331, 0.68055558, 0.70833331,\n",
       "        0.65972221, 0.5763889 , 0.74305558, 0.70833331, 0.64583331]),\n",
       " 'split2_test_score': array([0.68055558, 0.65277779, 0.63194442, 0.6388889 , 0.65972221,\n",
       "        0.6736111 , 0.44444445, 0.65972221, 0.6111111 , 0.6736111 ,\n",
       "        0.65972221, 0.65972221, 0.71527779, 0.68055558, 0.66666669,\n",
       "        0.68055558, 0.65972221, 0.65277779, 0.63194442, 0.6736111 ,\n",
       "        0.68055558, 0.60416669, 0.71527779, 0.68055558, 0.65972221,\n",
       "        0.69444442, 0.6388889 , 0.6736111 , 0.7013889 , 0.6736111 ,\n",
       "        0.66666669, 0.64583331, 0.68055558, 0.6736111 , 0.6875    ,\n",
       "        0.65972221, 0.6388889 , 0.66666669, 0.68055558, 0.68055558,\n",
       "        0.64583331, 0.625     , 0.72222221, 0.6388889 , 0.66666669,\n",
       "        0.6736111 , 0.65972221, 0.68055558, 0.65277779, 0.6736111 ,\n",
       "        0.65277779, 0.70833331, 0.69444442, 0.65277779, 0.68055558,\n",
       "        0.66666669, 0.66666669, 0.6875    , 0.69444442, 0.6875    ,\n",
       "        0.65277779, 0.6388889 , 0.69444442, 0.68055558, 0.65972221,\n",
       "        0.7013889 , 0.6875    , 0.65972221, 0.68055558, 0.68055558,\n",
       "        0.68055558, 0.6736111 , 0.68055558, 0.6736111 , 0.66666669,\n",
       "        0.63194442, 0.65277779, 0.6388889 , 0.6736111 , 0.69444442,\n",
       "        0.66666669, 0.59722221, 0.6875    , 0.64583331, 0.68055558,\n",
       "        0.6875    , 0.64583331, 0.65277779, 0.6736111 , 0.65277779,\n",
       "        0.64583331, 0.6875    , 0.7013889 , 0.6388889 , 0.68055558,\n",
       "        0.65277779, 0.64583331, 0.66666669, 0.64583331, 0.6875    ,\n",
       "        0.7013889 , 0.64583331, 0.64583331, 0.72222221, 0.71527779,\n",
       "        0.6875    , 0.65972221, 0.68055558, 0.6875    , 0.65277779,\n",
       "        0.68055558, 0.68055558, 0.65277779, 0.68055558, 0.6736111 ,\n",
       "        0.68055558, 0.66666669, 0.68055558, 0.71527779, 0.68055558,\n",
       "        0.68055558, 0.69444442, 0.49305555, 0.59027779, 0.65972221,\n",
       "        0.65277779, 0.66666669, 0.64583331, 0.6388889 , 0.63194442,\n",
       "        0.69444442, 0.68055558, 0.59027779, 0.65972221, 0.72222221,\n",
       "        0.7013889 , 0.65277779, 0.54166669, 0.6736111 , 0.6875    ,\n",
       "        0.70833331, 0.63194442, 0.7013889 , 0.71527779, 0.7013889 ,\n",
       "        0.69444442, 0.65277779, 0.65972221, 0.7013889 , 0.63194442,\n",
       "        0.66666669, 0.72222221, 0.7013889 , 0.69444442, 0.72222221,\n",
       "        0.68055558, 0.69444442, 0.66666669, 0.6875    , 0.66666669,\n",
       "        0.6875    , 0.63194442, 0.65972221, 0.7013889 , 0.69444442,\n",
       "        0.7013889 , 0.66666669, 0.65277779, 0.625     , 0.65277779,\n",
       "        0.71527779, 0.66666669, 0.65277779, 0.65972221, 0.66666669,\n",
       "        0.70833331, 0.65277779, 0.65972221, 0.69444442, 0.6736111 ,\n",
       "        0.55555558, 0.60416669, 0.60416669, 0.66666669, 0.625     ,\n",
       "        0.64583331, 0.66666669, 0.59722221, 0.6875    , 0.6388889 ,\n",
       "        0.52083331, 0.65972221, 0.5       , 0.6736111 , 0.5486111 ,\n",
       "        0.68055558, 0.66666669, 0.65277779, 0.66666669, 0.65277779,\n",
       "        0.65277779, 0.69444442, 0.50694442, 0.66666669, 0.66666669,\n",
       "        0.64583331, 0.6736111 , 0.625     , 0.6875    , 0.65277779,\n",
       "        0.6736111 , 0.68055558, 0.65277779, 0.65277779, 0.65972221,\n",
       "        0.6388889 , 0.6875    , 0.6736111 , 0.6736111 , 0.66666669,\n",
       "        0.68055558, 0.71527779, 0.60416669, 0.6875    , 0.69444442,\n",
       "        0.6875    , 0.64583331, 0.65972221, 0.65277779, 0.64583331,\n",
       "        0.70833331, 0.71527779, 0.68055558, 0.64583331, 0.70833331,\n",
       "        0.6736111 , 0.66666669, 0.7013889 , 0.6875    , 0.65972221]),\n",
       " 'mean_test_score': array([0.66898149, 0.68750002, 0.65972221, 0.65046297, 0.6574074 ,\n",
       "        0.68518519, 0.58564815, 0.68287037, 0.60416667, 0.66666667,\n",
       "        0.68518519, 0.6574074 , 0.68518519, 0.67592593, 0.66203705,\n",
       "        0.67361112, 0.65509258, 0.66203705, 0.64583331, 0.6875    ,\n",
       "        0.71064816, 0.61342595, 0.66203703, 0.66666667, 0.69444444,\n",
       "        0.71064814, 0.66435186, 0.6736111 , 0.69212963, 0.67592593,\n",
       "        0.67592593, 0.64583331, 0.69907409, 0.6412037 , 0.67592593,\n",
       "        0.69212963, 0.59953703, 0.65046297, 0.65740742, 0.68287039,\n",
       "        0.68749998, 0.6574074 , 0.68518517, 0.66203703, 0.68518519,\n",
       "        0.64814814, 0.65972223, 0.68518519, 0.66203705, 0.67592593,\n",
       "        0.65740742, 0.65277777, 0.68287035, 0.66898149, 0.66666667,\n",
       "        0.69212963, 0.6550926 , 0.69675926, 0.67592591, 0.68055556,\n",
       "        0.68981481, 0.6875    , 0.64583333, 0.67592593, 0.65277777,\n",
       "        0.68518517, 0.68055554, 0.66666667, 0.69212965, 0.69212963,\n",
       "        0.69907409, 0.63657407, 0.68981481, 0.6412037 , 0.67824076,\n",
       "        0.65509258, 0.6550926 , 0.67592593, 0.63657407, 0.70833333,\n",
       "        0.68055556, 0.6574074 , 0.6550926 , 0.63657407, 0.66898149,\n",
       "        0.70601853, 0.66203703, 0.61574074, 0.68287037, 0.68055556,\n",
       "        0.69212961, 0.66898149, 0.68518519, 0.6574074 , 0.66666667,\n",
       "        0.66898149, 0.62731481, 0.6736111 , 0.6087963 , 0.66435186,\n",
       "        0.6875    , 0.67129628, 0.65046295, 0.65277777, 0.6875    ,\n",
       "        0.67824074, 0.6412037 , 0.65046297, 0.66666667, 0.69212965,\n",
       "        0.67824076, 0.65277779, 0.6550926 , 0.67592595, 0.66666667,\n",
       "        0.69212965, 0.64351853, 0.67129632, 0.66666667, 0.66666667,\n",
       "        0.6550926 , 0.68981481, 0.57175925, 0.58796297, 0.68287037,\n",
       "        0.64583333, 0.65277777, 0.64583331, 0.67824074, 0.6388889 ,\n",
       "        0.6712963 , 0.67824076, 0.58333333, 0.65046297, 0.68518517,\n",
       "        0.68981483, 0.63425926, 0.63425926, 0.67361112, 0.69444444,\n",
       "        0.68981481, 0.67824074, 0.7175926 , 0.66898147, 0.69212963,\n",
       "        0.67129628, 0.67592593, 0.66435184, 0.68518519, 0.66203701,\n",
       "        0.66203703, 0.6875    , 0.68055556, 0.67824074, 0.69212963,\n",
       "        0.68518519, 0.65509258, 0.6574074 , 0.6574074 , 0.68750002,\n",
       "        0.67824074, 0.6574074 , 0.68055554, 0.68287037, 0.70138888,\n",
       "        0.71064816, 0.65972223, 0.68055554, 0.6574074 , 0.66898147,\n",
       "        0.66898149, 0.62731481, 0.68055556, 0.66666665, 0.67592593,\n",
       "        0.69444444, 0.65046299, 0.66898147, 0.67592593, 0.67592593,\n",
       "        0.59953703, 0.5763889 , 0.6388889 , 0.62731483, 0.6412037 ,\n",
       "        0.62037037, 0.62268519, 0.44675925, 0.6736111 , 0.5949074 ,\n",
       "        0.59027777, 0.55787037, 0.49768518, 0.59953703, 0.56481481,\n",
       "        0.68518519, 0.67361112, 0.56018518, 0.59953703, 0.56018519,\n",
       "        0.63425926, 0.63425926, 0.61342591, 0.60416667, 0.63194446,\n",
       "        0.63657405, 0.64351851, 0.56712963, 0.69212963, 0.59722223,\n",
       "        0.68287037, 0.69444446, 0.63425926, 0.65740742, 0.65277777,\n",
       "        0.63657407, 0.70601853, 0.58564814, 0.68981483, 0.66435184,\n",
       "        0.68287039, 0.65972223, 0.61805556, 0.68055554, 0.66203701,\n",
       "        0.69675926, 0.64814814, 0.65509258, 0.64814816, 0.6736111 ,\n",
       "        0.65277777, 0.66666667, 0.64814816, 0.6574074 , 0.69212961,\n",
       "        0.66203703, 0.63425926, 0.69675926, 0.69444444, 0.66435184]),\n",
       " 'std_test_score': array([0.02146671, 0.03156987, 0.02598373, 0.0118033 , 0.04255734,\n",
       "        0.01180329, 0.10643115, 0.02797001, 0.00982092, 0.00567012,\n",
       "        0.04101863, 0.00327363, 0.03322384, 0.01732247, 0.0173225 ,\n",
       "        0.01500171, 0.0173225 , 0.01309458, 0.01134024, 0.03540985,\n",
       "        0.02556797, 0.00654729, 0.03859568, 0.02471548, 0.02598373,\n",
       "        0.0142695 , 0.03601007, 0.01134024, 0.01822686, 0.04255736,\n",
       "        0.00866124, 0.01134024, 0.01426947, 0.03224164, 0.0118033 ,\n",
       "        0.02360658, 0.03122856, 0.03859568, 0.04822377, 0.01426947,\n",
       "        0.04943091, 0.02556796, 0.03859568, 0.01991279, 0.01426947,\n",
       "        0.01991279, 0.04536092, 0.02291551, 0.00654729, 0.01991279,\n",
       "        0.00654729, 0.04088777, 0.03775349, 0.01180329, 0.01500173,\n",
       "        0.04618039, 0.02146671, 0.02909676, 0.01426947, 0.02044389,\n",
       "        0.04755239, 0.0396908 , 0.06389893, 0.0118033 , 0.00567012,\n",
       "        0.01822687, 0.02598373, 0.00567012, 0.01636821, 0.00866123,\n",
       "        0.01426947, 0.03464497, 0.00654726, 0.05082062, 0.03775349,\n",
       "        0.02360658, 0.01426947, 0.02679592, 0.03859568, 0.03000343,\n",
       "        0.03000342, 0.05113593, 0.03645373, 0.04583099, 0.01180329,\n",
       "        0.0173225 , 0.01822687, 0.02853897, 0.00654729, 0.0392837 ,\n",
       "        0.03322384, 0.01426947, 0.02291549, 0.02146671, 0.04088778,\n",
       "        0.03322384, 0.0804544 , 0.0150017 , 0.03464497, 0.04293341,\n",
       "        0.0408878 , 0.02679592, 0.03417782, 0.05408944, 0.02598373,\n",
       "        0.01822686, 0.02146671, 0.02291551, 0.01500171, 0.03775349,\n",
       "        0.01991279, 0.03928373, 0.04255734, 0.00654729, 0.02044389,\n",
       "        0.02679592, 0.03273644, 0.01309458, 0.03540987, 0.03000343,\n",
       "        0.03122857, 0.03982557, 0.06835566, 0.0595587 , 0.0173225 ,\n",
       "        0.02598373, 0.05196747, 0.        , 0.02909676, 0.02044389,\n",
       "        0.02360656, 0.01991279, 0.06539095, 0.00866124, 0.03122856,\n",
       "        0.02679592, 0.03122855, 0.07134738, 0.00567012, 0.02044389,\n",
       "        0.02618912, 0.04330622, 0.01426947, 0.05144934, 0.01309458,\n",
       "        0.02797002, 0.01732247, 0.0173225 , 0.02291549, 0.04255736,\n",
       "        0.02291551, 0.02835056, 0.01701035, 0.01822686, 0.02909676,\n",
       "        0.01732247, 0.02909676, 0.01822688, 0.05791664, 0.02044389,\n",
       "        0.02909676, 0.01822688, 0.01500171, 0.0214667 , 0.04280842,\n",
       "        0.02360658, 0.00567012, 0.01964184, 0.03224164, 0.01822686,\n",
       "        0.04330623, 0.04179509, 0.03000342, 0.03156987, 0.02909678,\n",
       "        0.03000342, 0.02556796, 0.04022719, 0.01732247, 0.00327366,\n",
       "        0.03689206, 0.05468061, 0.05919773, 0.0606287 , 0.01426947,\n",
       "        0.04101862, 0.03122857, 0.12191846, 0.01964186, 0.03224164,\n",
       "        0.0503971 , 0.0740017 , 0.11624889, 0.06928996, 0.03322384,\n",
       "        0.01732247, 0.02044389, 0.06764649, 0.0676465 , 0.06928996,\n",
       "        0.05268429, 0.05819352, 0.0804544 , 0.04428503, 0.05919775,\n",
       "        0.05144933, 0.06859042, 0.11259618, 0.01180327, 0.04280844,\n",
       "        0.02360658, 0.01500171, 0.01426947, 0.0173225 , 0.00567012,\n",
       "        0.04255736, 0.0173225 , 0.07089533, 0.01822687, 0.02556797,\n",
       "        0.00327363, 0.0484455 , 0.02471547, 0.01500171, 0.02556796,\n",
       "        0.03464499, 0.00866124, 0.00654729, 0.0173225 , 0.02598373,\n",
       "        0.03969079, 0.03540987, 0.02556797, 0.01636823, 0.02291549,\n",
       "        0.00866124, 0.04101862, 0.0398256 , 0.00982092, 0.0173225 ]),\n",
       " 'rank_test_score': array([106,  37, 144, 175, 148,  45, 229,  59, 219, 115,  45, 148,  45,\n",
       "         83, 131,  95, 163, 131, 186,  39,   2, 216, 134, 115,  15,   4,\n",
       "        126,  98,  22,  83,  83, 186,   9, 191,  83,  22, 221, 175, 145,\n",
       "         57,  44, 148,  54, 134,  45, 182, 141,  45, 131,  83, 145, 168,\n",
       "         64, 106, 115,  22, 158,  11,  94,  65,  33,  39, 184,  83, 168,\n",
       "         54,  70, 115,  19,  22,   9, 197,  33, 191,  74, 163, 158,  83,\n",
       "        197,   5,  65, 148, 158, 197, 106,   6, 134, 215,  59,  65,  29,\n",
       "        106,  45, 148, 115, 106, 210,  98, 218, 126,  39, 104, 179, 168,\n",
       "         39,  77, 191, 175, 115,  19,  74, 167, 158,  82, 115,  19, 189,\n",
       "        102, 115, 115, 158,  33, 233, 228,  59, 184, 168, 186,  77, 195,\n",
       "        103,  74, 231, 175,  54,  31, 202, 202,  95,  15,  33,  77,   1,\n",
       "        112,  22, 104,  83, 128,  45, 139, 134,  39,  65,  77,  22,  45,\n",
       "        163, 148, 148,  37,  77, 148,  70,  59,   8,   2, 141,  70, 148,\n",
       "        112, 106, 210,  65, 125,  83,  15, 174, 112,  83,  83, 221, 232,\n",
       "        195, 209, 191, 213, 212, 240,  98, 226, 227, 238, 239, 221, 235,\n",
       "         45,  95, 237, 221, 236, 202, 202, 217, 219, 208, 201, 190, 234,\n",
       "         22, 225,  59,  14, 202, 145, 168, 197,   6, 230,  31, 128,  57,\n",
       "        141, 214,  70, 139,  11, 182, 163, 180,  98, 168, 115, 180, 148,\n",
       "         29, 134, 202,  11,  15, 128], dtype=int32)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
