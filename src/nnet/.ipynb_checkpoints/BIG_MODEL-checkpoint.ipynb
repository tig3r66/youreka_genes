{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# for data scaling and splitting\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "# for neural net\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# for evaluation\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th>classification</th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>TNMD</th>\n",
       "      <th>DPM1</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>C1orf112</th>\n",
       "      <th>FGR</th>\n",
       "      <th>CFH</th>\n",
       "      <th>FUCA2</th>\n",
       "      <th>...</th>\n",
       "      <th>COL15A1</th>\n",
       "      <th>C6orf10</th>\n",
       "      <th>TMEM225</th>\n",
       "      <th>NOTCH4</th>\n",
       "      <th>PBX2</th>\n",
       "      <th>AGER</th>\n",
       "      <th>RNF5</th>\n",
       "      <th>AGPAT1</th>\n",
       "      <th>DFNB59</th>\n",
       "      <th>PRRT1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240121</td>\n",
       "      <td>1</td>\n",
       "      <td>6.419526</td>\n",
       "      <td>3.182094</td>\n",
       "      <td>9.320548</td>\n",
       "      <td>3.759654</td>\n",
       "      <td>3.802619</td>\n",
       "      <td>3.215753</td>\n",
       "      <td>4.698729</td>\n",
       "      <td>7.873672</td>\n",
       "      <td>...</td>\n",
       "      <td>3.245454</td>\n",
       "      <td>2.953508</td>\n",
       "      <td>3.543429</td>\n",
       "      <td>3.352022</td>\n",
       "      <td>4.672310</td>\n",
       "      <td>3.641128</td>\n",
       "      <td>3.135310</td>\n",
       "      <td>3.737072</td>\n",
       "      <td>3.450927</td>\n",
       "      <td>3.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240122</td>\n",
       "      <td>2</td>\n",
       "      <td>7.646494</td>\n",
       "      <td>2.626819</td>\n",
       "      <td>10.153853</td>\n",
       "      <td>3.564755</td>\n",
       "      <td>3.942749</td>\n",
       "      <td>3.290760</td>\n",
       "      <td>3.551675</td>\n",
       "      <td>8.252413</td>\n",
       "      <td>...</td>\n",
       "      <td>2.786709</td>\n",
       "      <td>3.077382</td>\n",
       "      <td>3.728232</td>\n",
       "      <td>3.208882</td>\n",
       "      <td>4.586840</td>\n",
       "      <td>3.395654</td>\n",
       "      <td>3.586800</td>\n",
       "      <td>3.519128</td>\n",
       "      <td>3.115323</td>\n",
       "      <td>3.051645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240123</td>\n",
       "      <td>1</td>\n",
       "      <td>8.319417</td>\n",
       "      <td>3.111183</td>\n",
       "      <td>9.643558</td>\n",
       "      <td>4.757258</td>\n",
       "      <td>3.919757</td>\n",
       "      <td>3.602185</td>\n",
       "      <td>3.329644</td>\n",
       "      <td>9.076950</td>\n",
       "      <td>...</td>\n",
       "      <td>3.459089</td>\n",
       "      <td>3.085394</td>\n",
       "      <td>3.462811</td>\n",
       "      <td>3.339030</td>\n",
       "      <td>4.614897</td>\n",
       "      <td>3.395845</td>\n",
       "      <td>3.419193</td>\n",
       "      <td>3.971646</td>\n",
       "      <td>3.729310</td>\n",
       "      <td>3.320022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240124</td>\n",
       "      <td>1</td>\n",
       "      <td>9.006994</td>\n",
       "      <td>3.028173</td>\n",
       "      <td>9.686700</td>\n",
       "      <td>4.280504</td>\n",
       "      <td>3.147646</td>\n",
       "      <td>3.188881</td>\n",
       "      <td>3.293807</td>\n",
       "      <td>8.678790</td>\n",
       "      <td>...</td>\n",
       "      <td>2.835403</td>\n",
       "      <td>2.960303</td>\n",
       "      <td>3.415083</td>\n",
       "      <td>3.290171</td>\n",
       "      <td>4.770123</td>\n",
       "      <td>3.400821</td>\n",
       "      <td>3.383734</td>\n",
       "      <td>3.798107</td>\n",
       "      <td>2.822404</td>\n",
       "      <td>3.297547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240127</td>\n",
       "      <td>1</td>\n",
       "      <td>7.985676</td>\n",
       "      <td>2.694729</td>\n",
       "      <td>10.676134</td>\n",
       "      <td>4.159685</td>\n",
       "      <td>3.804637</td>\n",
       "      <td>3.481942</td>\n",
       "      <td>3.111261</td>\n",
       "      <td>7.555407</td>\n",
       "      <td>...</td>\n",
       "      <td>2.896523</td>\n",
       "      <td>2.849899</td>\n",
       "      <td>3.480114</td>\n",
       "      <td>3.226128</td>\n",
       "      <td>5.832710</td>\n",
       "      <td>3.612179</td>\n",
       "      <td>3.347095</td>\n",
       "      <td>4.457963</td>\n",
       "      <td>5.198524</td>\n",
       "      <td>4.553586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CELL_LINE_NAME  classification    TSPAN6      TNMD       DPM1     SCYL3  \\\n",
       "0         1240121               1  6.419526  3.182094   9.320548  3.759654   \n",
       "1         1240122               2  7.646494  2.626819  10.153853  3.564755   \n",
       "2         1240123               1  8.319417  3.111183   9.643558  4.757258   \n",
       "3         1240124               1  9.006994  3.028173   9.686700  4.280504   \n",
       "4         1240127               1  7.985676  2.694729  10.676134  4.159685   \n",
       "\n",
       "   C1orf112       FGR       CFH     FUCA2  ...   COL15A1   C6orf10   TMEM225  \\\n",
       "0  3.802619  3.215753  4.698729  7.873672  ...  3.245454  2.953508  3.543429   \n",
       "1  3.942749  3.290760  3.551675  8.252413  ...  2.786709  3.077382  3.728232   \n",
       "2  3.919757  3.602185  3.329644  9.076950  ...  3.459089  3.085394  3.462811   \n",
       "3  3.147646  3.188881  3.293807  8.678790  ...  2.835403  2.960303  3.415083   \n",
       "4  3.804637  3.481942  3.111261  7.555407  ...  2.896523  2.849899  3.480114   \n",
       "\n",
       "     NOTCH4      PBX2      AGER      RNF5    AGPAT1    DFNB59     PRRT1  \n",
       "0  3.352022  4.672310  3.641128  3.135310  3.737072  3.450927  3.168800  \n",
       "1  3.208882  4.586840  3.395654  3.586800  3.519128  3.115323  3.051645  \n",
       "2  3.339030  4.614897  3.395845  3.419193  3.971646  3.729310  3.320022  \n",
       "3  3.290171  4.770123  3.400821  3.383734  3.798107  2.822404  3.297547  \n",
       "4  3.226128  5.832710  3.612179  3.347095  4.457963  5.198524  4.553586  \n",
       "\n",
       "[5 rows x 16383 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/combined_expression.csv\")\n",
    "data['classification'].map({1: 0, 2: 1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving proper columns\n",
    "X = data.drop(columns=['CELL_LINE_NAME', 'classification'])\n",
    "y = data['classification'].values\n",
    "\n",
    "# scaling the data\n",
    "scalar = MinMaxScaler()\n",
    "x_scaled = scalar.fit_transform(X)\n",
    "\n",
    "# splitting data (20% test, 80% train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='rmsprop',init='glorot_uniform', dropout=0.3):\n",
    "    model = Sequential()\n",
    "    # adding layers and adding droplayers to avoid overfitting\n",
    "    hidden_layers = len(X)\n",
    "    model.add(Dense(hidden_layers, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense((hidden_layers*0.5), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense((hidden_layers*0.25), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense((hidden_layers*0.125), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 5ms/sample - loss: 1.5535 - accuracy: 0.5292\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.9236 - accuracy: 0.5965\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.8182 - accuracy: 0.5614\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7311 - accuracy: 0.6257\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7976 - accuracy: 0.5789\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7383 - accuracy: 0.6082\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6959 - accuracy: 0.6228\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7029 - accuracy: 0.5906\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6858 - accuracy: 0.6257\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7001 - accuracy: 0.6053\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6891 - accuracy: 0.6082\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6909 - accuracy: 0.6170\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6590 - accuracy: 0.6433\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6428 - accuracy: 0.6491\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6554 - accuracy: 0.6316\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6752 - accuracy: 0.6170\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6444 - accuracy: 0.6316\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 0.6533 - accuracy: 0.6462\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6267 - accuracy: 0.6374\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 0.6548 - accuracy: 0.6433\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 0.6482 - accuracy: 0.6345\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 0.6543 - accuracy: 0.6491\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6665 - accuracy: 0.6462\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 0.6433 - accuracy: 0.6491\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6621 - accuracy: 0.6433\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6412 - accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 0.6523 - accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6116 - accuracy: 0.6784\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6382 - accuracy: 0.6345\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6550 - accuracy: 0.6433\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6532 - accuracy: 0.6520\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6461 - accuracy: 0.6520\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6177 - accuracy: 0.6784\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6453 - accuracy: 0.6550\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6259 - accuracy: 0.6520\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6432 - accuracy: 0.6637\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6244 - accuracy: 0.6784\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6388 - accuracy: 0.6550\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6058 - accuracy: 0.6637\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6461 - accuracy: 0.6491\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6266 - accuracy: 0.6491\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6255 - accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6217 - accuracy: 0.6550\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6278 - accuracy: 0.6550\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6052 - accuracy: 0.6784\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6150 - accuracy: 0.6550\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5944 - accuracy: 0.6813\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6026 - accuracy: 0.6696\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6050 - accuracy: 0.6813\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6130 - accuracy: 0.6696\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5958 - accuracy: 0.6784\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6091 - accuracy: 0.6754\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6115 - accuracy: 0.6696\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5797 - accuracy: 0.6813\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5924 - accuracy: 0.6608\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5818 - accuracy: 0.6725\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6028 - accuracy: 0.6959\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5993 - accuracy: 0.6754\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5775 - accuracy: 0.6871\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5874 - accuracy: 0.6871\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5886 - accuracy: 0.6842\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5557 - accuracy: 0.6871\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5609 - accuracy: 0.7135\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5841 - accuracy: 0.6871\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5550 - accuracy: 0.6959\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5775 - accuracy: 0.6901\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5631 - accuracy: 0.7076\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5709 - accuracy: 0.6784\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5640 - accuracy: 0.7164\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5375 - accuracy: 0.7076\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5645 - accuracy: 0.6901\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5530 - accuracy: 0.6988\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5434 - accuracy: 0.7047\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5338 - accuracy: 0.6959\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5420 - accuracy: 0.7368\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5368 - accuracy: 0.7193\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5450 - accuracy: 0.7222\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5301 - accuracy: 0.6842\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5187 - accuracy: 0.7135\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5452 - accuracy: 0.7339\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5169 - accuracy: 0.7135\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5184 - accuracy: 0.7047\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5033 - accuracy: 0.7281\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5089 - accuracy: 0.7427\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5028 - accuracy: 0.7544\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4981 - accuracy: 0.7164\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5022 - accuracy: 0.7222\n",
      "Epoch 88/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5151 - accuracy: 0.7339\n",
      "Epoch 89/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4814 - accuracy: 0.7456\n",
      "Epoch 90/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4828 - accuracy: 0.7368\n",
      "Epoch 91/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4797 - accuracy: 0.7456\n",
      "Epoch 92/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4853 - accuracy: 0.7719\n",
      "Epoch 93/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4814 - accuracy: 0.7456\n",
      "Epoch 94/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4659 - accuracy: 0.7690\n",
      "Epoch 95/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4807 - accuracy: 0.7427\n",
      "Epoch 96/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4372 - accuracy: 0.7807\n",
      "Epoch 97/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4551 - accuracy: 0.7632\n",
      "Epoch 98/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4415 - accuracy: 0.7719\n",
      "Epoch 99/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4360 - accuracy: 0.8099\n",
      "Epoch 100/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4382 - accuracy: 0.8070\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.7419 - accuracy: 0.5789\n",
      "Train on 342 samples\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 5ms/sample - loss: 1.0940 - accuracy: 0.6023\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.9997 - accuracy: 0.5936\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.8575 - accuracy: 0.5760\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.8100 - accuracy: 0.5380\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7693 - accuracy: 0.5877\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7082 - accuracy: 0.5848\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7254 - accuracy: 0.5877\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6820 - accuracy: 0.6023\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7006 - accuracy: 0.6023\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6919 - accuracy: 0.6228\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6860 - accuracy: 0.6053\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6695 - accuracy: 0.6111\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6954 - accuracy: 0.6023\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6956 - accuracy: 0.5848\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6736 - accuracy: 0.6316\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7022 - accuracy: 0.5789\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6714 - accuracy: 0.6199\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6653 - accuracy: 0.6053\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6387 - accuracy: 0.6491\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6702 - accuracy: 0.6345\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6624 - accuracy: 0.6199\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6488 - accuracy: 0.6345\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6333 - accuracy: 0.6491\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6633 - accuracy: 0.6228\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6539 - accuracy: 0.6140\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6662 - accuracy: 0.6023\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6553 - accuracy: 0.6374\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6463 - accuracy: 0.6462\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6554 - accuracy: 0.6140\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6317 - accuracy: 0.6608\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6528 - accuracy: 0.6433\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6556 - accuracy: 0.6316\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6676 - accuracy: 0.6404\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6304 - accuracy: 0.6550\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6469 - accuracy: 0.6404\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6245 - accuracy: 0.6608\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6352 - accuracy: 0.6404\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6249 - accuracy: 0.6316\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6310 - accuracy: 0.6725\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6489 - accuracy: 0.6374\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6261 - accuracy: 0.6345\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6339 - accuracy: 0.6550\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6307 - accuracy: 0.6491\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6249 - accuracy: 0.6520\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6320 - accuracy: 0.6696\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6237 - accuracy: 0.6462\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6171 - accuracy: 0.6608\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6160 - accuracy: 0.6520\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6114 - accuracy: 0.6842\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6164 - accuracy: 0.6550\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5943 - accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5983 - accuracy: 0.6462\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5886 - accuracy: 0.6784\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5921 - accuracy: 0.6988\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5936 - accuracy: 0.6842\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5911 - accuracy: 0.6901\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5770 - accuracy: 0.6871\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5832 - accuracy: 0.6871\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5884 - accuracy: 0.6608\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5864 - accuracy: 0.6813\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5765 - accuracy: 0.6842\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5703 - accuracy: 0.6813\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5752 - accuracy: 0.6842\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5701 - accuracy: 0.6725\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5586 - accuracy: 0.6988\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5558 - accuracy: 0.6696\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5467 - accuracy: 0.6930\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5689 - accuracy: 0.7018\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5424 - accuracy: 0.6930\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5492 - accuracy: 0.6959\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5296 - accuracy: 0.7193\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5390 - accuracy: 0.7281\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5349 - accuracy: 0.7251\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5232 - accuracy: 0.7485\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5080 - accuracy: 0.7485\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5159 - accuracy: 0.7251\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5153 - accuracy: 0.7456\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5039 - accuracy: 0.7515\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5123 - accuracy: 0.7573\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4870 - accuracy: 0.7778\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5028 - accuracy: 0.7661\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4970 - accuracy: 0.7602\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4784 - accuracy: 0.7719\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4799 - accuracy: 0.7953\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4868 - accuracy: 0.7778\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4621 - accuracy: 0.7865\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4773 - accuracy: 0.7807\n",
      "Epoch 88/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4509 - accuracy: 0.8158\n",
      "Epoch 89/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4823 - accuracy: 0.7865\n",
      "Epoch 90/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4550 - accuracy: 0.7982\n",
      "Epoch 91/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4423 - accuracy: 0.8099\n",
      "Epoch 92/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4293 - accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4494 - accuracy: 0.8187\n",
      "Epoch 94/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4318 - accuracy: 0.8275\n",
      "Epoch 95/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4293 - accuracy: 0.8246\n",
      "Epoch 96/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4113 - accuracy: 0.8421\n",
      "Epoch 97/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4199 - accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4257 - accuracy: 0.8246\n",
      "Epoch 99/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4144 - accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3850 - accuracy: 0.8216\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.5405 - accuracy: 0.6433\n",
      "Train on 342 samples\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 5ms/sample - loss: 1.3625 - accuracy: 0.5585\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.9974 - accuracy: 0.5789\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.8931 - accuracy: 0.5146\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.8082 - accuracy: 0.5819\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7651 - accuracy: 0.5760\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7292 - accuracy: 0.6082\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7035 - accuracy: 0.5848\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6718 - accuracy: 0.6374\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6798 - accuracy: 0.6082\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6908 - accuracy: 0.6170\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6929 - accuracy: 0.6140\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7057 - accuracy: 0.5936\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6817 - accuracy: 0.6111\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6535 - accuracy: 0.6170\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6888 - accuracy: 0.6053\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6499 - accuracy: 0.6170\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6653 - accuracy: 0.6228\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6635 - accuracy: 0.6579\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6705 - accuracy: 0.6228\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6281 - accuracy: 0.6491\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6475 - accuracy: 0.6111\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6379 - accuracy: 0.6520\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6349 - accuracy: 0.6491\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6258 - accuracy: 0.6316\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6428 - accuracy: 0.6170\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6476 - accuracy: 0.6053\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6113 - accuracy: 0.6550\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6269 - accuracy: 0.6374\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6386 - accuracy: 0.6345\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6373 - accuracy: 0.6491\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6059 - accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6126 - accuracy: 0.6491\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6168 - accuracy: 0.6696\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5988 - accuracy: 0.6404\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6065 - accuracy: 0.6491\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6116 - accuracy: 0.6491\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5881 - accuracy: 0.6637\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5951 - accuracy: 0.7018\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5693 - accuracy: 0.6959\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5968 - accuracy: 0.6842\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5933 - accuracy: 0.6754\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5867 - accuracy: 0.6754\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5786 - accuracy: 0.7018\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5802 - accuracy: 0.6842\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5735 - accuracy: 0.7135\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5737 - accuracy: 0.6930\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5716 - accuracy: 0.6988\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5652 - accuracy: 0.6842\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5659 - accuracy: 0.7164\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5454 - accuracy: 0.6784\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5600 - accuracy: 0.7135\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5393 - accuracy: 0.7047\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5522 - accuracy: 0.7164\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5368 - accuracy: 0.7047\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5213 - accuracy: 0.7456\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5345 - accuracy: 0.7398\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5137 - accuracy: 0.7368\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5150 - accuracy: 0.7515\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5049 - accuracy: 0.7485\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5124 - accuracy: 0.7193\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5217 - accuracy: 0.7515\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4943 - accuracy: 0.7573\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4982 - accuracy: 0.7515\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.5007 - accuracy: 0.7573\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4805 - accuracy: 0.7865\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4934 - accuracy: 0.7749\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4718 - accuracy: 0.7865\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4758 - accuracy: 0.7895\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4851 - accuracy: 0.7719\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4714 - accuracy: 0.8012\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4499 - accuracy: 0.8012\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4520 - accuracy: 0.8216\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4409 - accuracy: 0.8099\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4524 - accuracy: 0.8099\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4393 - accuracy: 0.8129\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4376 - accuracy: 0.8275\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4311 - accuracy: 0.8187\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4260 - accuracy: 0.8275\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4222 - accuracy: 0.8012\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4405 - accuracy: 0.8099\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3907 - accuracy: 0.8275\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4049 - accuracy: 0.8158\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4152 - accuracy: 0.8246\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3872 - accuracy: 0.8421\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4246 - accuracy: 0.8187\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.4060 - accuracy: 0.8363\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3674 - accuracy: 0.8684\n",
      "Epoch 88/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3743 - accuracy: 0.8596\n",
      "Epoch 89/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3635 - accuracy: 0.8596\n",
      "Epoch 90/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3516 - accuracy: 0.8363\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3502 - accuracy: 0.8626\n",
      "Epoch 92/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3470 - accuracy: 0.8655\n",
      "Epoch 93/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3415 - accuracy: 0.8860\n",
      "Epoch 94/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3626 - accuracy: 0.8655\n",
      "Epoch 95/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3135 - accuracy: 0.9035\n",
      "Epoch 96/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3189 - accuracy: 0.8743\n",
      "Epoch 97/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.3087 - accuracy: 0.8860\n",
      "Epoch 98/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.2826 - accuracy: 0.9152\n",
      "Epoch 99/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.2990 - accuracy: 0.8801\n",
      "Epoch 100/100\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.2945 - accuracy: 0.9006\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.8032 - accuracy: 0.5497\n",
      "Baseline Accuracy: 59.06% (3.91%)\n"
     ]
    }
   ],
   "source": [
    "# parameters selected from previous gridsearch\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=32, optimizer='Adagrad',init='uniform')\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Baseline Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 513 samples\n",
      "Epoch 1/100\n",
      "513/513 [==============================] - 2s 4ms/sample - loss: 1.2018 - accuracy: 0.5595\n",
      "Epoch 2/100\n",
      "512/513 [============================>.] - ETA: 0s - loss: 0.8921 - accuracy: 0.5859"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      1.00      0.74        75\n",
      "           2       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.58       129\n",
      "   macro avg       0.29      0.50      0.37       129\n",
      "weighted avg       0.34      0.58      0.43       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75  0]\n",
      " [54  0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/big_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1da58c3af1a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "history.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
