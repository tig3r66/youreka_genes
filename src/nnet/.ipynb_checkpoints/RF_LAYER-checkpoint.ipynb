{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# for data scaling and splitting\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "# for neural net\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# for evaluation\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 16383)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/combined_expression.csv\")\n",
    "data['classification'].map({1: 0, 2: 1})\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes = pd.read_csv('cleaned/rf_genes.csv')\n",
    "selected_genes = selected_genes.values.tolist()\n",
    "selected_genes = list(itertools.chain(*selected_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving proper columns\n",
    "X = data.loc[:, selected_genes]\n",
    "y = data['classification'].values\n",
    "\n",
    "# scaling the data\n",
    "scalar = MinMaxScaler()\n",
    "x_scaled = scalar.fit_transform(X)\n",
    "\n",
    "# splitting data (20% test, 80% train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='rmsprop',init='glorot_uniform', dropout=0.3):\n",
    "    model = Sequential()\n",
    "    # adding layers and adding droplayers to avoid overfitting\n",
    "    hidden_layers = len(selected_genes)\n",
    "    model.add(Dense(hidden_layers, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense((hidden_layers*0.5), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense((hidden_layers*0.25), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 2s 5ms/sample - loss: 0.7368 - accuracy: 0.3743\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.7196 - accuracy: 0.4269\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 72us/sample - loss: 0.7195 - accuracy: 0.4211\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 73us/sample - loss: 0.7014 - accuracy: 0.5029\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 67us/sample - loss: 0.7089 - accuracy: 0.4561\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 69us/sample - loss: 0.6974 - accuracy: 0.5029\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 69us/sample - loss: 0.6982 - accuracy: 0.5175\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6969 - accuracy: 0.5175\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 72us/sample - loss: 0.6978 - accuracy: 0.5117\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 67us/sample - loss: 0.7020 - accuracy: 0.4649\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6935 - accuracy: 0.5292\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6962 - accuracy: 0.5234\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 79us/sample - loss: 0.6903 - accuracy: 0.5526\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6973 - accuracy: 0.4971\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6940 - accuracy: 0.5205\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 66us/sample - loss: 0.6924 - accuracy: 0.5322\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6948 - accuracy: 0.5058\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6840 - accuracy: 0.5585\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6837 - accuracy: 0.5497\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 70us/sample - loss: 0.6885 - accuracy: 0.5380\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 76us/sample - loss: 0.6883 - accuracy: 0.5526\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.6877 - accuracy: 0.5760\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 70us/sample - loss: 0.6822 - accuracy: 0.5497\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6891 - accuracy: 0.5497\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6855 - accuracy: 0.5439\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 66us/sample - loss: 0.6941 - accuracy: 0.5117\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6894 - accuracy: 0.5146\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.6847 - accuracy: 0.5819\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 69us/sample - loss: 0.6860 - accuracy: 0.5731\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 75us/sample - loss: 0.6841 - accuracy: 0.5409\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 73us/sample - loss: 0.6842 - accuracy: 0.5936\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 67us/sample - loss: 0.6825 - accuracy: 0.6023\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6724 - accuracy: 0.5760\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6914 - accuracy: 0.5409\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6785 - accuracy: 0.5789\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6807 - accuracy: 0.5263\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6859 - accuracy: 0.5673\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6724 - accuracy: 0.5936\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 69us/sample - loss: 0.6751 - accuracy: 0.6228\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6831 - accuracy: 0.5585\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6715 - accuracy: 0.5965\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6709 - accuracy: 0.6199\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6761 - accuracy: 0.5936\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6720 - accuracy: 0.6345\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6735 - accuracy: 0.6140\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6646 - accuracy: 0.6287\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6815 - accuracy: 0.5585\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6793 - accuracy: 0.5994\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6743 - accuracy: 0.5994\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6691 - accuracy: 0.6140\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.6741 - accuracy: 0.6257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 1s 4ms/sample - loss: 0.6654 - accuracy: 0.6374\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6644 - accuracy: 0.6053\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6691 - accuracy: 0.6287\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.6605 - accuracy: 0.6023\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 67us/sample - loss: 0.6705 - accuracy: 0.6228\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.7002 - accuracy: 0.5819\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6902 - accuracy: 0.5965\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 66us/sample - loss: 0.6542 - accuracy: 0.6287\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 73us/sample - loss: 0.6796 - accuracy: 0.5877\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 68us/sample - loss: 0.6655 - accuracy: 0.5848\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6800 - accuracy: 0.5848\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6815 - accuracy: 0.5702\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.7002 - accuracy: 0.5760\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6760 - accuracy: 0.5906\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6593 - accuracy: 0.6170\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6623 - accuracy: 0.6140\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6554 - accuracy: 0.6287\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 71us/sample - loss: 0.6607 - accuracy: 0.6053\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 69us/sample - loss: 0.6743 - accuracy: 0.5760\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.6648 - accuracy: 0.6257\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6453 - accuracy: 0.6345\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 70us/sample - loss: 0.6564 - accuracy: 0.6404\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 66us/sample - loss: 0.6789 - accuracy: 0.6170\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6734 - accuracy: 0.6111\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 66us/sample - loss: 0.6708 - accuracy: 0.5877\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 74us/sample - loss: 0.6806 - accuracy: 0.5877\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6673 - accuracy: 0.5789\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6567 - accuracy: 0.6111\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6863 - accuracy: 0.5848\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6712 - accuracy: 0.6257\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6705 - accuracy: 0.6228\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.6656 - accuracy: 0.6023\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6622 - accuracy: 0.6462\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6710 - accuracy: 0.5760\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 72us/sample - loss: 0.6348 - accuracy: 0.6550\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 67us/sample - loss: 0.6633 - accuracy: 0.5965\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6814 - accuracy: 0.5819\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6489 - accuracy: 0.6345\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6674 - accuracy: 0.6257\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6660 - accuracy: 0.6140\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6452 - accuracy: 0.6228\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6737 - accuracy: 0.5965\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6653 - accuracy: 0.6520\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 72us/sample - loss: 0.6566 - accuracy: 0.6140\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 71us/sample - loss: 0.6591 - accuracy: 0.6345\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6653 - accuracy: 0.6053\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6666 - accuracy: 0.6170\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6479 - accuracy: 0.6199\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6682 - accuracy: 0.6023\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6728 - accuracy: 0.6170\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.6226 - accuracy: 0.6959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 0.7154 - accuracy: 0.6257\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.7162 - accuracy: 0.6491\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6798 - accuracy: 0.6374\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6625 - accuracy: 0.6404\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6790 - accuracy: 0.6111\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 67us/sample - loss: 0.6670 - accuracy: 0.6433\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6774 - accuracy: 0.6374\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6776 - accuracy: 0.6140\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6307 - accuracy: 0.6520\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6397 - accuracy: 0.6579\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6507 - accuracy: 0.6608\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6458 - accuracy: 0.6374\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6720 - accuracy: 0.6140\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6598 - accuracy: 0.6404\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6489 - accuracy: 0.6462\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 70us/sample - loss: 0.6714 - accuracy: 0.6257\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6320 - accuracy: 0.6374\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6609 - accuracy: 0.6374\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6346 - accuracy: 0.6345\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6513 - accuracy: 0.6462\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6213 - accuracy: 0.6491\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6588 - accuracy: 0.6550\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6625 - accuracy: 0.6345\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6413 - accuracy: 0.6491\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 69us/sample - loss: 0.6505 - accuracy: 0.6404\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 69us/sample - loss: 0.6503 - accuracy: 0.6140\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6699 - accuracy: 0.6111\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6724 - accuracy: 0.6433\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6362 - accuracy: 0.6462\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6564 - accuracy: 0.6491\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6264 - accuracy: 0.6608\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6432 - accuracy: 0.6462\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6281 - accuracy: 0.6696\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6633 - accuracy: 0.6316\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 69us/sample - loss: 0.6549 - accuracy: 0.6404\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6523 - accuracy: 0.6199\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6516 - accuracy: 0.6433\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6433 - accuracy: 0.6345\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6579 - accuracy: 0.6257\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6337 - accuracy: 0.6667\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6632 - accuracy: 0.6257\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6420 - accuracy: 0.6345\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6351 - accuracy: 0.6667\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6504 - accuracy: 0.6579\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6463 - accuracy: 0.6667\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6494 - accuracy: 0.6520\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6331 - accuracy: 0.6462\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6269 - accuracy: 0.6550\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6530 - accuracy: 0.6491\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6366 - accuracy: 0.6579\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.6372 - accuracy: 0.6608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 66.08% (2.86%)\n"
     ]
    }
   ],
   "source": [
    "# parameters selected from previous gridsearch\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=64, optimizer='Adagrad',init='uniform')\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Baseline Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 513 samples\n",
      "Epoch 1/50\n",
      "513/513 [==============================] - 1s 3ms/sample - loss: 0.6764 - accuracy: 0.6433\n",
      "Epoch 2/50\n",
      "513/513 [==============================] - 0s 63us/sample - loss: 0.6641 - accuracy: 0.6374\n",
      "Epoch 3/50\n",
      "513/513 [==============================] - 0s 62us/sample - loss: 0.6658 - accuracy: 0.6296\n",
      "Epoch 4/50\n",
      "513/513 [==============================] - 0s 69us/sample - loss: 0.6620 - accuracy: 0.6355\n",
      "Epoch 5/50\n",
      "513/513 [==============================] - 0s 64us/sample - loss: 0.6852 - accuracy: 0.6238\n",
      "Epoch 6/50\n",
      "513/513 [==============================] - 0s 60us/sample - loss: 0.6446 - accuracy: 0.6530\n",
      "Epoch 7/50\n",
      "513/513 [==============================] - 0s 64us/sample - loss: 0.6675 - accuracy: 0.6569\n",
      "Epoch 8/50\n",
      "513/513 [==============================] - 0s 60us/sample - loss: 0.6557 - accuracy: 0.6472\n",
      "Epoch 9/50\n",
      "513/513 [==============================] - 0s 58us/sample - loss: 0.6438 - accuracy: 0.6550\n",
      "Epoch 10/50\n",
      "513/513 [==============================] - 0s 63us/sample - loss: 0.6447 - accuracy: 0.6491\n",
      "Epoch 11/50\n",
      "513/513 [==============================] - 0s 57us/sample - loss: 0.6379 - accuracy: 0.6433\n",
      "Epoch 12/50\n",
      "513/513 [==============================] - 0s 56us/sample - loss: 0.6572 - accuracy: 0.6218\n",
      "Epoch 13/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6527 - accuracy: 0.6316\n",
      "Epoch 14/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6437 - accuracy: 0.6550\n",
      "Epoch 15/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6607 - accuracy: 0.6413\n",
      "Epoch 16/50\n",
      "513/513 [==============================] - 0s 50us/sample - loss: 0.6848 - accuracy: 0.6257\n",
      "Epoch 17/50\n",
      "513/513 [==============================] - 0s 62us/sample - loss: 0.6427 - accuracy: 0.6433\n",
      "Epoch 18/50\n",
      "513/513 [==============================] - 0s 59us/sample - loss: 0.6706 - accuracy: 0.6218\n",
      "Epoch 19/50\n",
      "513/513 [==============================] - 0s 53us/sample - loss: 0.6442 - accuracy: 0.6550\n",
      "Epoch 20/50\n",
      "513/513 [==============================] - 0s 55us/sample - loss: 0.6500 - accuracy: 0.6335\n",
      "Epoch 21/50\n",
      "513/513 [==============================] - 0s 51us/sample - loss: 0.6483 - accuracy: 0.6608\n",
      "Epoch 22/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6673 - accuracy: 0.6491\n",
      "Epoch 23/50\n",
      "513/513 [==============================] - 0s 51us/sample - loss: 0.6402 - accuracy: 0.6686\n",
      "Epoch 24/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6417 - accuracy: 0.6569\n",
      "Epoch 25/50\n",
      "513/513 [==============================] - 0s 61us/sample - loss: 0.6731 - accuracy: 0.6433\n",
      "Epoch 26/50\n",
      "513/513 [==============================] - 0s 55us/sample - loss: 0.6502 - accuracy: 0.6589\n",
      "Epoch 27/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6636 - accuracy: 0.6394\n",
      "Epoch 28/50\n",
      "513/513 [==============================] - 0s 53us/sample - loss: 0.6653 - accuracy: 0.6374\n",
      "Epoch 29/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6624 - accuracy: 0.6433\n",
      "Epoch 30/50\n",
      "513/513 [==============================] - 0s 50us/sample - loss: 0.6520 - accuracy: 0.6433\n",
      "Epoch 31/50\n",
      "513/513 [==============================] - 0s 55us/sample - loss: 0.6498 - accuracy: 0.6569\n",
      "Epoch 32/50\n",
      "513/513 [==============================] - 0s 58us/sample - loss: 0.6672 - accuracy: 0.6472\n",
      "Epoch 33/50\n",
      "513/513 [==============================] - 0s 53us/sample - loss: 0.6656 - accuracy: 0.6452\n",
      "Epoch 34/50\n",
      "513/513 [==============================] - 0s 50us/sample - loss: 0.6679 - accuracy: 0.6316\n",
      "Epoch 35/50\n",
      "513/513 [==============================] - 0s 51us/sample - loss: 0.6500 - accuracy: 0.6413\n",
      "Epoch 36/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6507 - accuracy: 0.6491\n",
      "Epoch 37/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6358 - accuracy: 0.6589\n",
      "Epoch 38/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6413 - accuracy: 0.6628\n",
      "Epoch 39/50\n",
      "513/513 [==============================] - 0s 61us/sample - loss: 0.6512 - accuracy: 0.6491\n",
      "Epoch 40/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6585 - accuracy: 0.6472\n",
      "Epoch 41/50\n",
      "513/513 [==============================] - 0s 50us/sample - loss: 0.6435 - accuracy: 0.6511\n",
      "Epoch 42/50\n",
      "513/513 [==============================] - 0s 50us/sample - loss: 0.6646 - accuracy: 0.6550\n",
      "Epoch 43/50\n",
      "513/513 [==============================] - 0s 53us/sample - loss: 0.6504 - accuracy: 0.6433\n",
      "Epoch 44/50\n",
      "513/513 [==============================] - 0s 53us/sample - loss: 0.6491 - accuracy: 0.6628\n",
      "Epoch 45/50\n",
      "513/513 [==============================] - 0s 49us/sample - loss: 0.6602 - accuracy: 0.6452\n",
      "Epoch 46/50\n",
      "513/513 [==============================] - 0s 60us/sample - loss: 0.6410 - accuracy: 0.6491\n",
      "Epoch 47/50\n",
      "513/513 [==============================] - 0s 53us/sample - loss: 0.6686 - accuracy: 0.6433\n",
      "Epoch 48/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6433 - accuracy: 0.6472\n",
      "Epoch 49/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6522 - accuracy: 0.6413\n",
      "Epoch 50/50\n",
      "513/513 [==============================] - 0s 53us/sample - loss: 0.6403 - accuracy: 0.6394\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      1.00      0.74        75\n",
      "           2       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.58       129\n",
      "   macro avg       0.29      0.50      0.37       129\n",
      "weighted avg       0.34      0.58      0.43       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddieguo/anaconda3/envs/fixed_comp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75  0]\n",
      " [54  0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save('models/rf_hidden_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f5db5fbd3b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fixed_comp/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fixed_comp/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \"\"\"\n\u001b[1;32m    775\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 776\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fixed_comp/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    565\u001b[0m                          \u001b[0;34m\"take value in {{0, 1}} or {{-1, 1}} or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                          \"pass pos_label explicitly.\".format(\n\u001b[0;32m--> 567\u001b[0;31m                              classes_repr=classes_repr))\n\u001b[0m\u001b[1;32m    568\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mpos_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "y_pred = y_pred.ravel()\n",
    "fpr, tpr, thresh = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='rmsprop',init='glorot_uniform', dropout=0.3):\n",
    "    model = Sequential()\n",
    "    # adding layers and adding droplayers to avoid overfitting\n",
    "    hidden_layers = len(selected_genes)\n",
    "    model.add(Dense(hidden_layers, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense((hidden_layers*0.5), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 0.6744 - accuracy: 0.6111\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 46us/sample - loss: 0.6630 - accuracy: 0.6579\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6605 - accuracy: 0.6170\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6624 - accuracy: 0.6345\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 71us/sample - loss: 0.6668 - accuracy: 0.6228\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 66us/sample - loss: 0.6525 - accuracy: 0.6696\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6543 - accuracy: 0.6579\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6627 - accuracy: 0.6550\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6448 - accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6476 - accuracy: 0.6550\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6574 - accuracy: 0.6579\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6353 - accuracy: 0.6579\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6569 - accuracy: 0.6842\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 66us/sample - loss: 0.6546 - accuracy: 0.6550\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6549 - accuracy: 0.6608\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6528 - accuracy: 0.6550\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6475 - accuracy: 0.6608\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6380 - accuracy: 0.6637\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6355 - accuracy: 0.6784\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6558 - accuracy: 0.6637\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6432 - accuracy: 0.6637\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6516 - accuracy: 0.6637\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6360 - accuracy: 0.6696\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 67us/sample - loss: 0.6399 - accuracy: 0.6754\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6394 - accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6386 - accuracy: 0.6667\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6428 - accuracy: 0.6696\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6378 - accuracy: 0.6725\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6485 - accuracy: 0.6637\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6315 - accuracy: 0.6667\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6482 - accuracy: 0.6637\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6394 - accuracy: 0.6667\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 68us/sample - loss: 0.6275 - accuracy: 0.6696\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.6419 - accuracy: 0.6725\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6335 - accuracy: 0.6696\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6368 - accuracy: 0.6725\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6421 - accuracy: 0.6696\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6449 - accuracy: 0.6608\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6367 - accuracy: 0.6550\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6332 - accuracy: 0.6637\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6353 - accuracy: 0.6725\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6358 - accuracy: 0.6784\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6249 - accuracy: 0.6667\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6357 - accuracy: 0.6754\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6280 - accuracy: 0.6696\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6315 - accuracy: 0.6725\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6137 - accuracy: 0.6667\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6252 - accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6306 - accuracy: 0.6754\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6277 - accuracy: 0.6696\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.6363 - accuracy: 0.6374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 0.7119 - accuracy: 0.5058\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 48us/sample - loss: 0.6999 - accuracy: 0.5234\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 48us/sample - loss: 0.6913 - accuracy: 0.5292\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 51us/sample - loss: 0.6864 - accuracy: 0.5702\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6855 - accuracy: 0.5585\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6799 - accuracy: 0.6111\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 52us/sample - loss: 0.6640 - accuracy: 0.6111\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 50us/sample - loss: 0.6644 - accuracy: 0.6199\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6592 - accuracy: 0.6023\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6711 - accuracy: 0.5906\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 51us/sample - loss: 0.6542 - accuracy: 0.6345\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6657 - accuracy: 0.6170\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6530 - accuracy: 0.6287\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 49us/sample - loss: 0.6603 - accuracy: 0.6316\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6641 - accuracy: 0.6287\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6561 - accuracy: 0.6199\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6571 - accuracy: 0.6433\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 50us/sample - loss: 0.6512 - accuracy: 0.6345\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6421 - accuracy: 0.6433\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 52us/sample - loss: 0.6560 - accuracy: 0.6374\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 52us/sample - loss: 0.6627 - accuracy: 0.6257\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 51us/sample - loss: 0.6447 - accuracy: 0.6462\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6586 - accuracy: 0.6287\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 50us/sample - loss: 0.6461 - accuracy: 0.6520\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 51us/sample - loss: 0.6454 - accuracy: 0.6491\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.6445 - accuracy: 0.6433\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6511 - accuracy: 0.6637\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6527 - accuracy: 0.6316\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 50us/sample - loss: 0.6373 - accuracy: 0.6491\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6399 - accuracy: 0.6433\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 50us/sample - loss: 0.6426 - accuracy: 0.6491\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 49us/sample - loss: 0.6481 - accuracy: 0.6579\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 49us/sample - loss: 0.6453 - accuracy: 0.6287\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6385 - accuracy: 0.6579\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6496 - accuracy: 0.6462\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6524 - accuracy: 0.6374\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.6649 - accuracy: 0.6462\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6431 - accuracy: 0.6667\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6350 - accuracy: 0.6754\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6545 - accuracy: 0.6345\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6389 - accuracy: 0.6637\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6486 - accuracy: 0.6433\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6508 - accuracy: 0.6667\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6439 - accuracy: 0.6520\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6403 - accuracy: 0.6491\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.6330 - accuracy: 0.6696\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6357 - accuracy: 0.6520\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6493 - accuracy: 0.6374\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6421 - accuracy: 0.6520\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.6360 - accuracy: 0.6433\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.6459 - accuracy: 0.6550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 0.7874 - accuracy: 0.4211\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.7570 - accuracy: 0.4415\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.7264 - accuracy: 0.4591\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.7252 - accuracy: 0.4854\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 76us/sample - loss: 0.6919 - accuracy: 0.5643\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.7108 - accuracy: 0.5058\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6811 - accuracy: 0.5614\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6920 - accuracy: 0.5497\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6841 - accuracy: 0.5673\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 51us/sample - loss: 0.6838 - accuracy: 0.5760\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6575 - accuracy: 0.6257\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6887 - accuracy: 0.5205\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 52us/sample - loss: 0.6794 - accuracy: 0.5760\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6893 - accuracy: 0.5789\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 72us/sample - loss: 0.6850 - accuracy: 0.5936\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6751 - accuracy: 0.5906\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6688 - accuracy: 0.5877\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6668 - accuracy: 0.6111\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6717 - accuracy: 0.6053\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6810 - accuracy: 0.5789\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6574 - accuracy: 0.5906\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 52us/sample - loss: 0.6501 - accuracy: 0.6140\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 51us/sample - loss: 0.6745 - accuracy: 0.6111\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.6681 - accuracy: 0.6053\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 0.6698 - accuracy: 0.5936\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6644 - accuracy: 0.6023\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6751 - accuracy: 0.5936\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6698 - accuracy: 0.6199\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6735 - accuracy: 0.6170\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6722 - accuracy: 0.6228\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6444 - accuracy: 0.6082\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6585 - accuracy: 0.6082\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 54us/sample - loss: 0.6686 - accuracy: 0.6316\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6607 - accuracy: 0.6287\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 0.6661 - accuracy: 0.6257\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6662 - accuracy: 0.6111\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6516 - accuracy: 0.6345\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6738 - accuracy: 0.6140\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 57us/sample - loss: 0.6771 - accuracy: 0.6199\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 55us/sample - loss: 0.6487 - accuracy: 0.6228\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6640 - accuracy: 0.6082\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 52us/sample - loss: 0.6895 - accuracy: 0.6023\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 49us/sample - loss: 0.6784 - accuracy: 0.5819\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.6734 - accuracy: 0.5906\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.6653 - accuracy: 0.6053\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.6712 - accuracy: 0.6257\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6547 - accuracy: 0.6520\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 56us/sample - loss: 0.6572 - accuracy: 0.6316\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 53us/sample - loss: 0.6527 - accuracy: 0.6228\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 51us/sample - loss: 0.6371 - accuracy: 0.6433\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.6003 - accuracy: 0.6901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 66.08% (2.19%)\n"
     ]
    }
   ],
   "source": [
    "# parameters selected from previous gridsearch\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=64, optimizer='Adagrad',init='uniform')\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Baseline Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 513 samples\n",
      "Epoch 1/50\n",
      "513/513 [==============================] - 1s 2ms/sample - loss: 0.7078 - accuracy: 0.4932\n",
      "Epoch 2/50\n",
      "513/513 [==============================] - 0s 46us/sample - loss: 0.6885 - accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "513/513 [==============================] - 0s 45us/sample - loss: 0.6773 - accuracy: 0.5750\n",
      "Epoch 4/50\n",
      "513/513 [==============================] - 0s 48us/sample - loss: 0.6681 - accuracy: 0.6101\n",
      "Epoch 5/50\n",
      "513/513 [==============================] - 0s 56us/sample - loss: 0.6646 - accuracy: 0.6082\n",
      "Epoch 6/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6699 - accuracy: 0.5712\n",
      "Epoch 7/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6589 - accuracy: 0.5926\n",
      "Epoch 8/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6653 - accuracy: 0.5789\n",
      "Epoch 9/50\n",
      "513/513 [==============================] - 0s 49us/sample - loss: 0.6752 - accuracy: 0.5906\n",
      "Epoch 10/50\n",
      "513/513 [==============================] - 0s 49us/sample - loss: 0.6785 - accuracy: 0.5731\n",
      "Epoch 11/50\n",
      "513/513 [==============================] - 0s 47us/sample - loss: 0.6673 - accuracy: 0.6082\n",
      "Epoch 12/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6720 - accuracy: 0.5926\n",
      "Epoch 13/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6603 - accuracy: 0.6082\n",
      "Epoch 14/50\n",
      "513/513 [==============================] - 0s 48us/sample - loss: 0.6502 - accuracy: 0.6296\n",
      "Epoch 15/50\n",
      "513/513 [==============================] - 0s 48us/sample - loss: 0.6624 - accuracy: 0.6023\n",
      "Epoch 16/50\n",
      "513/513 [==============================] - 0s 55us/sample - loss: 0.6485 - accuracy: 0.6413\n",
      "Epoch 17/50\n",
      "513/513 [==============================] - 0s 50us/sample - loss: 0.6475 - accuracy: 0.6433\n",
      "Epoch 18/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6524 - accuracy: 0.6238\n",
      "Epoch 19/50\n",
      "513/513 [==============================] - 0s 51us/sample - loss: 0.6511 - accuracy: 0.6316\n",
      "Epoch 20/50\n",
      "513/513 [==============================] - 0s 53us/sample - loss: 0.6604 - accuracy: 0.6062\n",
      "Epoch 21/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6497 - accuracy: 0.6296\n",
      "Epoch 22/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6668 - accuracy: 0.6101\n",
      "Epoch 23/50\n",
      "513/513 [==============================] - 0s 53us/sample - loss: 0.6618 - accuracy: 0.6179\n",
      "Epoch 24/50\n",
      "513/513 [==============================] - 0s 47us/sample - loss: 0.6588 - accuracy: 0.6199\n",
      "Epoch 25/50\n",
      "513/513 [==============================] - 0s 49us/sample - loss: 0.6558 - accuracy: 0.6355\n",
      "Epoch 26/50\n",
      "513/513 [==============================] - 0s 50us/sample - loss: 0.6504 - accuracy: 0.6530\n",
      "Epoch 27/50\n",
      "513/513 [==============================] - 0s 56us/sample - loss: 0.6485 - accuracy: 0.6530\n",
      "Epoch 28/50\n",
      "513/513 [==============================] - 0s 59us/sample - loss: 0.6455 - accuracy: 0.6316\n",
      "Epoch 29/50\n",
      "513/513 [==============================] - 0s 53us/sample - loss: 0.6572 - accuracy: 0.6296\n",
      "Epoch 30/50\n",
      "513/513 [==============================] - 0s 57us/sample - loss: 0.6404 - accuracy: 0.6296\n",
      "Epoch 31/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6625 - accuracy: 0.6140\n",
      "Epoch 32/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6596 - accuracy: 0.6218\n",
      "Epoch 33/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6595 - accuracy: 0.6316\n",
      "Epoch 34/50\n",
      "513/513 [==============================] - 0s 60us/sample - loss: 0.6524 - accuracy: 0.6335\n",
      "Epoch 35/50\n",
      "513/513 [==============================] - 0s 60us/sample - loss: 0.6424 - accuracy: 0.6511\n",
      "Epoch 36/50\n",
      "513/513 [==============================] - 0s 53us/sample - loss: 0.6373 - accuracy: 0.6550\n",
      "Epoch 37/50\n",
      "513/513 [==============================] - 0s 54us/sample - loss: 0.6462 - accuracy: 0.6530\n",
      "Epoch 38/50\n",
      "513/513 [==============================] - 0s 48us/sample - loss: 0.6456 - accuracy: 0.6491\n",
      "Epoch 39/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6422 - accuracy: 0.6394\n",
      "Epoch 40/50\n",
      "513/513 [==============================] - 0s 47us/sample - loss: 0.6469 - accuracy: 0.6413\n",
      "Epoch 41/50\n",
      "513/513 [==============================] - 0s 59us/sample - loss: 0.6514 - accuracy: 0.6355\n",
      "Epoch 42/50\n",
      "513/513 [==============================] - 0s 60us/sample - loss: 0.6486 - accuracy: 0.6511\n",
      "Epoch 43/50\n",
      "513/513 [==============================] - 0s 52us/sample - loss: 0.6472 - accuracy: 0.6472\n",
      "Epoch 44/50\n",
      "513/513 [==============================] - 0s 50us/sample - loss: 0.6588 - accuracy: 0.6218\n",
      "Epoch 45/50\n",
      "513/513 [==============================] - 0s 48us/sample - loss: 0.6464 - accuracy: 0.6413\n",
      "Epoch 46/50\n",
      "513/513 [==============================] - 0s 44us/sample - loss: 0.6474 - accuracy: 0.6550\n",
      "Epoch 47/50\n",
      "513/513 [==============================] - 0s 49us/sample - loss: 0.6422 - accuracy: 0.6511\n",
      "Epoch 48/50\n",
      "513/513 [==============================] - 0s 51us/sample - loss: 0.6391 - accuracy: 0.6842\n",
      "Epoch 49/50\n",
      "513/513 [==============================] - 0s 55us/sample - loss: 0.6566 - accuracy: 0.6316\n",
      "Epoch 50/50\n",
      "513/513 [==============================] - 0s 50us/sample - loss: 0.6400 - accuracy: 0.6511\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      1.00      0.74        75\n",
      "           2       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.58       129\n",
      "   macro avg       0.29      0.50      0.37       129\n",
      "weighted avg       0.34      0.58      0.43       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75  0]\n",
      " [54  0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save('models/hidden_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='rmsprop',init='glorot_uniform', dropout=0.3):\n",
    "    model = Sequential()\n",
    "    # adding layers and adding droplayers to avoid overfitting\n",
    "    hidden_layers = len(selected_genes)\n",
    "    model.add(Dense(hidden_layers, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.7090 - accuracy: 0.5614\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 98us/sample - loss: 0.6379 - accuracy: 0.6579\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 98us/sample - loss: 0.6177 - accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 97us/sample - loss: 0.6061 - accuracy: 0.6608\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5950 - accuracy: 0.6725\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 99us/sample - loss: 0.6000 - accuracy: 0.6754\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 100us/sample - loss: 0.5826 - accuracy: 0.7105\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 100us/sample - loss: 0.5896 - accuracy: 0.6813\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 97us/sample - loss: 0.5772 - accuracy: 0.6813\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 98us/sample - loss: 0.5540 - accuracy: 0.6988\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 99us/sample - loss: 0.5702 - accuracy: 0.7193\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 100us/sample - loss: 0.5623 - accuracy: 0.7281\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 99us/sample - loss: 0.5608 - accuracy: 0.6988\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5464 - accuracy: 0.7076\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 101us/sample - loss: 0.5525 - accuracy: 0.7018\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5546 - accuracy: 0.7310\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 101us/sample - loss: 0.5402 - accuracy: 0.7193\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5548 - accuracy: 0.7076\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 101us/sample - loss: 0.5429 - accuracy: 0.7135\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5352 - accuracy: 0.7281\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 100us/sample - loss: 0.5267 - accuracy: 0.7368\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5427 - accuracy: 0.7251\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5480 - accuracy: 0.7222\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5438 - accuracy: 0.7164\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5390 - accuracy: 0.7222\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5324 - accuracy: 0.7310\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5239 - accuracy: 0.7690\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5257 - accuracy: 0.7398\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5234 - accuracy: 0.7193\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5287 - accuracy: 0.7339\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5344 - accuracy: 0.7368\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5233 - accuracy: 0.7515\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5168 - accuracy: 0.7339\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5194 - accuracy: 0.7251\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5304 - accuracy: 0.7427\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5250 - accuracy: 0.7485\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 101us/sample - loss: 0.5253 - accuracy: 0.7661\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5249 - accuracy: 0.7339\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 99us/sample - loss: 0.5128 - accuracy: 0.7573\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5142 - accuracy: 0.7368\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5018 - accuracy: 0.7749\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5084 - accuracy: 0.7719\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 100us/sample - loss: 0.5112 - accuracy: 0.7281\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5095 - accuracy: 0.7515\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5187 - accuracy: 0.7515\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5062 - accuracy: 0.7661\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5082 - accuracy: 0.7749\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5067 - accuracy: 0.7749\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5085 - accuracy: 0.7427\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.4884 - accuracy: 0.7544\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.6003 - accuracy: 0.7310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 0.6836 - accuracy: 0.6023\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 97us/sample - loss: 0.6214 - accuracy: 0.6784\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 101us/sample - loss: 0.6072 - accuracy: 0.6871\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.6039 - accuracy: 0.6842\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5949 - accuracy: 0.6813\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5951 - accuracy: 0.6842\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 99us/sample - loss: 0.5769 - accuracy: 0.6842\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5672 - accuracy: 0.7251\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5640 - accuracy: 0.6988\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5769 - accuracy: 0.7105\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5739 - accuracy: 0.6959\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5658 - accuracy: 0.7339\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5496 - accuracy: 0.7251\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5416 - accuracy: 0.7398\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5441 - accuracy: 0.7456\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5430 - accuracy: 0.7251\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5348 - accuracy: 0.7544\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5455 - accuracy: 0.7368\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5389 - accuracy: 0.7573\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5503 - accuracy: 0.7281\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 117us/sample - loss: 0.5345 - accuracy: 0.7456\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 108us/sample - loss: 0.5155 - accuracy: 0.7544\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5301 - accuracy: 0.7222\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5347 - accuracy: 0.7485\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5383 - accuracy: 0.7515\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5207 - accuracy: 0.7515\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.5388 - accuracy: 0.7398\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5233 - accuracy: 0.7485\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 101us/sample - loss: 0.5337 - accuracy: 0.7427\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5184 - accuracy: 0.7602\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5218 - accuracy: 0.7485\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 109us/sample - loss: 0.5377 - accuracy: 0.7339\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 156us/sample - loss: 0.5080 - accuracy: 0.7749\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 117us/sample - loss: 0.5178 - accuracy: 0.7515\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 109us/sample - loss: 0.5109 - accuracy: 0.7690\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5343 - accuracy: 0.7544\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5139 - accuracy: 0.7544\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5072 - accuracy: 0.7690\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5238 - accuracy: 0.7427\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5062 - accuracy: 0.7661\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 138us/sample - loss: 0.5174 - accuracy: 0.7281\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 127us/sample - loss: 0.5091 - accuracy: 0.7573\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 122us/sample - loss: 0.5068 - accuracy: 0.7632\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5089 - accuracy: 0.7544\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 114us/sample - loss: 0.4967 - accuracy: 0.7778\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 110us/sample - loss: 0.4955 - accuracy: 0.7719\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5112 - accuracy: 0.7515\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 109us/sample - loss: 0.5082 - accuracy: 0.7485\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 111us/sample - loss: 0.5157 - accuracy: 0.7632\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 108us/sample - loss: 0.5004 - accuracy: 0.7661\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.5687 - accuracy: 0.6901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 1s 3ms/sample - loss: 0.6816 - accuracy: 0.5702\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 96us/sample - loss: 0.6308 - accuracy: 0.6520\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 102us/sample - loss: 0.6148 - accuracy: 0.6462\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 100us/sample - loss: 0.6082 - accuracy: 0.6901\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.6147 - accuracy: 0.6637\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5963 - accuracy: 0.6754\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5871 - accuracy: 0.6813\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5919 - accuracy: 0.6930\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5736 - accuracy: 0.7018\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5783 - accuracy: 0.7076\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5837 - accuracy: 0.6754\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5587 - accuracy: 0.7076\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5696 - accuracy: 0.7047\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5661 - accuracy: 0.7281\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5660 - accuracy: 0.7164\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 104us/sample - loss: 0.5689 - accuracy: 0.7164\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5591 - accuracy: 0.7018\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5454 - accuracy: 0.7368\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5573 - accuracy: 0.7339\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 109us/sample - loss: 0.5535 - accuracy: 0.7251\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 109us/sample - loss: 0.5486 - accuracy: 0.7427\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 108us/sample - loss: 0.5452 - accuracy: 0.7339\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 106us/sample - loss: 0.5498 - accuracy: 0.7602\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5391 - accuracy: 0.7485\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5375 - accuracy: 0.7310\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 109us/sample - loss: 0.5411 - accuracy: 0.7778\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 110us/sample - loss: 0.5394 - accuracy: 0.7368\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 110us/sample - loss: 0.5396 - accuracy: 0.7398\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 111us/sample - loss: 0.5452 - accuracy: 0.7339\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 111us/sample - loss: 0.5294 - accuracy: 0.7544\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 108us/sample - loss: 0.5299 - accuracy: 0.7544\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 108us/sample - loss: 0.5435 - accuracy: 0.7368\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 111us/sample - loss: 0.5456 - accuracy: 0.7836\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 111us/sample - loss: 0.5334 - accuracy: 0.7427\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 114us/sample - loss: 0.5497 - accuracy: 0.7222\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5364 - accuracy: 0.7544\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 109us/sample - loss: 0.5239 - accuracy: 0.7632\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 108us/sample - loss: 0.5300 - accuracy: 0.7544\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 109us/sample - loss: 0.5306 - accuracy: 0.7515\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 108us/sample - loss: 0.5280 - accuracy: 0.7485\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 109us/sample - loss: 0.5414 - accuracy: 0.7368\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 105us/sample - loss: 0.5198 - accuracy: 0.7602\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 103us/sample - loss: 0.5214 - accuracy: 0.7485\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 107us/sample - loss: 0.5188 - accuracy: 0.7661\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 108us/sample - loss: 0.5289 - accuracy: 0.7602\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 115us/sample - loss: 0.5179 - accuracy: 0.7690\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 108us/sample - loss: 0.5234 - accuracy: 0.7602\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 109us/sample - loss: 0.5258 - accuracy: 0.7602\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 109us/sample - loss: 0.5093 - accuracy: 0.7924\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 110us/sample - loss: 0.5145 - accuracy: 0.7719\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.4851 - accuracy: 0.7251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 71.54% (1.81%)\n"
     ]
    }
   ],
   "source": [
    "# parameters selected from previous gridsearch\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=64, optimizer='Adagrad',init='uniform')\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Baseline Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 513 samples\n",
      "Epoch 1/50\n",
      "513/513 [==============================] - 1s 1ms/sample - loss: 0.6378 - accuracy: 0.6550\n",
      "Epoch 2/50\n",
      "513/513 [==============================] - 0s 108us/sample - loss: 0.6064 - accuracy: 0.6764\n",
      "Epoch 3/50\n",
      "513/513 [==============================] - 0s 109us/sample - loss: 0.6049 - accuracy: 0.6803\n",
      "Epoch 4/50\n",
      "513/513 [==============================] - 0s 111us/sample - loss: 0.5766 - accuracy: 0.6940\n",
      "Epoch 5/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5789 - accuracy: 0.7037\n",
      "Epoch 6/50\n",
      "513/513 [==============================] - 0s 104us/sample - loss: 0.5901 - accuracy: 0.6803\n",
      "Epoch 7/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5871 - accuracy: 0.7251\n",
      "Epoch 8/50\n",
      "513/513 [==============================] - 0s 105us/sample - loss: 0.5732 - accuracy: 0.6940\n",
      "Epoch 9/50\n",
      "513/513 [==============================] - 0s 106us/sample - loss: 0.5794 - accuracy: 0.6979\n",
      "Epoch 10/50\n",
      "513/513 [==============================] - 0s 102us/sample - loss: 0.5679 - accuracy: 0.7076\n",
      "Epoch 11/50\n",
      "513/513 [==============================] - 0s 101us/sample - loss: 0.5629 - accuracy: 0.7076\n",
      "Epoch 12/50\n",
      "513/513 [==============================] - 0s 102us/sample - loss: 0.5552 - accuracy: 0.7096\n",
      "Epoch 13/50\n",
      "513/513 [==============================] - 0s 111us/sample - loss: 0.5729 - accuracy: 0.7115\n",
      "Epoch 14/50\n",
      "513/513 [==============================] - 0s 102us/sample - loss: 0.5562 - accuracy: 0.7251\n",
      "Epoch 15/50\n",
      "513/513 [==============================] - 0s 101us/sample - loss: 0.5710 - accuracy: 0.7115\n",
      "Epoch 16/50\n",
      "513/513 [==============================] - 0s 105us/sample - loss: 0.5651 - accuracy: 0.7154\n",
      "Epoch 17/50\n",
      "513/513 [==============================] - 0s 107us/sample - loss: 0.5573 - accuracy: 0.7310\n",
      "Epoch 18/50\n",
      "513/513 [==============================] - 0s 107us/sample - loss: 0.5643 - accuracy: 0.7290\n",
      "Epoch 19/50\n",
      "513/513 [==============================] - 0s 105us/sample - loss: 0.5555 - accuracy: 0.7212\n",
      "Epoch 20/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5563 - accuracy: 0.7427\n",
      "Epoch 21/50\n",
      "513/513 [==============================] - 0s 104us/sample - loss: 0.5674 - accuracy: 0.7290\n",
      "Epoch 22/50\n",
      "513/513 [==============================] - 0s 104us/sample - loss: 0.5620 - accuracy: 0.7115\n",
      "Epoch 23/50\n",
      "513/513 [==============================] - 0s 106us/sample - loss: 0.5564 - accuracy: 0.7427\n",
      "Epoch 24/50\n",
      "513/513 [==============================] - 0s 104us/sample - loss: 0.5525 - accuracy: 0.7388\n",
      "Epoch 25/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5361 - accuracy: 0.7427\n",
      "Epoch 26/50\n",
      "513/513 [==============================] - 0s 102us/sample - loss: 0.5602 - accuracy: 0.7310\n",
      "Epoch 27/50\n",
      "513/513 [==============================] - 0s 104us/sample - loss: 0.5547 - accuracy: 0.7232\n",
      "Epoch 28/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5360 - accuracy: 0.7368\n",
      "Epoch 29/50\n",
      "513/513 [==============================] - 0s 104us/sample - loss: 0.5535 - accuracy: 0.7310\n",
      "Epoch 30/50\n",
      "513/513 [==============================] - 0s 102us/sample - loss: 0.5439 - accuracy: 0.7251\n",
      "Epoch 31/50\n",
      "513/513 [==============================] - 0s 102us/sample - loss: 0.5406 - accuracy: 0.7446\n",
      "Epoch 32/50\n",
      "513/513 [==============================] - 0s 102us/sample - loss: 0.5494 - accuracy: 0.7349\n",
      "Epoch 33/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5374 - accuracy: 0.7641\n",
      "Epoch 34/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5392 - accuracy: 0.7290\n",
      "Epoch 35/50\n",
      "513/513 [==============================] - 0s 104us/sample - loss: 0.5496 - accuracy: 0.7212\n",
      "Epoch 36/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5459 - accuracy: 0.7310\n",
      "Epoch 37/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5514 - accuracy: 0.7310\n",
      "Epoch 38/50\n",
      "513/513 [==============================] - 0s 101us/sample - loss: 0.5399 - accuracy: 0.7290\n",
      "Epoch 39/50\n",
      "513/513 [==============================] - 0s 107us/sample - loss: 0.5411 - accuracy: 0.7388\n",
      "Epoch 40/50\n",
      "513/513 [==============================] - 0s 107us/sample - loss: 0.5440 - accuracy: 0.7310\n",
      "Epoch 41/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5363 - accuracy: 0.7329\n",
      "Epoch 42/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5458 - accuracy: 0.7310\n",
      "Epoch 43/50\n",
      "513/513 [==============================] - 0s 102us/sample - loss: 0.5334 - accuracy: 0.7505\n",
      "Epoch 44/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5398 - accuracy: 0.7271\n",
      "Epoch 45/50\n",
      "513/513 [==============================] - 0s 103us/sample - loss: 0.5287 - accuracy: 0.7368\n",
      "Epoch 46/50\n",
      "513/513 [==============================] - 0s 112us/sample - loss: 0.5370 - accuracy: 0.7407\n",
      "Epoch 47/50\n",
      "513/513 [==============================] - 0s 112us/sample - loss: 0.5459 - accuracy: 0.7329\n",
      "Epoch 48/50\n",
      "513/513 [==============================] - 0s 105us/sample - loss: 0.5412 - accuracy: 0.7485\n",
      "Epoch 49/50\n",
      "513/513 [==============================] - 0s 102us/sample - loss: 0.5395 - accuracy: 0.7485\n",
      "Epoch 50/50\n",
      "513/513 [==============================] - 0s 106us/sample - loss: 0.5336 - accuracy: 0.7485\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.93      0.78        75\n",
      "           2       0.79      0.35      0.49        54\n",
      "\n",
      "    accuracy                           0.69       129\n",
      "   macro avg       0.73      0.64      0.63       129\n",
      "weighted avg       0.72      0.69      0.66       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70  5]\n",
      " [35 19]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save('models/hidden_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
