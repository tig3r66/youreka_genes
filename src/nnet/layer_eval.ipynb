{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# for data scaling and splitting\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "# for neural net\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# for evaluation\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 16383)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/combined_expression.csv\")\n",
    "data['classification'].map({1: 0, 2: 1})\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes = pd.read_csv('cleaned/boruta-99-25-0.01.csv')\n",
    "selected_genes = selected_genes.values.tolist()\n",
    "selected_genes = list(itertools.chain(*selected_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving proper columns\n",
    "X = data.loc[:, selected_genes]\n",
    "y = data['classification'].values\n",
    "\n",
    "# scaling the data\n",
    "scalar = MinMaxScaler()\n",
    "x_scaled = scalar.fit_transform(X)\n",
    "\n",
    "# splitting data (20% test, 80% train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Hidden Layers (with batch normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "def create_model(optimizer='rmsprop',init='glorot_uniform', dropout=0.3):\n",
    "    model = Sequential()\n",
    "    # adding layers and adding droplayers to avoid overfitting\n",
    "    hidden_layers = len(selected_genes)\n",
    "    model.add(Dense(hidden_layers, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense((hidden_layers*1.45), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense((hidden_layers), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense((hidden_layers*0.5), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters selected from previous gridsearch\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=32, optimizer='Adam',init='normal')\n",
    "# kfold = KFold(n_splits=3, shuffle=True)\n",
    "# results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "# print(\"Baseline Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 513 samples, validate on 129 samples\n",
      "Epoch 1/50\n",
      "513/513 [==============================] - 3s 6ms/sample - loss: 0.8948 - accuracy: 0.5517 - val_loss: 0.7883 - val_accuracy: 0.0078\n",
      "Epoch 2/50\n",
      "513/513 [==============================] - 0s 695us/sample - loss: 0.7368 - accuracy: 0.6452 - val_loss: 1.2587 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "513/513 [==============================] - 0s 704us/sample - loss: 0.6504 - accuracy: 0.6745 - val_loss: 1.5341 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "513/513 [==============================] - 0s 719us/sample - loss: 0.5423 - accuracy: 0.7661 - val_loss: 1.7003 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "513/513 [==============================] - 0s 730us/sample - loss: 0.5093 - accuracy: 0.7329 - val_loss: 2.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "513/513 [==============================] - 0s 717us/sample - loss: 0.5019 - accuracy: 0.7680 - val_loss: 1.8673 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "513/513 [==============================] - 0s 723us/sample - loss: 0.4333 - accuracy: 0.7856 - val_loss: 1.7492 - val_accuracy: 0.0078\n",
      "Epoch 8/50\n",
      "513/513 [==============================] - 0s 723us/sample - loss: 0.4302 - accuracy: 0.8012 - val_loss: 2.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "513/513 [==============================] - 0s 728us/sample - loss: 0.3773 - accuracy: 0.8382 - val_loss: 2.0017 - val_accuracy: 0.0155\n",
      "Epoch 10/50\n",
      "513/513 [==============================] - 0s 775us/sample - loss: 0.3191 - accuracy: 0.8655 - val_loss: 2.2261 - val_accuracy: 0.0155\n",
      "Epoch 11/50\n",
      "513/513 [==============================] - 0s 745us/sample - loss: 0.3316 - accuracy: 0.8441 - val_loss: 3.0612 - val_accuracy: 0.0155\n",
      "Epoch 12/50\n",
      "513/513 [==============================] - 0s 748us/sample - loss: 0.3309 - accuracy: 0.8538 - val_loss: 2.6334 - val_accuracy: 0.0233\n",
      "Epoch 13/50\n",
      "513/513 [==============================] - 0s 779us/sample - loss: 0.2824 - accuracy: 0.8752 - val_loss: 2.6955 - val_accuracy: 0.0233\n",
      "Epoch 14/50\n",
      "513/513 [==============================] - 0s 758us/sample - loss: 0.2359 - accuracy: 0.9006 - val_loss: 2.6391 - val_accuracy: 0.0233\n",
      "Epoch 15/50\n",
      "513/513 [==============================] - 0s 753us/sample - loss: 0.2531 - accuracy: 0.8889 - val_loss: 2.3974 - val_accuracy: 0.0310\n",
      "Epoch 16/50\n",
      "513/513 [==============================] - 0s 754us/sample - loss: 0.2174 - accuracy: 0.9279 - val_loss: 2.3902 - val_accuracy: 0.0543\n",
      "Epoch 17/50\n",
      "513/513 [==============================] - 0s 760us/sample - loss: 0.2163 - accuracy: 0.9045 - val_loss: 3.1348 - val_accuracy: 0.0465\n",
      "Epoch 18/50\n",
      "513/513 [==============================] - 0s 769us/sample - loss: 0.2127 - accuracy: 0.9201 - val_loss: 3.4923 - val_accuracy: 0.0388\n",
      "Epoch 19/50\n",
      "513/513 [==============================] - 0s 769us/sample - loss: 0.1843 - accuracy: 0.9123 - val_loss: 3.2377 - val_accuracy: 0.0465\n",
      "Epoch 20/50\n",
      "513/513 [==============================] - 0s 774us/sample - loss: 0.1740 - accuracy: 0.9396 - val_loss: 3.1773 - val_accuracy: 0.0620\n",
      "Epoch 21/50\n",
      "513/513 [==============================] - 0s 777us/sample - loss: 0.1788 - accuracy: 0.9220 - val_loss: 2.2559 - val_accuracy: 0.1008\n",
      "Epoch 22/50\n",
      "513/513 [==============================] - 0s 771us/sample - loss: 0.1925 - accuracy: 0.9259 - val_loss: 0.5132 - val_accuracy: 0.1938\n",
      "Epoch 23/50\n",
      "513/513 [==============================] - 0s 777us/sample - loss: 0.1787 - accuracy: 0.9337 - val_loss: 0.2880 - val_accuracy: 0.2636\n",
      "Epoch 24/50\n",
      "513/513 [==============================] - 0s 785us/sample - loss: 0.1734 - accuracy: 0.9318 - val_loss: 0.7251 - val_accuracy: 0.2016\n",
      "Epoch 25/50\n",
      "513/513 [==============================] - 0s 792us/sample - loss: 0.1822 - accuracy: 0.9220 - val_loss: 0.2887 - val_accuracy: 0.2481\n",
      "Epoch 26/50\n",
      "513/513 [==============================] - 0s 767us/sample - loss: 0.1160 - accuracy: 0.9571 - val_loss: 1.1652 - val_accuracy: 0.1628\n",
      "Epoch 27/50\n",
      " 32/513 [>.............................] - ETA: 0s - loss: 0.0982 - accuracy: 0.9375"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test,y_test))\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test', 'loss'], loc='upper right')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(optimizer='rmsprop',init='glorot_uniform', dropout=0.3):\n",
    "    model = Sequential()\n",
    "    # adding layers and adding droplayers to avoid overfitting\n",
    "    hidden_layers = len(selected_genes)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(hidden_layers*1.5, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense((hidden_layers), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense((hidden_layers*0.5), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 2s 6ms/sample - loss: 0.7389 - accuracy: 0.5994\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 464us/sample - loss: 0.5929 - accuracy: 0.7018\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 480us/sample - loss: 0.4636 - accuracy: 0.7632\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 467us/sample - loss: 0.4055 - accuracy: 0.8012\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 468us/sample - loss: 0.3572 - accuracy: 0.8392\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 501us/sample - loss: 0.3484 - accuracy: 0.8596\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 475us/sample - loss: 0.2708 - accuracy: 0.9035\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 485us/sample - loss: 0.2027 - accuracy: 0.9240\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 485us/sample - loss: 0.2312 - accuracy: 0.9035\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 492us/sample - loss: 0.1432 - accuracy: 0.9444\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 501us/sample - loss: 0.1670 - accuracy: 0.9444\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 476us/sample - loss: 0.1608 - accuracy: 0.9503\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 480us/sample - loss: 0.1567 - accuracy: 0.9357\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 481us/sample - loss: 0.1419 - accuracy: 0.9444\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 473us/sample - loss: 0.0818 - accuracy: 0.9591\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 476us/sample - loss: 0.0832 - accuracy: 0.9649\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 469us/sample - loss: 0.0448 - accuracy: 0.9912\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 480us/sample - loss: 0.0769 - accuracy: 0.9825\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 506us/sample - loss: 0.0554 - accuracy: 0.9766\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 510us/sample - loss: 0.0984 - accuracy: 0.9591\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 529us/sample - loss: 0.0936 - accuracy: 0.9561\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 509us/sample - loss: 0.0802 - accuracy: 0.9737\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 542us/sample - loss: 0.0375 - accuracy: 0.9883\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 518us/sample - loss: 0.0466 - accuracy: 0.9825\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 531us/sample - loss: 0.0303 - accuracy: 0.9912\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 513us/sample - loss: 0.0592 - accuracy: 0.9708\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 514us/sample - loss: 0.0381 - accuracy: 0.9795\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 516us/sample - loss: 0.0250 - accuracy: 0.9971\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 519us/sample - loss: 0.0352 - accuracy: 0.9854\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 518us/sample - loss: 0.0432 - accuracy: 0.9883\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 518us/sample - loss: 0.0375 - accuracy: 0.9883\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 511us/sample - loss: 0.0328 - accuracy: 0.9854\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 524us/sample - loss: 0.0202 - accuracy: 0.9912\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 529us/sample - loss: 0.0189 - accuracy: 0.9912\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 519us/sample - loss: 0.0340 - accuracy: 0.9883\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 515us/sample - loss: 0.0604 - accuracy: 0.9766\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 516us/sample - loss: 0.0419 - accuracy: 0.9795\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 526us/sample - loss: 0.0275 - accuracy: 0.9912\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 516us/sample - loss: 0.0229 - accuracy: 0.9912\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 516us/sample - loss: 0.0528 - accuracy: 0.9766\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 514us/sample - loss: 0.0135 - accuracy: 0.9942\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 520us/sample - loss: 0.0430 - accuracy: 0.9825\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 520us/sample - loss: 0.0375 - accuracy: 0.9854\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 518us/sample - loss: 0.0759 - accuracy: 0.9766\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 512us/sample - loss: 0.0669 - accuracy: 0.9825\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 514us/sample - loss: 0.1112 - accuracy: 0.9737\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 518us/sample - loss: 0.0558 - accuracy: 0.9795\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 502us/sample - loss: 0.0391 - accuracy: 0.9883\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 510us/sample - loss: 0.0251 - accuracy: 0.9912\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 525us/sample - loss: 0.0178 - accuracy: 0.9971\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.2002 - accuracy: 0.8304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 2s 6ms/sample - loss: 0.7837 - accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 469us/sample - loss: 0.5597 - accuracy: 0.7222\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 480us/sample - loss: 0.4896 - accuracy: 0.7602\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 487us/sample - loss: 0.3924 - accuracy: 0.8070\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 487us/sample - loss: 0.3704 - accuracy: 0.8421\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 497us/sample - loss: 0.3633 - accuracy: 0.8099\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 463us/sample - loss: 0.2470 - accuracy: 0.9035\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 459us/sample - loss: 0.2729 - accuracy: 0.9006\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 493us/sample - loss: 0.1914 - accuracy: 0.9152\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 477us/sample - loss: 0.1535 - accuracy: 0.9415\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 491us/sample - loss: 0.1285 - accuracy: 0.9591\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 508us/sample - loss: 0.1377 - accuracy: 0.9444\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 524us/sample - loss: 0.1049 - accuracy: 0.9649\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 492us/sample - loss: 0.1291 - accuracy: 0.9591\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 500us/sample - loss: 0.0876 - accuracy: 0.9825\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 473us/sample - loss: 0.0713 - accuracy: 0.9825\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 484us/sample - loss: 0.0793 - accuracy: 0.9649\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 492us/sample - loss: 0.0520 - accuracy: 0.9795\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 501us/sample - loss: 0.0547 - accuracy: 0.9766\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 518us/sample - loss: 0.0679 - accuracy: 0.9766\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 513us/sample - loss: 0.0666 - accuracy: 0.9854\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 533us/sample - loss: 0.0565 - accuracy: 0.9795\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 557us/sample - loss: 0.0333 - accuracy: 0.9942\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 513us/sample - loss: 0.0280 - accuracy: 0.9942\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 551us/sample - loss: 0.0298 - accuracy: 0.9912\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 565us/sample - loss: 0.0356 - accuracy: 0.9854\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 530us/sample - loss: 0.0386 - accuracy: 0.9854\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 535us/sample - loss: 0.0121 - accuracy: 0.9971\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 525us/sample - loss: 0.0192 - accuracy: 0.9942\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 527us/sample - loss: 0.0269 - accuracy: 0.9854\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 510us/sample - loss: 0.0220 - accuracy: 0.9942\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 523us/sample - loss: 0.0419 - accuracy: 0.9854\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 525us/sample - loss: 0.0208 - accuracy: 0.9912\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 566us/sample - loss: 0.0312 - accuracy: 0.9912\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 584us/sample - loss: 0.0253 - accuracy: 0.9912\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 539us/sample - loss: 0.0435 - accuracy: 0.9825\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 537us/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 568us/sample - loss: 0.0284 - accuracy: 0.9883\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 555us/sample - loss: 0.0303 - accuracy: 0.9912\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 541us/sample - loss: 0.0409 - accuracy: 0.9912\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 518us/sample - loss: 0.0246 - accuracy: 0.9942\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 513us/sample - loss: 0.0189 - accuracy: 0.9883\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 512us/sample - loss: 0.0464 - accuracy: 0.9854\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 513us/sample - loss: 0.0239 - accuracy: 0.9883\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 509us/sample - loss: 0.0115 - accuracy: 0.9971\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 543us/sample - loss: 0.0133 - accuracy: 0.9971\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 572us/sample - loss: 0.0086 - accuracy: 0.9971\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 547us/sample - loss: 0.0111 - accuracy: 0.9971\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 553us/sample - loss: 0.0334 - accuracy: 0.9912\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 508us/sample - loss: 0.0427 - accuracy: 0.9825\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 2.9908 - accuracy: 0.7193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 2s 6ms/sample - loss: 0.6606 - accuracy: 0.6287\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 0s 449us/sample - loss: 0.4696 - accuracy: 0.7982\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 0s 464us/sample - loss: 0.4042 - accuracy: 0.8070\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 0s 464us/sample - loss: 0.3635 - accuracy: 0.8567\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 0s 462us/sample - loss: 0.2600 - accuracy: 0.8918\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 0s 471us/sample - loss: 0.2628 - accuracy: 0.8889\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 0s 470us/sample - loss: 0.1995 - accuracy: 0.9211\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 0s 477us/sample - loss: 0.1757 - accuracy: 0.9444\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 0s 470us/sample - loss: 0.1711 - accuracy: 0.9386\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 0s 460us/sample - loss: 0.1374 - accuracy: 0.9532\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 0s 457us/sample - loss: 0.1014 - accuracy: 0.9620\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 0s 460us/sample - loss: 0.0785 - accuracy: 0.9678\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 0s 474us/sample - loss: 0.1007 - accuracy: 0.9620\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 0s 472us/sample - loss: 0.0654 - accuracy: 0.9766\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 0s 468us/sample - loss: 0.0816 - accuracy: 0.9678\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 0s 494us/sample - loss: 0.0630 - accuracy: 0.9737\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 0s 521us/sample - loss: 0.0486 - accuracy: 0.9854\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 0s 522us/sample - loss: 0.1006 - accuracy: 0.9444\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 0s 518us/sample - loss: 0.0693 - accuracy: 0.9766\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 0s 525us/sample - loss: 0.0576 - accuracy: 0.9795\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 0s 510us/sample - loss: 0.0299 - accuracy: 0.9912\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 0s 510us/sample - loss: 0.0590 - accuracy: 0.9825\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 0s 507us/sample - loss: 0.0218 - accuracy: 0.9971\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 0s 512us/sample - loss: 0.0653 - accuracy: 0.9795\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 0s 512us/sample - loss: 0.0180 - accuracy: 0.9971\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 0s 527us/sample - loss: 0.0203 - accuracy: 0.9942\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 0s 516us/sample - loss: 0.0321 - accuracy: 0.9883\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 0s 514us/sample - loss: 0.0389 - accuracy: 0.9825\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 0s 523us/sample - loss: 0.0174 - accuracy: 0.9912\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 0s 526us/sample - loss: 0.0324 - accuracy: 0.9912\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 0s 524us/sample - loss: 0.0582 - accuracy: 0.9825\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 0s 518us/sample - loss: 0.0908 - accuracy: 0.9620\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 0s 517us/sample - loss: 0.0362 - accuracy: 0.9912\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 0s 528us/sample - loss: 0.0261 - accuracy: 0.9912\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 0s 518us/sample - loss: 0.0474 - accuracy: 0.9795\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 0s 527us/sample - loss: 0.0274 - accuracy: 0.9942\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 0s 517us/sample - loss: 0.0272 - accuracy: 0.9854\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 0s 523us/sample - loss: 0.0241 - accuracy: 0.9883\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 0s 519us/sample - loss: 0.0376 - accuracy: 0.9825\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 0s 515us/sample - loss: 0.0251 - accuracy: 0.9971\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 0s 507us/sample - loss: 0.0294 - accuracy: 0.9883\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 0s 513us/sample - loss: 0.0345 - accuracy: 0.9883\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 0s 522us/sample - loss: 0.0141 - accuracy: 0.9942\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 0s 526us/sample - loss: 0.0411 - accuracy: 0.9825\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 0s 520us/sample - loss: 0.0170 - accuracy: 0.9912\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 0s 520us/sample - loss: 0.0121 - accuracy: 0.9971\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 0s 525us/sample - loss: 0.0130 - accuracy: 0.9942\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 0s 513us/sample - loss: 0.0352 - accuracy: 0.9883\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 0s 508us/sample - loss: 0.0268 - accuracy: 0.9942\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 0s 545us/sample - loss: 0.0241 - accuracy: 0.9912\n",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 2.6538 - accuracy: 0.6316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 72.71% (8.14%)\n"
     ]
    }
   ],
   "source": [
    "# parameters selected from previous gridsearch\n",
    "model = KerasClassifier(build_fn=create_model2, epochs=50, batch_size=32, optimizer='Adam', init='normal')\n",
    "# kfold = KFold(n_splits=3, shuffle=True)\n",
    "# results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "# print(\"Baseline Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 513 samples, validate on 129 samples\n",
      "Epoch 1/50\n",
      "513/513 [==============================] - 2s 4ms/sample - loss: 0.7397 - accuracy: 0.6335 - val_loss: 0.8388 - val_accuracy: 0.0310\n",
      "Epoch 2/50\n",
      "513/513 [==============================] - 0s 566us/sample - loss: 0.5176 - accuracy: 0.7329 - val_loss: 1.0511 - val_accuracy: 0.0078\n",
      "Epoch 3/50\n",
      "513/513 [==============================] - 0s 580us/sample - loss: 0.4778 - accuracy: 0.7934 - val_loss: 1.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "513/513 [==============================] - 0s 579us/sample - loss: 0.4146 - accuracy: 0.8031 - val_loss: 1.5053 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "513/513 [==============================] - 0s 602us/sample - loss: 0.3314 - accuracy: 0.8694 - val_loss: 1.6903 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "513/513 [==============================] - 0s 603us/sample - loss: 0.2967 - accuracy: 0.8635 - val_loss: 1.9582 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "513/513 [==============================] - 0s 644us/sample - loss: 0.2362 - accuracy: 0.9064 - val_loss: 2.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "513/513 [==============================] - 0s 653us/sample - loss: 0.2276 - accuracy: 0.9064 - val_loss: 3.0965 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "513/513 [==============================] - 0s 669us/sample - loss: 0.2118 - accuracy: 0.9084 - val_loss: 3.4960 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "513/513 [==============================] - 0s 680us/sample - loss: 0.1794 - accuracy: 0.9298 - val_loss: 4.5132 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "513/513 [==============================] - 0s 661us/sample - loss: 0.1552 - accuracy: 0.9376 - val_loss: 5.2403 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "513/513 [==============================] - 0s 658us/sample - loss: 0.1278 - accuracy: 0.9532 - val_loss: 5.6818 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "513/513 [==============================] - 0s 662us/sample - loss: 0.1314 - accuracy: 0.9571 - val_loss: 6.1068 - val_accuracy: 0.0078\n",
      "Epoch 14/50\n",
      "513/513 [==============================] - 0s 669us/sample - loss: 0.0988 - accuracy: 0.9708 - val_loss: 6.2672 - val_accuracy: 0.0078\n",
      "Epoch 15/50\n",
      "513/513 [==============================] - 0s 680us/sample - loss: 0.0712 - accuracy: 0.9747 - val_loss: 6.8018 - val_accuracy: 0.0078\n",
      "Epoch 16/50\n",
      "513/513 [==============================] - 0s 674us/sample - loss: 0.1116 - accuracy: 0.9493 - val_loss: 7.0745 - val_accuracy: 0.0078\n",
      "Epoch 17/50\n",
      "513/513 [==============================] - 0s 681us/sample - loss: 0.0550 - accuracy: 0.9766 - val_loss: 6.8055 - val_accuracy: 0.0078\n",
      "Epoch 18/50\n",
      "513/513 [==============================] - 0s 661us/sample - loss: 0.0875 - accuracy: 0.9649 - val_loss: 6.2981 - val_accuracy: 0.0233\n",
      "Epoch 19/50\n",
      "513/513 [==============================] - 0s 676us/sample - loss: 0.0550 - accuracy: 0.9805 - val_loss: 6.4027 - val_accuracy: 0.0233\n",
      "Epoch 20/50\n",
      "513/513 [==============================] - 0s 684us/sample - loss: 0.0924 - accuracy: 0.9688 - val_loss: 6.1869 - val_accuracy: 0.0233\n",
      "Epoch 21/50\n",
      "513/513 [==============================] - 0s 689us/sample - loss: 0.0619 - accuracy: 0.9747 - val_loss: 6.2502 - val_accuracy: 0.0155\n",
      "Epoch 22/50\n",
      "513/513 [==============================] - 0s 673us/sample - loss: 0.0609 - accuracy: 0.9786 - val_loss: 6.4550 - val_accuracy: 0.0310\n",
      "Epoch 23/50\n",
      "513/513 [==============================] - 0s 671us/sample - loss: 0.0700 - accuracy: 0.9688 - val_loss: 6.6009 - val_accuracy: 0.0233\n",
      "Epoch 24/50\n",
      "513/513 [==============================] - 0s 666us/sample - loss: 0.0597 - accuracy: 0.9825 - val_loss: 6.6874 - val_accuracy: 0.0310\n",
      "Epoch 25/50\n",
      "513/513 [==============================] - 0s 670us/sample - loss: 0.0981 - accuracy: 0.9669 - val_loss: 6.7629 - val_accuracy: 0.0388\n",
      "Epoch 26/50\n",
      "513/513 [==============================] - 0s 669us/sample - loss: 0.0503 - accuracy: 0.9825 - val_loss: 6.0652 - val_accuracy: 0.0310\n",
      "Epoch 27/50\n",
      "513/513 [==============================] - 0s 674us/sample - loss: 0.0682 - accuracy: 0.9727 - val_loss: 6.0678 - val_accuracy: 0.0543\n",
      "Epoch 28/50\n",
      "513/513 [==============================] - 0s 683us/sample - loss: 0.0741 - accuracy: 0.9747 - val_loss: 5.7552 - val_accuracy: 0.0388\n",
      "Epoch 29/50\n",
      "513/513 [==============================] - 0s 668us/sample - loss: 0.0568 - accuracy: 0.9805 - val_loss: 5.3824 - val_accuracy: 0.0698\n",
      "Epoch 30/50\n",
      "513/513 [==============================] - 0s 672us/sample - loss: 0.0740 - accuracy: 0.9727 - val_loss: 4.6451 - val_accuracy: 0.0775\n",
      "Epoch 31/50\n",
      "513/513 [==============================] - 0s 667us/sample - loss: 0.0633 - accuracy: 0.9766 - val_loss: 4.0914 - val_accuracy: 0.1240\n",
      "Epoch 32/50\n",
      "513/513 [==============================] - 0s 665us/sample - loss: 0.0458 - accuracy: 0.9844 - val_loss: 4.7163 - val_accuracy: 0.0465\n",
      "Epoch 33/50\n",
      "513/513 [==============================] - 0s 664us/sample - loss: 0.0636 - accuracy: 0.9708 - val_loss: 4.3473 - val_accuracy: 0.0853\n",
      "Epoch 34/50\n",
      "513/513 [==============================] - 0s 673us/sample - loss: 0.0378 - accuracy: 0.9883 - val_loss: 4.4781 - val_accuracy: 0.0698\n",
      "Epoch 35/50\n",
      "513/513 [==============================] - 0s 665us/sample - loss: 0.0311 - accuracy: 0.9864 - val_loss: 4.9273 - val_accuracy: 0.0543\n",
      "Epoch 36/50\n",
      "513/513 [==============================] - 0s 660us/sample - loss: 0.0540 - accuracy: 0.9805 - val_loss: 5.3348 - val_accuracy: 0.0543\n",
      "Epoch 37/50\n",
      "513/513 [==============================] - 0s 646us/sample - loss: 0.0232 - accuracy: 0.9942 - val_loss: 4.6483 - val_accuracy: 0.0775\n",
      "Epoch 38/50\n",
      "513/513 [==============================] - 0s 686us/sample - loss: 0.0196 - accuracy: 0.9942 - val_loss: 4.4737 - val_accuracy: 0.0543\n",
      "Epoch 39/50\n",
      "513/513 [==============================] - 0s 694us/sample - loss: 0.0207 - accuracy: 0.9961 - val_loss: 4.1519 - val_accuracy: 0.0543\n",
      "Epoch 40/50\n",
      "513/513 [==============================] - 0s 665us/sample - loss: 0.0231 - accuracy: 0.9903 - val_loss: 4.0560 - val_accuracy: 0.0853\n",
      "Epoch 41/50\n",
      "513/513 [==============================] - 0s 667us/sample - loss: 0.0290 - accuracy: 0.9883 - val_loss: 4.3305 - val_accuracy: 0.0698\n",
      "Epoch 42/50\n",
      "513/513 [==============================] - 0s 658us/sample - loss: 0.0348 - accuracy: 0.9883 - val_loss: 4.7342 - val_accuracy: 0.0620\n",
      "Epoch 43/50\n",
      "513/513 [==============================] - 0s 676us/sample - loss: 0.0336 - accuracy: 0.9903 - val_loss: 5.1363 - val_accuracy: 0.0543\n",
      "Epoch 44/50\n",
      "513/513 [==============================] - 0s 667us/sample - loss: 0.0391 - accuracy: 0.9786 - val_loss: 5.0473 - val_accuracy: 0.0775\n",
      "Epoch 45/50\n",
      "513/513 [==============================] - 0s 643us/sample - loss: 0.0243 - accuracy: 0.9922 - val_loss: 4.6712 - val_accuracy: 0.1085\n",
      "Epoch 46/50\n",
      "513/513 [==============================] - 0s 642us/sample - loss: 0.0478 - accuracy: 0.9766 - val_loss: 4.7384 - val_accuracy: 0.0543\n",
      "Epoch 47/50\n",
      "513/513 [==============================] - 0s 660us/sample - loss: 0.0194 - accuracy: 0.9922 - val_loss: 4.4037 - val_accuracy: 0.0543\n",
      "Epoch 48/50\n",
      "513/513 [==============================] - 0s 645us/sample - loss: 0.0243 - accuracy: 0.9883 - val_loss: 4.4295 - val_accuracy: 0.0465\n",
      "Epoch 49/50\n",
      "513/513 [==============================] - 0s 646us/sample - loss: 0.0223 - accuracy: 0.9922 - val_loss: 4.3053 - val_accuracy: 0.0698\n",
      "Epoch 50/50\n",
      "513/513 [==============================] - 0s 666us/sample - loss: 0.0262 - accuracy: 0.9903 - val_loss: 3.9318 - val_accuracy: 0.0543\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), shuffle=True)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.90      0.77        67\n",
      "           2       0.83      0.55      0.66        62\n",
      "\n",
      "    accuracy                           0.73       129\n",
      "   macro avg       0.76      0.72      0.72       129\n",
      "weighted avg       0.75      0.73      0.72       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60  7]\n",
      " [28 34]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test', 'loss'], loc='upper right')\n",
    "plt.xlim(0, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='rmsprop',init='glorot_uniform', dropout=0.3):\n",
    "    model = Sequential()\n",
    "    # adding layers and adding droplayers to avoid overfitting\n",
    "    hidden_layers = len(selected_genes)\n",
    "    model.add(Dense(hidden_layers*1.5, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense((hidden_layers), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters selected from previous gridsearch\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=32, optimizer='Adamax',init='uniform')\n",
    "# kfold = KFold(n_splits=3, shuffle=True)\n",
    "# results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "# print(\"Baseline Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 513 samples\n",
      "Epoch 1/50\n",
      "513/513 [==============================] - 2s 3ms/sample - loss: 0.8869 - accuracy: 0.5906\n",
      "Epoch 2/50\n",
      "513/513 [==============================] - 0s 344us/sample - loss: 0.6353 - accuracy: 0.6940\n",
      "Epoch 3/50\n",
      "513/513 [==============================] - 0s 344us/sample - loss: 0.5967 - accuracy: 0.7407\n",
      "Epoch 4/50\n",
      "513/513 [==============================] - 0s 347us/sample - loss: 0.5564 - accuracy: 0.7212\n",
      "Epoch 5/50\n",
      "513/513 [==============================] - 0s 346us/sample - loss: 0.5398 - accuracy: 0.7524\n",
      "Epoch 6/50\n",
      "513/513 [==============================] - 0s 362us/sample - loss: 0.4925 - accuracy: 0.7739\n",
      "Epoch 7/50\n",
      "513/513 [==============================] - 0s 349us/sample - loss: 0.4582 - accuracy: 0.7895\n",
      "Epoch 8/50\n",
      "513/513 [==============================] - 0s 346us/sample - loss: 0.4838 - accuracy: 0.7680\n",
      "Epoch 9/50\n",
      "513/513 [==============================] - 0s 357us/sample - loss: 0.4234 - accuracy: 0.8109\n",
      "Epoch 10/50\n",
      "513/513 [==============================] - 0s 349us/sample - loss: 0.4246 - accuracy: 0.7856\n",
      "Epoch 11/50\n",
      "513/513 [==============================] - 0s 347us/sample - loss: 0.4108 - accuracy: 0.8148\n",
      "Epoch 12/50\n",
      "513/513 [==============================] - 0s 346us/sample - loss: 0.3599 - accuracy: 0.8460\n",
      "Epoch 13/50\n",
      "513/513 [==============================] - 0s 345us/sample - loss: 0.3887 - accuracy: 0.8265\n",
      "Epoch 14/50\n",
      "513/513 [==============================] - 0s 343us/sample - loss: 0.3599 - accuracy: 0.8460\n",
      "Epoch 15/50\n",
      "513/513 [==============================] - 0s 346us/sample - loss: 0.3737 - accuracy: 0.8596\n",
      "Epoch 16/50\n",
      "513/513 [==============================] - 0s 344us/sample - loss: 0.3828 - accuracy: 0.8207\n",
      "Epoch 17/50\n",
      "513/513 [==============================] - 0s 354us/sample - loss: 0.3230 - accuracy: 0.8694\n",
      "Epoch 18/50\n",
      "513/513 [==============================] - 0s 349us/sample - loss: 0.3110 - accuracy: 0.8616\n",
      "Epoch 19/50\n",
      "513/513 [==============================] - 0s 357us/sample - loss: 0.3095 - accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "513/513 [==============================] - 0s 354us/sample - loss: 0.3083 - accuracy: 0.8577\n",
      "Epoch 21/50\n",
      "513/513 [==============================] - 0s 360us/sample - loss: 0.2633 - accuracy: 0.8967\n",
      "Epoch 22/50\n",
      "513/513 [==============================] - 0s 350us/sample - loss: 0.2477 - accuracy: 0.9006\n",
      "Epoch 23/50\n",
      "513/513 [==============================] - 0s 359us/sample - loss: 0.2701 - accuracy: 0.8713\n",
      "Epoch 24/50\n",
      "513/513 [==============================] - 0s 361us/sample - loss: 0.2548 - accuracy: 0.8850\n",
      "Epoch 25/50\n",
      "513/513 [==============================] - 0s 370us/sample - loss: 0.2505 - accuracy: 0.8908\n",
      "Epoch 26/50\n",
      "513/513 [==============================] - 0s 361us/sample - loss: 0.2387 - accuracy: 0.9084\n",
      "Epoch 27/50\n",
      "513/513 [==============================] - 0s 361us/sample - loss: 0.2754 - accuracy: 0.8733\n",
      "Epoch 28/50\n",
      "513/513 [==============================] - 0s 355us/sample - loss: 0.2175 - accuracy: 0.9201\n",
      "Epoch 29/50\n",
      "513/513 [==============================] - 0s 360us/sample - loss: 0.2323 - accuracy: 0.9259\n",
      "Epoch 30/50\n",
      "513/513 [==============================] - 0s 406us/sample - loss: 0.2330 - accuracy: 0.9025\n",
      "Epoch 31/50\n",
      "513/513 [==============================] - 0s 365us/sample - loss: 0.2315 - accuracy: 0.9025\n",
      "Epoch 32/50\n",
      "513/513 [==============================] - 0s 358us/sample - loss: 0.2165 - accuracy: 0.9142\n",
      "Epoch 33/50\n",
      "513/513 [==============================] - 0s 373us/sample - loss: 0.1613 - accuracy: 0.9552\n",
      "Epoch 34/50\n",
      "513/513 [==============================] - 0s 367us/sample - loss: 0.2040 - accuracy: 0.9298\n",
      "Epoch 35/50\n",
      "513/513 [==============================] - 0s 369us/sample - loss: 0.1877 - accuracy: 0.9298\n",
      "Epoch 36/50\n",
      "513/513 [==============================] - 0s 384us/sample - loss: 0.2197 - accuracy: 0.9142\n",
      "Epoch 37/50\n",
      "513/513 [==============================] - 0s 392us/sample - loss: 0.1780 - accuracy: 0.9318\n",
      "Epoch 38/50\n",
      "513/513 [==============================] - 0s 395us/sample - loss: 0.1734 - accuracy: 0.9454\n",
      "Epoch 39/50\n",
      "513/513 [==============================] - 0s 408us/sample - loss: 0.1556 - accuracy: 0.9435\n",
      "Epoch 40/50\n",
      "513/513 [==============================] - 0s 392us/sample - loss: 0.1619 - accuracy: 0.9337\n",
      "Epoch 41/50\n",
      "513/513 [==============================] - 0s 389us/sample - loss: 0.1423 - accuracy: 0.9454\n",
      "Epoch 42/50\n",
      "513/513 [==============================] - 0s 395us/sample - loss: 0.1797 - accuracy: 0.9337\n",
      "Epoch 43/50\n",
      "513/513 [==============================] - 0s 391us/sample - loss: 0.1570 - accuracy: 0.9376\n",
      "Epoch 44/50\n",
      "513/513 [==============================] - 0s 386us/sample - loss: 0.1657 - accuracy: 0.9357\n",
      "Epoch 45/50\n",
      "513/513 [==============================] - 0s 385us/sample - loss: 0.1575 - accuracy: 0.9415\n",
      "Epoch 46/50\n",
      "513/513 [==============================] - 0s 388us/sample - loss: 0.1240 - accuracy: 0.9591\n",
      "Epoch 47/50\n",
      "513/513 [==============================] - 0s 393us/sample - loss: 0.1510 - accuracy: 0.9435\n",
      "Epoch 48/50\n",
      "513/513 [==============================] - 0s 406us/sample - loss: 0.1364 - accuracy: 0.9435\n",
      "Epoch 49/50\n",
      "513/513 [==============================] - 0s 391us/sample - loss: 0.1419 - accuracy: 0.9532\n",
      "Epoch 50/50\n",
      "513/513 [==============================] - 0s 395us/sample - loss: 0.1318 - accuracy: 0.9493\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.96      0.74        67\n",
      "           2       0.88      0.34      0.49        62\n",
      "\n",
      "    accuracy                           0.66       129\n",
      "   macro avg       0.74      0.65      0.62       129\n",
      "weighted avg       0.74      0.66      0.62       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 19]\n",
      " [26 36]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save('models/hidden_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='rmsprop',init='glorot_uniform', dropout=0.3):\n",
    "    model = Sequential()\n",
    "    # adding layers and adding droplayers to avoid overfitting\n",
    "    hidden_layers = len(selected_genes)\n",
    "    model.add(Dense(hidden_layers, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters selected from previous gridsearch\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=16, optimizer='Adamax',init='uniform')\n",
    "# kfold = KFold(n_splits=3, shuffle=True)\n",
    "# results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "# print(\"Baseline Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 513 samples\n",
      "Epoch 1/50\n",
      "513/513 [==============================] - 1s 2ms/sample - loss: 0.7165 - accuracy: 0.6238\n",
      "Epoch 2/50\n",
      "513/513 [==============================] - 0s 300us/sample - loss: 0.5545 - accuracy: 0.7251\n",
      "Epoch 3/50\n",
      "513/513 [==============================] - 0s 317us/sample - loss: 0.4661 - accuracy: 0.7758\n",
      "Epoch 4/50\n",
      "513/513 [==============================] - 0s 297us/sample - loss: 0.4446 - accuracy: 0.7992\n",
      "Epoch 5/50\n",
      "513/513 [==============================] - 0s 294us/sample - loss: 0.4202 - accuracy: 0.8187\n",
      "Epoch 6/50\n",
      "513/513 [==============================] - 0s 293us/sample - loss: 0.4035 - accuracy: 0.8148\n",
      "Epoch 7/50\n",
      "513/513 [==============================] - 0s 292us/sample - loss: 0.3858 - accuracy: 0.8324\n",
      "Epoch 8/50\n",
      "513/513 [==============================] - 0s 312us/sample - loss: 0.3890 - accuracy: 0.8324\n",
      "Epoch 9/50\n",
      "513/513 [==============================] - 0s 302us/sample - loss: 0.3431 - accuracy: 0.8558\n",
      "Epoch 10/50\n",
      "513/513 [==============================] - 0s 301us/sample - loss: 0.3285 - accuracy: 0.8752\n",
      "Epoch 11/50\n",
      "513/513 [==============================] - 0s 299us/sample - loss: 0.3056 - accuracy: 0.8811\n",
      "Epoch 12/50\n",
      "513/513 [==============================] - 0s 294us/sample - loss: 0.3252 - accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "513/513 [==============================] - 0s 303us/sample - loss: 0.2917 - accuracy: 0.8928\n",
      "Epoch 14/50\n",
      "513/513 [==============================] - 0s 313us/sample - loss: 0.2880 - accuracy: 0.8733\n",
      "Epoch 15/50\n",
      "513/513 [==============================] - 0s 296us/sample - loss: 0.2763 - accuracy: 0.8830\n",
      "Epoch 16/50\n",
      "513/513 [==============================] - 0s 310us/sample - loss: 0.2540 - accuracy: 0.8986\n",
      "Epoch 17/50\n",
      "513/513 [==============================] - 0s 319us/sample - loss: 0.2404 - accuracy: 0.9318\n",
      "Epoch 18/50\n",
      "513/513 [==============================] - 0s 308us/sample - loss: 0.2498 - accuracy: 0.9084\n",
      "Epoch 19/50\n",
      "513/513 [==============================] - 0s 315us/sample - loss: 0.2500 - accuracy: 0.9123\n",
      "Epoch 20/50\n",
      "513/513 [==============================] - 0s 308us/sample - loss: 0.2466 - accuracy: 0.9064\n",
      "Epoch 21/50\n",
      "513/513 [==============================] - 0s 318us/sample - loss: 0.2213 - accuracy: 0.9201\n",
      "Epoch 22/50\n",
      "513/513 [==============================] - 0s 299us/sample - loss: 0.2256 - accuracy: 0.9025\n",
      "Epoch 23/50\n",
      "513/513 [==============================] - 0s 297us/sample - loss: 0.2237 - accuracy: 0.9103\n",
      "Epoch 24/50\n",
      "513/513 [==============================] - 0s 300us/sample - loss: 0.2064 - accuracy: 0.9279\n",
      "Epoch 25/50\n",
      "513/513 [==============================] - 0s 311us/sample - loss: 0.1828 - accuracy: 0.9435\n",
      "Epoch 26/50\n",
      "513/513 [==============================] - 0s 311us/sample - loss: 0.1944 - accuracy: 0.9415\n",
      "Epoch 27/50\n",
      "513/513 [==============================] - 0s 312us/sample - loss: 0.1638 - accuracy: 0.9454\n",
      "Epoch 28/50\n",
      "513/513 [==============================] - 0s 311us/sample - loss: 0.2001 - accuracy: 0.9337\n",
      "Epoch 29/50\n",
      "513/513 [==============================] - 0s 303us/sample - loss: 0.1878 - accuracy: 0.9376\n",
      "Epoch 30/50\n",
      "513/513 [==============================] - 0s 311us/sample - loss: 0.1665 - accuracy: 0.9552\n",
      "Epoch 31/50\n",
      "513/513 [==============================] - 0s 305us/sample - loss: 0.1474 - accuracy: 0.9571\n",
      "Epoch 32/50\n",
      "513/513 [==============================] - 0s 306us/sample - loss: 0.1647 - accuracy: 0.9513\n",
      "Epoch 33/50\n",
      "513/513 [==============================] - 0s 309us/sample - loss: 0.1489 - accuracy: 0.9591\n",
      "Epoch 34/50\n",
      "513/513 [==============================] - 0s 309us/sample - loss: 0.1442 - accuracy: 0.9571\n",
      "Epoch 35/50\n",
      "513/513 [==============================] - 0s 318us/sample - loss: 0.1441 - accuracy: 0.9532\n",
      "Epoch 36/50\n",
      "513/513 [==============================] - 0s 312us/sample - loss: 0.1351 - accuracy: 0.9630\n",
      "Epoch 37/50\n",
      "513/513 [==============================] - 0s 314us/sample - loss: 0.1184 - accuracy: 0.9649\n",
      "Epoch 38/50\n",
      "513/513 [==============================] - 0s 331us/sample - loss: 0.1206 - accuracy: 0.9766\n",
      "Epoch 39/50\n",
      "513/513 [==============================] - 0s 333us/sample - loss: 0.1192 - accuracy: 0.9610\n",
      "Epoch 40/50\n",
      "513/513 [==============================] - 0s 332us/sample - loss: 0.1021 - accuracy: 0.9708\n",
      "Epoch 41/50\n",
      "513/513 [==============================] - 0s 311us/sample - loss: 0.1063 - accuracy: 0.9766\n",
      "Epoch 42/50\n",
      "513/513 [==============================] - 0s 328us/sample - loss: 0.1018 - accuracy: 0.9805\n",
      "Epoch 43/50\n",
      "513/513 [==============================] - 0s 370us/sample - loss: 0.0950 - accuracy: 0.9825\n",
      "Epoch 44/50\n",
      "513/513 [==============================] - 0s 370us/sample - loss: 0.1179 - accuracy: 0.9669\n",
      "Epoch 45/50\n",
      "513/513 [==============================] - 0s 374us/sample - loss: 0.0779 - accuracy: 0.9903\n",
      "Epoch 46/50\n",
      "513/513 [==============================] - 0s 364us/sample - loss: 0.0882 - accuracy: 0.9825\n",
      "Epoch 47/50\n",
      "513/513 [==============================] - 0s 347us/sample - loss: 0.1042 - accuracy: 0.9708\n",
      "Epoch 48/50\n",
      "513/513 [==============================] - 0s 333us/sample - loss: 0.0830 - accuracy: 0.9864\n",
      "Epoch 49/50\n",
      "513/513 [==============================] - 0s 337us/sample - loss: 0.0769 - accuracy: 0.9903\n",
      "Epoch 50/50\n",
      "513/513 [==============================] - 0s 351us/sample - loss: 0.1021 - accuracy: 0.9727\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.84      0.75        67\n",
      "           2       0.76      0.56      0.65        62\n",
      "\n",
      "    accuracy                           0.71       129\n",
      "   macro avg       0.72      0.70      0.70       129\n",
      "weighted avg       0.72      0.71      0.70       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56 11]\n",
      " [27 35]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save('models/hidden_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
