{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# for data scaling and splitting\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "# for neural net\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# for evaluation\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th>classification</th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>TNMD</th>\n",
       "      <th>DPM1</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>C1orf112</th>\n",
       "      <th>FGR</th>\n",
       "      <th>CFH</th>\n",
       "      <th>FUCA2</th>\n",
       "      <th>...</th>\n",
       "      <th>COL15A1</th>\n",
       "      <th>C6orf10</th>\n",
       "      <th>TMEM225</th>\n",
       "      <th>NOTCH4</th>\n",
       "      <th>PBX2</th>\n",
       "      <th>AGER</th>\n",
       "      <th>RNF5</th>\n",
       "      <th>AGPAT1</th>\n",
       "      <th>DFNB59</th>\n",
       "      <th>PRRT1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240121</td>\n",
       "      <td>1</td>\n",
       "      <td>6.419526</td>\n",
       "      <td>3.182094</td>\n",
       "      <td>9.320548</td>\n",
       "      <td>3.759654</td>\n",
       "      <td>3.802619</td>\n",
       "      <td>3.215753</td>\n",
       "      <td>4.698729</td>\n",
       "      <td>7.873672</td>\n",
       "      <td>...</td>\n",
       "      <td>3.245454</td>\n",
       "      <td>2.953508</td>\n",
       "      <td>3.543429</td>\n",
       "      <td>3.352022</td>\n",
       "      <td>4.672310</td>\n",
       "      <td>3.641128</td>\n",
       "      <td>3.135310</td>\n",
       "      <td>3.737072</td>\n",
       "      <td>3.450927</td>\n",
       "      <td>3.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240122</td>\n",
       "      <td>2</td>\n",
       "      <td>7.646494</td>\n",
       "      <td>2.626819</td>\n",
       "      <td>10.153853</td>\n",
       "      <td>3.564755</td>\n",
       "      <td>3.942749</td>\n",
       "      <td>3.290760</td>\n",
       "      <td>3.551675</td>\n",
       "      <td>8.252413</td>\n",
       "      <td>...</td>\n",
       "      <td>2.786709</td>\n",
       "      <td>3.077382</td>\n",
       "      <td>3.728232</td>\n",
       "      <td>3.208882</td>\n",
       "      <td>4.586840</td>\n",
       "      <td>3.395654</td>\n",
       "      <td>3.586800</td>\n",
       "      <td>3.519128</td>\n",
       "      <td>3.115323</td>\n",
       "      <td>3.051645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240123</td>\n",
       "      <td>1</td>\n",
       "      <td>8.319417</td>\n",
       "      <td>3.111183</td>\n",
       "      <td>9.643558</td>\n",
       "      <td>4.757258</td>\n",
       "      <td>3.919757</td>\n",
       "      <td>3.602185</td>\n",
       "      <td>3.329644</td>\n",
       "      <td>9.076950</td>\n",
       "      <td>...</td>\n",
       "      <td>3.459089</td>\n",
       "      <td>3.085394</td>\n",
       "      <td>3.462811</td>\n",
       "      <td>3.339030</td>\n",
       "      <td>4.614897</td>\n",
       "      <td>3.395845</td>\n",
       "      <td>3.419193</td>\n",
       "      <td>3.971646</td>\n",
       "      <td>3.729310</td>\n",
       "      <td>3.320022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240124</td>\n",
       "      <td>1</td>\n",
       "      <td>9.006994</td>\n",
       "      <td>3.028173</td>\n",
       "      <td>9.686700</td>\n",
       "      <td>4.280504</td>\n",
       "      <td>3.147646</td>\n",
       "      <td>3.188881</td>\n",
       "      <td>3.293807</td>\n",
       "      <td>8.678790</td>\n",
       "      <td>...</td>\n",
       "      <td>2.835403</td>\n",
       "      <td>2.960303</td>\n",
       "      <td>3.415083</td>\n",
       "      <td>3.290171</td>\n",
       "      <td>4.770123</td>\n",
       "      <td>3.400821</td>\n",
       "      <td>3.383734</td>\n",
       "      <td>3.798107</td>\n",
       "      <td>2.822404</td>\n",
       "      <td>3.297547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240127</td>\n",
       "      <td>1</td>\n",
       "      <td>7.985676</td>\n",
       "      <td>2.694729</td>\n",
       "      <td>10.676134</td>\n",
       "      <td>4.159685</td>\n",
       "      <td>3.804637</td>\n",
       "      <td>3.481942</td>\n",
       "      <td>3.111261</td>\n",
       "      <td>7.555407</td>\n",
       "      <td>...</td>\n",
       "      <td>2.896523</td>\n",
       "      <td>2.849899</td>\n",
       "      <td>3.480114</td>\n",
       "      <td>3.226128</td>\n",
       "      <td>5.832710</td>\n",
       "      <td>3.612179</td>\n",
       "      <td>3.347095</td>\n",
       "      <td>4.457963</td>\n",
       "      <td>5.198524</td>\n",
       "      <td>4.553586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CELL_LINE_NAME  classification    TSPAN6      TNMD       DPM1     SCYL3  \\\n",
       "0         1240121               1  6.419526  3.182094   9.320548  3.759654   \n",
       "1         1240122               2  7.646494  2.626819  10.153853  3.564755   \n",
       "2         1240123               1  8.319417  3.111183   9.643558  4.757258   \n",
       "3         1240124               1  9.006994  3.028173   9.686700  4.280504   \n",
       "4         1240127               1  7.985676  2.694729  10.676134  4.159685   \n",
       "\n",
       "   C1orf112       FGR       CFH     FUCA2  ...   COL15A1   C6orf10   TMEM225  \\\n",
       "0  3.802619  3.215753  4.698729  7.873672  ...  3.245454  2.953508  3.543429   \n",
       "1  3.942749  3.290760  3.551675  8.252413  ...  2.786709  3.077382  3.728232   \n",
       "2  3.919757  3.602185  3.329644  9.076950  ...  3.459089  3.085394  3.462811   \n",
       "3  3.147646  3.188881  3.293807  8.678790  ...  2.835403  2.960303  3.415083   \n",
       "4  3.804637  3.481942  3.111261  7.555407  ...  2.896523  2.849899  3.480114   \n",
       "\n",
       "     NOTCH4      PBX2      AGER      RNF5    AGPAT1    DFNB59     PRRT1  \n",
       "0  3.352022  4.672310  3.641128  3.135310  3.737072  3.450927  3.168800  \n",
       "1  3.208882  4.586840  3.395654  3.586800  3.519128  3.115323  3.051645  \n",
       "2  3.339030  4.614897  3.395845  3.419193  3.971646  3.729310  3.320022  \n",
       "3  3.290171  4.770123  3.400821  3.383734  3.798107  2.822404  3.297547  \n",
       "4  3.226128  5.832710  3.612179  3.347095  4.457963  5.198524  4.553586  \n",
       "\n",
       "[5 rows x 16383 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/combined_expression.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes = pd.read_csv('cleaned/boruta-99-25-0.01.csv')\n",
    "selected_genes = selected_genes.values.tolist()\n",
    "selected_genes = list(itertools.chain(*selected_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving proper columns\n",
    "X = data.loc[:, selected_genes]\n",
    "y = data['classification'].values\n",
    "# scaling the data\n",
    "scalar = MinMaxScaler()\n",
    "x_scaled = scalar.fit_transform(X)\n",
    "# splitting data (20% test, 80% train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch for Input and Output Layer (no hidden layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Epochs and Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    # adding layers\n",
    "    model.add(Dense(len(selected_genes), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddieguo/anaconda3/envs/fixed_comp/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "513/513 [==============================] - 0s 972us/step - loss: 0.6632 - accuracy: 0.6238\n",
      "Epoch 2/50\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.5979 - accuracy: 0.6628\n",
      "Epoch 3/50\n",
      "513/513 [==============================] - 0s 83us/step - loss: 0.5593 - accuracy: 0.6979\n",
      "Epoch 4/50\n",
      "513/513 [==============================] - 0s 84us/step - loss: 0.5484 - accuracy: 0.7115\n",
      "Epoch 5/50\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.5294 - accuracy: 0.7173\n",
      "Epoch 6/50\n",
      "513/513 [==============================] - 0s 95us/step - loss: 0.5194 - accuracy: 0.7505\n",
      "Epoch 7/50\n",
      "513/513 [==============================] - 0s 97us/step - loss: 0.5465 - accuracy: 0.7037\n",
      "Epoch 8/50\n",
      "513/513 [==============================] - 0s 95us/step - loss: 0.5835 - accuracy: 0.6920\n",
      "Epoch 9/50\n",
      "513/513 [==============================] - 0s 91us/step - loss: 0.5858 - accuracy: 0.6940\n",
      "Epoch 10/50\n",
      "513/513 [==============================] - 0s 89us/step - loss: 0.5838 - accuracy: 0.6979\n",
      "Epoch 11/50\n",
      "513/513 [==============================] - 0s 88us/step - loss: 0.5100 - accuracy: 0.7349\n",
      "Epoch 12/50\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.5149 - accuracy: 0.7563\n",
      "Epoch 13/50\n",
      "513/513 [==============================] - 0s 87us/step - loss: 0.5130 - accuracy: 0.7427\n",
      "Epoch 14/50\n",
      "513/513 [==============================] - 0s 91us/step - loss: 0.4911 - accuracy: 0.7739\n",
      "Epoch 15/50\n",
      "513/513 [==============================] - 0s 92us/step - loss: 0.4871 - accuracy: 0.7875\n",
      "Epoch 16/50\n",
      "513/513 [==============================] - 0s 93us/step - loss: 0.5349 - accuracy: 0.7232\n",
      "Epoch 17/50\n",
      "513/513 [==============================] - 0s 92us/step - loss: 0.6481 - accuracy: 0.6296\n",
      "Epoch 18/50\n",
      "513/513 [==============================] - 0s 92us/step - loss: 0.5670 - accuracy: 0.7076\n",
      "Epoch 19/50\n",
      "513/513 [==============================] - 0s 92us/step - loss: 0.6689 - accuracy: 0.6140\n",
      "Epoch 20/50\n",
      "513/513 [==============================] - 0s 93us/step - loss: 0.5775 - accuracy: 0.6979\n",
      "Epoch 21/50\n",
      "513/513 [==============================] - 0s 93us/step - loss: 0.5612 - accuracy: 0.7115\n",
      "Epoch 22/50\n",
      "513/513 [==============================] - 0s 90us/step - loss: 0.5262 - accuracy: 0.7368\n",
      "Epoch 23/50\n",
      "513/513 [==============================] - 0s 90us/step - loss: 0.4937 - accuracy: 0.7719\n",
      "Epoch 24/50\n",
      "513/513 [==============================] - 0s 90us/step - loss: 0.4957 - accuracy: 0.7388\n",
      "Epoch 25/50\n",
      "513/513 [==============================] - 0s 90us/step - loss: 0.4875 - accuracy: 0.7583\n",
      "Epoch 26/50\n",
      "513/513 [==============================] - 0s 90us/step - loss: 0.4750 - accuracy: 0.7817\n",
      "Epoch 27/50\n",
      "513/513 [==============================] - 0s 89us/step - loss: 0.4706 - accuracy: 0.7836\n",
      "Epoch 28/50\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4689 - accuracy: 0.7914\n",
      "Epoch 29/50\n",
      "513/513 [==============================] - 0s 88us/step - loss: 0.4896 - accuracy: 0.7329\n",
      "Epoch 30/50\n",
      "513/513 [==============================] - 0s 84us/step - loss: 0.5694 - accuracy: 0.6940\n",
      "Epoch 31/50\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4908 - accuracy: 0.7427\n",
      "Epoch 32/50\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4701 - accuracy: 0.7797\n",
      "Epoch 33/50\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.5151 - accuracy: 0.7485\n",
      "Epoch 34/50\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.4679 - accuracy: 0.7700\n",
      "Epoch 35/50\n",
      "513/513 [==============================] - 0s 84us/step - loss: 0.5251 - accuracy: 0.7544\n",
      "Epoch 36/50\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4709 - accuracy: 0.7836\n",
      "Epoch 37/50\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.4672 - accuracy: 0.7700\n",
      "Epoch 38/50\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.4597 - accuracy: 0.7778\n",
      "Epoch 39/50\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4978 - accuracy: 0.7602\n",
      "Epoch 40/50\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4551 - accuracy: 0.7953\n",
      "Epoch 41/50\n",
      "513/513 [==============================] - 0s 84us/step - loss: 0.4604 - accuracy: 0.7836\n",
      "Epoch 42/50\n",
      "513/513 [==============================] - 0s 84us/step - loss: 0.4461 - accuracy: 0.8051\n",
      "Epoch 43/50\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4494 - accuracy: 0.7856\n",
      "Epoch 44/50\n",
      "513/513 [==============================] - 0s 84us/step - loss: 0.4763 - accuracy: 0.7505\n",
      "Epoch 45/50\n",
      "513/513 [==============================] - 0s 84us/step - loss: 0.4652 - accuracy: 0.7700\n",
      "Epoch 46/50\n",
      "513/513 [==============================] - 0s 87us/step - loss: 0.4513 - accuracy: 0.7817\n",
      "Epoch 47/50\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4348 - accuracy: 0.8109\n",
      "Epoch 48/50\n",
      "513/513 [==============================] - 0s 87us/step - loss: 0.5234 - accuracy: 0.7368\n",
      "Epoch 49/50\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.4743 - accuracy: 0.7544\n",
      "Epoch 50/50\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4352 - accuracy: 0.8070\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "epochs = [10, 25, 50, 100]\n",
    "batches = [16, 32, 64, 128]\n",
    "param_grid = dict(epochs=epochs, batch_size=batches)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=0, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.754386 using {'batch_size': 64, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 8.89025078, 12.75803318, 19.26391606, 34.30394907,  8.20030737,\n",
       "        11.34873967, 13.6889308 , 18.04424515,  6.45221438,  8.43450785,\n",
       "         9.72793574, 14.60181489,  7.19966426,  6.71270518,  6.27273889,\n",
       "         8.398774  ]),\n",
       " 'std_fit_time': array([0.16444237, 0.12779544, 0.54525051, 0.20913776, 0.52294618,\n",
       "        0.51423753, 1.31642935, 0.08993733, 0.33960881, 0.32237099,\n",
       "        0.4168923 , 0.24949539, 0.47613226, 0.29489586, 0.36781995,\n",
       "        0.1170051 ]),\n",
       " 'mean_score_time': array([0.94311066, 0.66564546, 1.10282264, 0.70391574, 0.9941628 ,\n",
       "        1.18192902, 0.82030702, 0.78884726, 0.9586884 , 0.68544936,\n",
       "        0.96039133, 0.6519465 , 0.95165958, 0.60001125, 0.47210975,\n",
       "        0.18315883]),\n",
       " 'std_score_time': array([0.03113768, 0.02067126, 0.14116664, 0.15304386, 0.22508128,\n",
       "        0.21197436, 0.17951082, 0.15242896, 0.07337433, 0.09686909,\n",
       "        0.27478934, 0.0482765 , 0.19803076, 0.03923923, 0.16044839,\n",
       "        0.04926153]),\n",
       " 'param_batch_size': masked_array(data=[16, 16, 16, 16, 32, 32, 32, 32, 64, 64, 64, 64, 128,\n",
       "                    128, 128, 128],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[10, 25, 50, 100, 10, 25, 50, 100, 10, 25, 50, 100, 10,\n",
       "                    25, 50, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'batch_size': 16, 'epochs': 10},\n",
       "  {'batch_size': 16, 'epochs': 25},\n",
       "  {'batch_size': 16, 'epochs': 50},\n",
       "  {'batch_size': 16, 'epochs': 100},\n",
       "  {'batch_size': 32, 'epochs': 10},\n",
       "  {'batch_size': 32, 'epochs': 25},\n",
       "  {'batch_size': 32, 'epochs': 50},\n",
       "  {'batch_size': 32, 'epochs': 100},\n",
       "  {'batch_size': 64, 'epochs': 10},\n",
       "  {'batch_size': 64, 'epochs': 25},\n",
       "  {'batch_size': 64, 'epochs': 50},\n",
       "  {'batch_size': 64, 'epochs': 100},\n",
       "  {'batch_size': 128, 'epochs': 10},\n",
       "  {'batch_size': 128, 'epochs': 25},\n",
       "  {'batch_size': 128, 'epochs': 50},\n",
       "  {'batch_size': 128, 'epochs': 100}],\n",
       " 'split0_test_score': array([0.72815531, 0.7669903 , 0.74757284, 0.75728154, 0.74757284,\n",
       "        0.72815531, 0.75728154, 0.74757284, 0.78640777, 0.78640777,\n",
       "        0.815534  , 0.73786408, 0.77669901, 0.74757284, 0.7669903 ,\n",
       "        0.78640777]),\n",
       " 'split1_test_score': array([0.73786408, 0.66990292, 0.73786408, 0.78640777, 0.70873785,\n",
       "        0.73786408, 0.72815531, 0.71844661, 0.68932039, 0.71844661,\n",
       "        0.73786408, 0.74757284, 0.70873785, 0.71844661, 0.74757284,\n",
       "        0.77669901]),\n",
       " 'split2_test_score': array([0.73786408, 0.75728154, 0.74757284, 0.72815531, 0.72815531,\n",
       "        0.75728154, 0.72815531, 0.67961162, 0.73786408, 0.73786408,\n",
       "        0.74757284, 0.75728154, 0.66990292, 0.75728154, 0.7669903 ,\n",
       "        0.70873785]),\n",
       " 'split3_test_score': array([0.77450979, 0.74509805, 0.7352941 , 0.74509805, 0.72549021,\n",
       "        0.75490195, 0.74509805, 0.72549021, 0.71568626, 0.71568626,\n",
       "        0.78431374, 0.75490195, 0.7647059 , 0.77450979, 0.75490195,\n",
       "        0.75490195]),\n",
       " 'split4_test_score': array([0.67647058, 0.68627453, 0.66666669, 0.61764705, 0.66666669,\n",
       "        0.61764705, 0.67647058, 0.627451  , 0.65686274, 0.66666669,\n",
       "        0.68627453, 0.60784316, 0.72549021, 0.70588237, 0.66666669,\n",
       "        0.67647058]),\n",
       " 'mean_test_score': array([0.73099414, 0.72514621, 0.72709553, 0.72709551, 0.71539961,\n",
       "        0.71929823, 0.72709551, 0.69980508, 0.71734892, 0.7251462 ,\n",
       "        0.75438598, 0.72124757, 0.72904483, 0.74074075, 0.74074075,\n",
       "        0.74074073]),\n",
       " 'std_test_score': array([0.03143508, 0.03938553, 0.03051373, 0.05775577, 0.02723704,\n",
       "        0.0517801 , 0.02752125, 0.04221196, 0.04390632, 0.03863643,\n",
       "        0.04376475, 0.05689949, 0.03868331, 0.02514824, 0.03764188,\n",
       "        0.04177485]),\n",
       " 'rank_test_score': array([ 5, 10,  7,  8, 15, 13,  9, 16, 14, 11,  1, 12,  6,  3,  2,  4],\n",
       "       dtype=int32)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the Training Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    # adding layers\n",
    "    model.add(Dense(len(selected_genes), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "513/513 [==============================] - 0s 884us/step - loss: 0.6181 - accuracy: 0.6725\n",
      "Epoch 2/50\n",
      "513/513 [==============================] - 0s 73us/step - loss: 0.5726 - accuracy: 0.7076\n",
      "Epoch 3/50\n",
      "513/513 [==============================] - 0s 74us/step - loss: 0.5564 - accuracy: 0.7251\n",
      "Epoch 4/50\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.5450 - accuracy: 0.7583\n",
      "Epoch 5/50\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.5297 - accuracy: 0.7505\n",
      "Epoch 6/50\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.5395 - accuracy: 0.7271\n",
      "Epoch 7/50\n",
      "513/513 [==============================] - 0s 75us/step - loss: 0.5232 - accuracy: 0.7505\n",
      "Epoch 8/50\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.5173 - accuracy: 0.7485\n",
      "Epoch 9/50\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.5356 - accuracy: 0.7563\n",
      "Epoch 10/50\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.5323 - accuracy: 0.7212\n",
      "Epoch 11/50\n",
      "513/513 [==============================] - 0s 78us/step - loss: 0.5088 - accuracy: 0.7641\n",
      "Epoch 12/50\n",
      "513/513 [==============================] - 0s 80us/step - loss: 0.5207 - accuracy: 0.7583\n",
      "Epoch 13/50\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.5155 - accuracy: 0.7388\n",
      "Epoch 14/50\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.4933 - accuracy: 0.7797\n",
      "Epoch 15/50\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.5511 - accuracy: 0.7135\n",
      "Epoch 16/50\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.4978 - accuracy: 0.7641\n",
      "Epoch 17/50\n",
      "513/513 [==============================] - 0s 75us/step - loss: 0.4918 - accuracy: 0.7700\n",
      "Epoch 18/50\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.4878 - accuracy: 0.7856\n",
      "Epoch 19/50\n",
      "513/513 [==============================] - 0s 72us/step - loss: 0.5117 - accuracy: 0.7485\n",
      "Epoch 20/50\n",
      "513/513 [==============================] - 0s 69us/step - loss: 0.4921 - accuracy: 0.7602\n",
      "Epoch 21/50\n",
      "513/513 [==============================] - 0s 75us/step - loss: 0.4814 - accuracy: 0.7895\n",
      "Epoch 22/50\n",
      "513/513 [==============================] - 0s 72us/step - loss: 0.4798 - accuracy: 0.7856\n",
      "Epoch 23/50\n",
      "513/513 [==============================] - 0s 70us/step - loss: 0.5152 - accuracy: 0.7388\n",
      "Epoch 24/50\n",
      "513/513 [==============================] - 0s 71us/step - loss: 0.4840 - accuracy: 0.7739\n",
      "Epoch 25/50\n",
      "513/513 [==============================] - 0s 70us/step - loss: 0.4740 - accuracy: 0.7914\n",
      "Epoch 26/50\n",
      "513/513 [==============================] - 0s 71us/step - loss: 0.4789 - accuracy: 0.7856\n",
      "Epoch 27/50\n",
      "513/513 [==============================] - 0s 71us/step - loss: 0.4825 - accuracy: 0.7641\n",
      "Epoch 28/50\n",
      "513/513 [==============================] - 0s 73us/step - loss: 0.5084 - accuracy: 0.7661\n",
      "Epoch 29/50\n",
      "513/513 [==============================] - 0s 73us/step - loss: 0.4750 - accuracy: 0.7973\n",
      "Epoch 30/50\n",
      "513/513 [==============================] - 0s 72us/step - loss: 0.4927 - accuracy: 0.7563\n",
      "Epoch 31/50\n",
      "513/513 [==============================] - 0s 71us/step - loss: 0.4683 - accuracy: 0.7973\n",
      "Epoch 32/50\n",
      "513/513 [==============================] - 0s 73us/step - loss: 0.4789 - accuracy: 0.7875\n",
      "Epoch 33/50\n",
      "513/513 [==============================] - 0s 72us/step - loss: 0.4822 - accuracy: 0.7875\n",
      "Epoch 34/50\n",
      "513/513 [==============================] - 0s 73us/step - loss: 0.4676 - accuracy: 0.7778\n",
      "Epoch 35/50\n",
      "513/513 [==============================] - 0s 71us/step - loss: 0.4685 - accuracy: 0.7992\n",
      "Epoch 36/50\n",
      "513/513 [==============================] - 0s 70us/step - loss: 0.5147 - accuracy: 0.7524\n",
      "Epoch 37/50\n",
      "513/513 [==============================] - 0s 72us/step - loss: 0.4665 - accuracy: 0.7739\n",
      "Epoch 38/50\n",
      "513/513 [==============================] - 0s 74us/step - loss: 0.4679 - accuracy: 0.7817\n",
      "Epoch 39/50\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.5119 - accuracy: 0.7466\n",
      "Epoch 40/50\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.4637 - accuracy: 0.7973\n",
      "Epoch 41/50\n",
      "513/513 [==============================] - 0s 78us/step - loss: 0.4809 - accuracy: 0.7524\n",
      "Epoch 42/50\n",
      "513/513 [==============================] - 0s 72us/step - loss: 0.4567 - accuracy: 0.7953\n",
      "Epoch 43/50\n",
      "513/513 [==============================] - 0s 71us/step - loss: 0.4680 - accuracy: 0.7680\n",
      "Epoch 44/50\n",
      "513/513 [==============================] - 0s 70us/step - loss: 0.4645 - accuracy: 0.7680\n",
      "Epoch 45/50\n",
      "513/513 [==============================] - 0s 72us/step - loss: 0.4524 - accuracy: 0.8012\n",
      "Epoch 46/50\n",
      "513/513 [==============================] - 0s 72us/step - loss: 0.4649 - accuracy: 0.8012\n",
      "Epoch 47/50\n",
      "513/513 [==============================] - 0s 71us/step - loss: 0.4503 - accuracy: 0.8012\n",
      "Epoch 48/50\n",
      "513/513 [==============================] - 0s 71us/step - loss: 0.4544 - accuracy: 0.7836\n",
      "Epoch 49/50\n",
      "513/513 [==============================] - 0s 71us/step - loss: 0.4484 - accuracy: 0.7953\n",
      "Epoch 50/50\n",
      "513/513 [==============================] - 0s 71us/step - loss: 0.4613 - accuracy: 0.8051\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model2, epochs=50, batch_size=64)\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.734893 using {'optimizer': 'Adamax'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=64)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/model_1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
