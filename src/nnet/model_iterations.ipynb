{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# for data scaling and splitting\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for neural net\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# for evaluation\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/combined_expression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th>classification</th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>TNMD</th>\n",
       "      <th>DPM1</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>C1orf112</th>\n",
       "      <th>FGR</th>\n",
       "      <th>CFH</th>\n",
       "      <th>FUCA2</th>\n",
       "      <th>...</th>\n",
       "      <th>COL15A1</th>\n",
       "      <th>C6orf10</th>\n",
       "      <th>TMEM225</th>\n",
       "      <th>NOTCH4</th>\n",
       "      <th>PBX2</th>\n",
       "      <th>AGER</th>\n",
       "      <th>RNF5</th>\n",
       "      <th>AGPAT1</th>\n",
       "      <th>DFNB59</th>\n",
       "      <th>PRRT1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240121</td>\n",
       "      <td>0</td>\n",
       "      <td>6.419526</td>\n",
       "      <td>3.182094</td>\n",
       "      <td>9.320548</td>\n",
       "      <td>3.759654</td>\n",
       "      <td>3.802619</td>\n",
       "      <td>3.215753</td>\n",
       "      <td>4.698729</td>\n",
       "      <td>7.873672</td>\n",
       "      <td>...</td>\n",
       "      <td>3.245454</td>\n",
       "      <td>2.953508</td>\n",
       "      <td>3.543429</td>\n",
       "      <td>3.352022</td>\n",
       "      <td>4.672310</td>\n",
       "      <td>3.641128</td>\n",
       "      <td>3.135310</td>\n",
       "      <td>3.737072</td>\n",
       "      <td>3.450927</td>\n",
       "      <td>3.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240122</td>\n",
       "      <td>1</td>\n",
       "      <td>7.646494</td>\n",
       "      <td>2.626819</td>\n",
       "      <td>10.153853</td>\n",
       "      <td>3.564755</td>\n",
       "      <td>3.942749</td>\n",
       "      <td>3.290760</td>\n",
       "      <td>3.551675</td>\n",
       "      <td>8.252413</td>\n",
       "      <td>...</td>\n",
       "      <td>2.786709</td>\n",
       "      <td>3.077382</td>\n",
       "      <td>3.728232</td>\n",
       "      <td>3.208882</td>\n",
       "      <td>4.586840</td>\n",
       "      <td>3.395654</td>\n",
       "      <td>3.586800</td>\n",
       "      <td>3.519128</td>\n",
       "      <td>3.115323</td>\n",
       "      <td>3.051645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240123</td>\n",
       "      <td>0</td>\n",
       "      <td>8.319417</td>\n",
       "      <td>3.111183</td>\n",
       "      <td>9.643558</td>\n",
       "      <td>4.757258</td>\n",
       "      <td>3.919757</td>\n",
       "      <td>3.602185</td>\n",
       "      <td>3.329644</td>\n",
       "      <td>9.076950</td>\n",
       "      <td>...</td>\n",
       "      <td>3.459089</td>\n",
       "      <td>3.085394</td>\n",
       "      <td>3.462811</td>\n",
       "      <td>3.339030</td>\n",
       "      <td>4.614897</td>\n",
       "      <td>3.395845</td>\n",
       "      <td>3.419193</td>\n",
       "      <td>3.971646</td>\n",
       "      <td>3.729310</td>\n",
       "      <td>3.320022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240124</td>\n",
       "      <td>0</td>\n",
       "      <td>9.006994</td>\n",
       "      <td>3.028173</td>\n",
       "      <td>9.686700</td>\n",
       "      <td>4.280504</td>\n",
       "      <td>3.147646</td>\n",
       "      <td>3.188881</td>\n",
       "      <td>3.293807</td>\n",
       "      <td>8.678790</td>\n",
       "      <td>...</td>\n",
       "      <td>2.835403</td>\n",
       "      <td>2.960303</td>\n",
       "      <td>3.415083</td>\n",
       "      <td>3.290171</td>\n",
       "      <td>4.770123</td>\n",
       "      <td>3.400821</td>\n",
       "      <td>3.383734</td>\n",
       "      <td>3.798107</td>\n",
       "      <td>2.822404</td>\n",
       "      <td>3.297547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240127</td>\n",
       "      <td>0</td>\n",
       "      <td>7.985676</td>\n",
       "      <td>2.694729</td>\n",
       "      <td>10.676134</td>\n",
       "      <td>4.159685</td>\n",
       "      <td>3.804637</td>\n",
       "      <td>3.481942</td>\n",
       "      <td>3.111261</td>\n",
       "      <td>7.555407</td>\n",
       "      <td>...</td>\n",
       "      <td>2.896523</td>\n",
       "      <td>2.849899</td>\n",
       "      <td>3.480114</td>\n",
       "      <td>3.226128</td>\n",
       "      <td>5.832710</td>\n",
       "      <td>3.612179</td>\n",
       "      <td>3.347095</td>\n",
       "      <td>4.457963</td>\n",
       "      <td>5.198524</td>\n",
       "      <td>4.553586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CELL_LINE_NAME  classification    TSPAN6      TNMD       DPM1     SCYL3  \\\n",
       "0         1240121               0  6.419526  3.182094   9.320548  3.759654   \n",
       "1         1240122               1  7.646494  2.626819  10.153853  3.564755   \n",
       "2         1240123               0  8.319417  3.111183   9.643558  4.757258   \n",
       "3         1240124               0  9.006994  3.028173   9.686700  4.280504   \n",
       "4         1240127               0  7.985676  2.694729  10.676134  4.159685   \n",
       "\n",
       "   C1orf112       FGR       CFH     FUCA2  ...   COL15A1   C6orf10   TMEM225  \\\n",
       "0  3.802619  3.215753  4.698729  7.873672  ...  3.245454  2.953508  3.543429   \n",
       "1  3.942749  3.290760  3.551675  8.252413  ...  2.786709  3.077382  3.728232   \n",
       "2  3.919757  3.602185  3.329644  9.076950  ...  3.459089  3.085394  3.462811   \n",
       "3  3.147646  3.188881  3.293807  8.678790  ...  2.835403  2.960303  3.415083   \n",
       "4  3.804637  3.481942  3.111261  7.555407  ...  2.896523  2.849899  3.480114   \n",
       "\n",
       "     NOTCH4      PBX2      AGER      RNF5    AGPAT1    DFNB59     PRRT1  \n",
       "0  3.352022  4.672310  3.641128  3.135310  3.737072  3.450927  3.168800  \n",
       "1  3.208882  4.586840  3.395654  3.586800  3.519128  3.115323  3.051645  \n",
       "2  3.339030  4.614897  3.395845  3.419193  3.971646  3.729310  3.320022  \n",
       "3  3.290171  4.770123  3.400821  3.383734  3.798107  2.822404  3.297547  \n",
       "4  3.226128  5.832710  3.612179  3.347095  4.457963  5.198524  4.553586  \n",
       "\n",
       "[5 rows x 16383 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['classification'].replace({1: 0, 2: 1}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes = pd.read_csv('cleaned/boruta-99-25-0.01.csv')\n",
    "selected_genes = selected_genes.values.tolist()\n",
    "selected_genes = list(itertools.chain(*selected_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving proper columns\n",
    "X = data.loc[:, selected_genes].values\n",
    "y = data['classification'].values\n",
    "# scaling the data\n",
    "scalar = MinMaxScaler()\n",
    "x_scaled = scalar.fit_transform(X)\n",
    "# splitting data (20% test, 80% train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch for Input and Output Layer (One Hidden Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Epochs and Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    # adding layers\n",
    "    model.add(Dense(len(selected_genes), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compiling\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddieguo/anaconda3/envs/fixed_comp/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "513/513 [==============================] - 1s 1ms/step - loss: 0.7243 - accuracy: 0.5673\n",
      "Epoch 2/100\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.6347 - accuracy: 0.6608\n",
      "Epoch 3/100\n",
      "513/513 [==============================] - 0s 80us/step - loss: 0.5768 - accuracy: 0.6862\n",
      "Epoch 4/100\n",
      "513/513 [==============================] - 0s 72us/step - loss: 0.5867 - accuracy: 0.7388\n",
      "Epoch 5/100\n",
      "513/513 [==============================] - 0s 83us/step - loss: 0.5742 - accuracy: 0.6823\n",
      "Epoch 6/100\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.5606 - accuracy: 0.7505\n",
      "Epoch 7/100\n",
      "513/513 [==============================] - 0s 74us/step - loss: 0.5478 - accuracy: 0.7427\n",
      "Epoch 8/100\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.5570 - accuracy: 0.6979\n",
      "Epoch 9/100\n",
      "513/513 [==============================] - 0s 83us/step - loss: 0.5374 - accuracy: 0.7290\n",
      "Epoch 10/100\n",
      "513/513 [==============================] - 0s 84us/step - loss: 0.5663 - accuracy: 0.7427\n",
      "Epoch 11/100\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.5477 - accuracy: 0.7096\n",
      "Epoch 12/100\n",
      "513/513 [==============================] - 0s 84us/step - loss: 0.5257 - accuracy: 0.7622\n",
      "Epoch 13/100\n",
      "513/513 [==============================] - 0s 83us/step - loss: 0.5256 - accuracy: 0.7466\n",
      "Epoch 14/100\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.5233 - accuracy: 0.7290\n",
      "Epoch 15/100\n",
      "513/513 [==============================] - 0s 84us/step - loss: 0.5334 - accuracy: 0.7544\n",
      "Epoch 16/100\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.5368 - accuracy: 0.7563\n",
      "Epoch 17/100\n",
      "513/513 [==============================] - 0s 75us/step - loss: 0.5186 - accuracy: 0.7719\n",
      "Epoch 18/100\n",
      "513/513 [==============================] - 0s 80us/step - loss: 0.5206 - accuracy: 0.7368\n",
      "Epoch 19/100\n",
      "513/513 [==============================] - 0s 80us/step - loss: 0.5200 - accuracy: 0.7641\n",
      "Epoch 20/100\n",
      "513/513 [==============================] - 0s 87us/step - loss: 0.5108 - accuracy: 0.7466\n",
      "Epoch 21/100\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.5121 - accuracy: 0.7739\n",
      "Epoch 22/100\n",
      "513/513 [==============================] - 0s 101us/step - loss: 0.5099 - accuracy: 0.7680\n",
      "Epoch 23/100\n",
      "513/513 [==============================] - 0s 95us/step - loss: 0.5009 - accuracy: 0.7719\n",
      "Epoch 24/100\n",
      "513/513 [==============================] - 0s 87us/step - loss: 0.5046 - accuracy: 0.7563\n",
      "Epoch 25/100\n",
      "513/513 [==============================] - 0s 83us/step - loss: 0.5053 - accuracy: 0.7505\n",
      "Epoch 26/100\n",
      "513/513 [==============================] - 0s 83us/step - loss: 0.5184 - accuracy: 0.7583\n",
      "Epoch 27/100\n",
      "513/513 [==============================] - 0s 90us/step - loss: 0.4954 - accuracy: 0.7544\n",
      "Epoch 28/100\n",
      "513/513 [==============================] - 0s 96us/step - loss: 0.4936 - accuracy: 0.7524\n",
      "Epoch 29/100\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.5088 - accuracy: 0.7524\n",
      "Epoch 30/100\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.4997 - accuracy: 0.7563\n",
      "Epoch 31/100\n",
      "513/513 [==============================] - 0s 75us/step - loss: 0.4933 - accuracy: 0.7583\n",
      "Epoch 32/100\n",
      "513/513 [==============================] - 0s 75us/step - loss: 0.5365 - accuracy: 0.7310\n",
      "Epoch 33/100\n",
      "513/513 [==============================] - 0s 79us/step - loss: 0.5023 - accuracy: 0.7602\n",
      "Epoch 34/100\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.5050 - accuracy: 0.7505\n",
      "Epoch 35/100\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.4858 - accuracy: 0.7797\n",
      "Epoch 36/100\n",
      "513/513 [==============================] - 0s 75us/step - loss: 0.4856 - accuracy: 0.7739\n",
      "Epoch 37/100\n",
      "513/513 [==============================] - 0s 74us/step - loss: 0.4981 - accuracy: 0.7524\n",
      "Epoch 38/100\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.4825 - accuracy: 0.7602\n",
      "Epoch 39/100\n",
      "513/513 [==============================] - 0s 75us/step - loss: 0.5330 - accuracy: 0.7427\n",
      "Epoch 40/100\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.4975 - accuracy: 0.7700\n",
      "Epoch 41/100\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.4805 - accuracy: 0.7641\n",
      "Epoch 42/100\n",
      "513/513 [==============================] - 0s 78us/step - loss: 0.5322 - accuracy: 0.7407\n",
      "Epoch 43/100\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.4894 - accuracy: 0.7973\n",
      "Epoch 44/100\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.4942 - accuracy: 0.7485\n",
      "Epoch 45/100\n",
      "513/513 [==============================] - 0s 82us/step - loss: 0.4842 - accuracy: 0.7563\n",
      "Epoch 46/100\n",
      "513/513 [==============================] - 0s 80us/step - loss: 0.4781 - accuracy: 0.7739\n",
      "Epoch 47/100\n",
      "513/513 [==============================] - 0s 81us/step - loss: 0.4840 - accuracy: 0.7895\n",
      "Epoch 48/100\n",
      "513/513 [==============================] - 0s 78us/step - loss: 0.5197 - accuracy: 0.7544\n",
      "Epoch 49/100\n",
      "513/513 [==============================] - 0s 81us/step - loss: 0.4922 - accuracy: 0.7817\n",
      "Epoch 50/100\n",
      "513/513 [==============================] - 0s 79us/step - loss: 0.4755 - accuracy: 0.7895\n",
      "Epoch 51/100\n",
      "513/513 [==============================] - 0s 79us/step - loss: 0.4740 - accuracy: 0.7680\n",
      "Epoch 52/100\n",
      "513/513 [==============================] - 0s 81us/step - loss: 0.4749 - accuracy: 0.7641\n",
      "Epoch 53/100\n",
      "513/513 [==============================] - 0s 78us/step - loss: 0.4953 - accuracy: 0.7739\n",
      "Epoch 54/100\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.4853 - accuracy: 0.7934\n",
      "Epoch 55/100\n",
      "513/513 [==============================] - 0s 75us/step - loss: 0.4676 - accuracy: 0.7875\n",
      "Epoch 56/100\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4701 - accuracy: 0.7719\n",
      "Epoch 57/100\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4688 - accuracy: 0.7778\n",
      "Epoch 58/100\n",
      "513/513 [==============================] - 0s 87us/step - loss: 0.4768 - accuracy: 0.7719\n",
      "Epoch 59/100\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.4877 - accuracy: 0.7934\n",
      "Epoch 60/100\n",
      "513/513 [==============================] - 0s 82us/step - loss: 0.4699 - accuracy: 0.8012\n",
      "Epoch 61/100\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4785 - accuracy: 0.7583\n",
      "Epoch 62/100\n",
      "513/513 [==============================] - 0s 91us/step - loss: 0.4602 - accuracy: 0.7973\n",
      "Epoch 63/100\n",
      "513/513 [==============================] - 0s 81us/step - loss: 0.4748 - accuracy: 0.7856\n",
      "Epoch 64/100\n",
      "513/513 [==============================] - 0s 78us/step - loss: 0.4725 - accuracy: 0.7934\n",
      "Epoch 65/100\n",
      "513/513 [==============================] - 0s 82us/step - loss: 0.4830 - accuracy: 0.7505\n",
      "Epoch 66/100\n",
      "513/513 [==============================] - 0s 80us/step - loss: 0.4742 - accuracy: 0.7719\n",
      "Epoch 67/100\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.4584 - accuracy: 0.8012\n",
      "Epoch 68/100\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.4734 - accuracy: 0.7973\n",
      "Epoch 69/100\n",
      "513/513 [==============================] - 0s 79us/step - loss: 0.4667 - accuracy: 0.7992\n",
      "Epoch 70/100\n",
      "513/513 [==============================] - 0s 80us/step - loss: 0.4648 - accuracy: 0.8031\n",
      "Epoch 71/100\n",
      "513/513 [==============================] - 0s 81us/step - loss: 0.4549 - accuracy: 0.7856\n",
      "Epoch 72/100\n",
      "513/513 [==============================] - 0s 86us/step - loss: 0.4668 - accuracy: 0.7661\n",
      "Epoch 73/100\n",
      "513/513 [==============================] - 0s 79us/step - loss: 0.4543 - accuracy: 0.7953\n",
      "Epoch 74/100\n",
      "513/513 [==============================] - 0s 79us/step - loss: 0.4531 - accuracy: 0.7992\n",
      "Epoch 75/100\n",
      "513/513 [==============================] - 0s 81us/step - loss: 0.4561 - accuracy: 0.7797\n",
      "Epoch 76/100\n",
      "513/513 [==============================] - 0s 87us/step - loss: 0.4510 - accuracy: 0.8090\n",
      "Epoch 77/100\n",
      "513/513 [==============================] - 0s 95us/step - loss: 0.4505 - accuracy: 0.7817\n",
      "Epoch 78/100\n",
      "513/513 [==============================] - 0s 97us/step - loss: 0.4678 - accuracy: 0.7719\n",
      "Epoch 79/100\n",
      "513/513 [==============================] - 0s 81us/step - loss: 0.4578 - accuracy: 0.8051\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513/513 [==============================] - 0s 85us/step - loss: 0.4481 - accuracy: 0.8051\n",
      "Epoch 81/100\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.4555 - accuracy: 0.7778\n",
      "Epoch 82/100\n",
      "513/513 [==============================] - 0s 83us/step - loss: 0.4487 - accuracy: 0.8051\n",
      "Epoch 83/100\n",
      "513/513 [==============================] - 0s 81us/step - loss: 0.4658 - accuracy: 0.8090\n",
      "Epoch 84/100\n",
      "513/513 [==============================] - 0s 85us/step - loss: 0.4588 - accuracy: 0.7817\n",
      "Epoch 85/100\n",
      "513/513 [==============================] - 0s 82us/step - loss: 0.4585 - accuracy: 0.7739\n",
      "Epoch 86/100\n",
      "513/513 [==============================] - 0s 79us/step - loss: 0.4891 - accuracy: 0.7719\n",
      "Epoch 87/100\n",
      "513/513 [==============================] - 0s 75us/step - loss: 0.4643 - accuracy: 0.7973\n",
      "Epoch 88/100\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.4408 - accuracy: 0.8031\n",
      "Epoch 89/100\n",
      "513/513 [==============================] - 0s 78us/step - loss: 0.4400 - accuracy: 0.8090\n",
      "Epoch 90/100\n",
      "513/513 [==============================] - 0s 78us/step - loss: 0.4430 - accuracy: 0.8012\n",
      "Epoch 91/100\n",
      "513/513 [==============================] - 0s 80us/step - loss: 0.4556 - accuracy: 0.8051\n",
      "Epoch 92/100\n",
      "513/513 [==============================] - 0s 79us/step - loss: 0.4476 - accuracy: 0.7914\n",
      "Epoch 93/100\n",
      "513/513 [==============================] - 0s 81us/step - loss: 0.4473 - accuracy: 0.8090\n",
      "Epoch 94/100\n",
      "513/513 [==============================] - 0s 80us/step - loss: 0.4701 - accuracy: 0.7914\n",
      "Epoch 95/100\n",
      "513/513 [==============================] - 0s 80us/step - loss: 0.4405 - accuracy: 0.7992\n",
      "Epoch 96/100\n",
      "513/513 [==============================] - 0s 78us/step - loss: 0.4476 - accuracy: 0.7856\n",
      "Epoch 97/100\n",
      "513/513 [==============================] - 0s 77us/step - loss: 0.4356 - accuracy: 0.8168\n",
      "Epoch 98/100\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.4507 - accuracy: 0.8207\n",
      "Epoch 99/100\n",
      "513/513 [==============================] - 0s 78us/step - loss: 0.4405 - accuracy: 0.8012\n",
      "Epoch 100/100\n",
      "513/513 [==============================] - 0s 76us/step - loss: 0.4379 - accuracy: 0.8031\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "epochs = [10, 25, 50, 100]\n",
    "batches = [16, 32, 64, 128]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(epochs=epochs, batch_size=batches, optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.752437 using {'batch_size': 64, 'epochs': 100, 'optimizer': 'Adamax'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 5.2021636 ,  7.46684613,  5.95582743,  8.64542003,  8.56029124,\n",
       "         6.56816416,  9.74208169,  8.42310057, 11.57348404, 11.12729182,\n",
       "        17.79938416, 16.9462141 , 12.46522093, 17.255901  , 16.71501217,\n",
       "        21.63394456, 20.38423309, 27.95739164, 26.08763938, 22.92758164,\n",
       "        29.82075305, 34.97338004, 45.07815275, 43.23775382, 55.66169615,\n",
       "        51.89609666, 43.23025951, 42.82431064,  5.67866254,  8.77549472,\n",
       "         8.93743591, 10.85489421,  9.31100316,  5.63129916,  7.62295227,\n",
       "         5.67463179,  7.66104136,  6.84610858,  9.48351941,  8.96711965,\n",
       "         7.87698112, 11.1190383 ,  9.46409097, 12.01111097, 11.48419876,\n",
       "        15.0754046 , 15.10124159, 12.66982522, 17.91575823, 18.53054519,\n",
       "        21.84955144, 22.34677782, 27.95172658, 27.0053566 , 23.72991576,\n",
       "        22.83535175,  4.89873881,  6.90173645,  6.41060648,  7.83425164,\n",
       "         6.036378  ,  4.8538404 ,  7.13061953,  4.75712166,  5.95515823,\n",
       "         5.34932022,  7.65910578,  7.20702353,  6.36008258,  8.74033623,\n",
       "         6.04735785,  8.25904903,  7.44325757, 10.49038076, 10.08068027,\n",
       "         8.44923639, 12.26113892, 10.23980985, 13.03574929, 13.05275183,\n",
       "        16.80282722, 17.06793084, 14.74080753, 14.74383979,  4.0277843 ,\n",
       "         5.66690993,  5.7533618 ,  5.63357697,  5.56188197,  4.68003941,\n",
       "         6.51753659,  4.25632319,  5.37386875,  5.0554728 ,  6.41589422,\n",
       "         6.26189365,  5.43012257,  7.39880004,  5.37315745,  6.60586057,\n",
       "         6.09446931,  9.20933862,  9.13818207,  9.01151533, 10.72173758,\n",
       "         9.34762197, 12.66848269, 13.32766829, 16.11974554, 13.89890041,\n",
       "        11.82735562,  7.80437164]),\n",
       " 'std_fit_time': array([0.08366972, 0.17054521, 0.4085315 , 0.19519948, 0.13564419,\n",
       "        0.41210925, 0.05897506, 0.36917172, 0.26081595, 0.47104095,\n",
       "        0.32937831, 0.25300234, 1.90569715, 0.35266916, 0.51099163,\n",
       "        0.60226467, 0.21246719, 1.48334059, 0.46261542, 1.49529669,\n",
       "        0.38009913, 0.82233923, 0.39932234, 0.41822089, 1.59485186,\n",
       "        0.44589433, 5.28169642, 0.22186273, 0.57178286, 0.5551055 ,\n",
       "        0.26837517, 0.18210843, 1.03511395, 0.10350429, 0.20166147,\n",
       "        0.10918235, 0.20558451, 0.19261468, 0.12803884, 0.19540846,\n",
       "        0.40093671, 0.14204925, 0.52445283, 0.3872914 , 0.2050295 ,\n",
       "        0.70015757, 0.20550966, 0.66030244, 0.50419926, 0.18149975,\n",
       "        1.10859703, 0.21486225, 0.65312623, 0.4556925 , 1.58540653,\n",
       "        0.96005637, 0.19631323, 0.53353484, 0.18410734, 0.29846642,\n",
       "        0.49800013, 0.10079773, 0.23838375, 0.17608546, 0.17356751,\n",
       "        0.18816921, 0.07213023, 0.09225405, 0.1885312 , 0.19123018,\n",
       "        0.41134396, 0.28069942, 0.05603436, 0.31410772, 0.16205198,\n",
       "        0.64422035, 0.36939317, 0.6290617 , 0.92894086, 0.52782666,\n",
       "        1.04590406, 0.29450468, 0.87399054, 0.19487133, 0.06668286,\n",
       "        0.59959117, 0.12305358, 0.13044841, 0.05843925, 0.19896238,\n",
       "        0.0402328 , 0.05892705, 0.13463962, 0.14835144, 0.10020854,\n",
       "        0.09651933, 0.18352266, 0.16078383, 0.15796766, 0.17638224,\n",
       "        0.102657  , 0.67995409, 0.2849314 , 1.08634132, 0.26021272,\n",
       "        0.4184929 , 2.09977008, 0.52253008, 0.7331903 , 0.19472027,\n",
       "        0.82587586, 0.24564933]),\n",
       " 'mean_score_time': array([1.59178658, 0.66295319, 0.97522893, 0.91445637, 0.75747151,\n",
       "        0.83089843, 0.84887524, 0.95970659, 0.97911124, 0.92454081,\n",
       "        1.37679558, 1.01195779, 1.07491665, 1.12579632, 1.02300839,\n",
       "        1.207972  , 0.96721635, 1.35226173, 1.01054978, 1.31728821,\n",
       "        1.29462061, 1.13746643, 1.33953605, 1.21444817, 1.47122564,\n",
       "        1.16306376, 1.02810631, 0.86073546, 1.14139886, 1.6415575 ,\n",
       "        1.21649652, 1.37559662, 0.845715  , 0.73211522, 0.8677022 ,\n",
       "        0.74444513, 0.82923265, 0.74713879, 0.97860804, 0.82222557,\n",
       "        0.77826815, 0.91319971, 0.98092775, 0.98841205, 0.90047436,\n",
       "        0.92103786, 1.01566281, 0.85586181, 0.99551201, 0.77447162,\n",
       "        1.25394235, 1.08023381, 1.17162538, 1.06015124, 0.98144789,\n",
       "        0.85687795, 0.87510843, 1.18466182, 1.05287495, 0.71888089,\n",
       "        0.70305839, 0.69369221, 0.82523236, 0.79433303, 0.74262619,\n",
       "        0.75405722, 0.82378721, 0.78378987, 0.78350263, 0.7681344 ,\n",
       "        0.79500794, 0.85316644, 0.76897011, 0.83776388, 0.99662976,\n",
       "        0.73687072, 0.8673264 , 0.91522932, 0.93780789, 0.77025456,\n",
       "        0.96415224, 1.09881067, 0.91985326, 0.72271399, 0.77817693,\n",
       "        1.06200414, 0.8908545 , 0.76770887, 0.6901011 , 0.73839331,\n",
       "        0.67035365, 0.74349494, 0.80541587, 0.74233942, 0.799158  ,\n",
       "        0.80899634, 0.67006769, 0.80188036, 0.96599641, 0.87402163,\n",
       "        0.9223938 , 1.10601616, 1.19672537, 1.09549589, 0.89486227,\n",
       "        0.86381259, 1.28880334, 1.2072679 , 0.8179461 , 0.94855437,\n",
       "        0.72883039, 0.44789877]),\n",
       " 'std_score_time': array([0.02215842, 0.04103929, 0.06146623, 0.12537325, 0.07836962,\n",
       "        0.14359278, 0.07861315, 0.18458617, 0.08399264, 0.11427623,\n",
       "        0.26140513, 0.13653436, 0.43386171, 0.29784441, 0.27510744,\n",
       "        0.35134965, 0.17487897, 0.40628105, 0.15765263, 0.31936915,\n",
       "        0.23607077, 0.14996684, 0.15832773, 0.26034654, 0.35112521,\n",
       "        0.33018264, 0.26490041, 0.19480616, 0.13386592, 0.15175686,\n",
       "        0.14916574, 0.12125262, 0.1871167 , 0.06297666, 0.09593347,\n",
       "        0.14311044, 0.04870063, 0.05576186, 0.1678813 , 0.10406488,\n",
       "        0.05859939, 0.16942372, 0.22858492, 0.11150984, 0.08932145,\n",
       "        0.15104349, 0.13139163, 0.19935472, 0.12977715, 0.05539927,\n",
       "        0.21176289, 0.19298009, 0.15289823, 0.11588106, 0.16872793,\n",
       "        0.15823506, 0.14818384, 0.02777994, 0.04062931, 0.07269494,\n",
       "        0.02757454, 0.04312842, 0.09883402, 0.09078998, 0.08255782,\n",
       "        0.09270891, 0.10389752, 0.07133755, 0.07977062, 0.07065487,\n",
       "        0.04548058, 0.08006932, 0.09610588, 0.09721828, 0.15013844,\n",
       "        0.09450564, 0.14331027, 0.12462495, 0.0479863 , 0.12934452,\n",
       "        0.22074431, 0.0906625 , 0.25085654, 0.05979212, 0.07848956,\n",
       "        0.02295137, 0.22839733, 0.01926896, 0.03373707, 0.03834451,\n",
       "        0.05150734, 0.03119434, 0.01038107, 0.09642469, 0.06855588,\n",
       "        0.05569531, 0.08844173, 0.146357  , 0.18031242, 0.07841729,\n",
       "        0.12138481, 0.16981423, 0.12396574, 0.23283655, 0.09804533,\n",
       "        0.175112  , 0.29867274, 0.2407159 , 0.13136411, 0.10693332,\n",
       "        0.34185147, 0.12892265]),\n",
       " 'param_batch_size': masked_array(data=[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "                    128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "                    128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "                    128, 128, 128, 128, 128, 128],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 25, 25,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25,\n",
       "                    25, 25, 25, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 10, 10, 10, 10, 10, 10, 10, 25, 25,\n",
       "                    25, 25, 25, 25, 25, 50, 50, 50, 50, 50, 50, 50, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 25, 25, 25, 25, 25, 25, 25, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_optimizer': masked_array(data=['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam',\n",
       "                    'Adamax', 'Nadam', 'SGD', 'RMSprop', 'Adagrad',\n",
       "                    'Adadelta', 'Adam', 'Adamax', 'Nadam', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax',\n",
       "                    'Nadam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta',\n",
       "                    'Adam', 'Adamax', 'Nadam', 'SGD', 'RMSprop', 'Adagrad',\n",
       "                    'Adadelta', 'Adam', 'Adamax', 'Nadam', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax',\n",
       "                    'Nadam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta',\n",
       "                    'Adam', 'Adamax', 'Nadam', 'SGD', 'RMSprop', 'Adagrad',\n",
       "                    'Adadelta', 'Adam', 'Adamax', 'Nadam', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax',\n",
       "                    'Nadam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta',\n",
       "                    'Adam', 'Adamax', 'Nadam', 'SGD', 'RMSprop', 'Adagrad',\n",
       "                    'Adadelta', 'Adam', 'Adamax', 'Nadam', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax',\n",
       "                    'Nadam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta',\n",
       "                    'Adam', 'Adamax', 'Nadam', 'SGD', 'RMSprop', 'Adagrad',\n",
       "                    'Adadelta', 'Adam', 'Adamax', 'Nadam', 'SGD',\n",
       "                    'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax',\n",
       "                    'Nadam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta',\n",
       "                    'Adam', 'Adamax', 'Nadam'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'batch_size': 16, 'epochs': 10, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 10, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 25, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 50, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 16, 'epochs': 100, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 10, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 25, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 50, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 32, 'epochs': 100, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 10, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 25, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 50, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 64, 'epochs': 100, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 10, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 25, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 50, 'optimizer': 'Nadam'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'SGD'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'RMSprop'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'Adagrad'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'Adadelta'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'Adam'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'Adamax'},\n",
       "  {'batch_size': 128, 'epochs': 100, 'optimizer': 'Nadam'}],\n",
       " 'split0_test_score': array([0.70873785, 0.70873785, 0.74757284, 0.73786408, 0.74757284,\n",
       "        0.75728154, 0.70873785, 0.71844661, 0.69902915, 0.75728154,\n",
       "        0.80582523, 0.7669903 , 0.77669901, 0.73786408, 0.74757284,\n",
       "        0.68932039, 0.74757284, 0.73786408, 0.72815531, 0.77669901,\n",
       "        0.74757284, 0.73786408, 0.49514562, 0.78640777, 0.75728154,\n",
       "        0.75728154, 0.72815531, 0.75728154, 0.69902915, 0.73786408,\n",
       "        0.7669903 , 0.69902915, 0.7669903 , 0.74757284, 0.64077669,\n",
       "        0.71844661, 0.71844661, 0.7669903 , 0.73786408, 0.74757284,\n",
       "        0.78640777, 0.7669903 , 0.75728154, 0.69902915, 0.7669903 ,\n",
       "        0.69902915, 0.75728154, 0.71844661, 0.70873785, 0.74757284,\n",
       "        0.53398061, 0.72815531, 0.74757284, 0.75728154, 0.73786408,\n",
       "        0.75728154, 0.69902915, 0.69902915, 0.73786408, 0.69902915,\n",
       "        0.75728154, 0.7669903 , 0.70873785, 0.69902915, 0.75728154,\n",
       "        0.78640777, 0.74757284, 0.77669901, 0.75728154, 0.69902915,\n",
       "        0.72815531, 0.73786408, 0.67961162, 0.64077669, 0.75728154,\n",
       "        0.77669901, 0.7669903 , 0.74757284, 0.74757284, 0.75728154,\n",
       "        0.68932039, 0.72815531, 0.78640777, 0.75728154, 0.68932039,\n",
       "        0.73786408, 0.70873785, 0.51456308, 0.78640777, 0.7669903 ,\n",
       "        0.74757284, 0.68932039, 0.7669903 , 0.78640777, 0.69902915,\n",
       "        0.75728154, 0.77669901, 0.74757284, 0.69902915, 0.74757284,\n",
       "        0.73786408, 0.71844661, 0.77669901, 0.73786408, 0.78640777,\n",
       "        0.70873785, 0.79611653, 0.74757284, 0.66019416, 0.72815531,\n",
       "        0.7669903 , 0.815534  ]),\n",
       " 'split1_test_score': array([0.71844661, 0.69902915, 0.71844661, 0.71844661, 0.73786408,\n",
       "        0.71844661, 0.71844661, 0.69902915, 0.74757284, 0.71844661,\n",
       "        0.70873785, 0.71844661, 0.73786408, 0.74757284, 0.74757284,\n",
       "        0.74757284, 0.70873785, 0.74757284, 0.69902915, 0.72815531,\n",
       "        0.71844661, 0.72815531, 0.68932039, 0.7669903 , 0.73786408,\n",
       "        0.72815531, 0.75728154, 0.75728154, 0.64077669, 0.68932039,\n",
       "        0.69902915, 0.68932039, 0.69902915, 0.66990292, 0.71844661,\n",
       "        0.70873785, 0.64077669, 0.72815531, 0.69902915, 0.70873785,\n",
       "        0.68932039, 0.70873785, 0.69902915, 0.72815531, 0.71844661,\n",
       "        0.70873785, 0.72815531, 0.7669903 , 0.73786408, 0.72815531,\n",
       "        0.75728154, 0.7669903 , 0.75728154, 0.73786408, 0.74757284,\n",
       "        0.74757284, 0.64077669, 0.69902915, 0.68932039, 0.68932039,\n",
       "        0.70873785, 0.69902915, 0.70873785, 0.68932039, 0.71844661,\n",
       "        0.70873785, 0.70873785, 0.74757284, 0.70873785, 0.69902915,\n",
       "        0.67961162, 0.71844661, 0.70873785, 0.70873785, 0.71844661,\n",
       "        0.71844661, 0.71844661, 0.71844661, 0.73786408, 0.73786408,\n",
       "        0.70873785, 0.74757284, 0.77669901, 0.70873785, 0.64077669,\n",
       "        0.66990292, 0.69902915, 0.70873785, 0.66990292, 0.70873785,\n",
       "        0.67961162, 0.64077669, 0.70873785, 0.70873785, 0.48543689,\n",
       "        0.70873785, 0.68932039, 0.70873785, 0.67961162, 0.71844661,\n",
       "        0.70873785, 0.71844661, 0.72815531, 0.71844661, 0.71844661,\n",
       "        0.71844661, 0.71844661, 0.74757284, 0.53398061, 0.7669903 ,\n",
       "        0.73786408, 0.70873785]),\n",
       " 'split2_test_score': array([0.66990292, 0.66990292, 0.66019416, 0.67961162, 0.74757284,\n",
       "        0.73786408, 0.69902915, 0.67961162, 0.73786408, 0.69902915,\n",
       "        0.69902915, 0.71844661, 0.7669903 , 0.72815531, 0.74757284,\n",
       "        0.7669903 , 0.73786408, 0.75728154, 0.71844661, 0.71844661,\n",
       "        0.69902915, 0.73786408, 0.69902915, 0.74757284, 0.72815531,\n",
       "        0.69902915, 0.71844661, 0.71844661, 0.63106793, 0.62135923,\n",
       "        0.71844661, 0.73786408, 0.71844661, 0.75728154, 0.73786408,\n",
       "        0.63106793, 0.73786408, 0.77669901, 0.7669903 , 0.77669901,\n",
       "        0.7669903 , 0.7669903 , 0.69902915, 0.72815531, 0.73786408,\n",
       "        0.75728154, 0.74757284, 0.74757284, 0.70873785, 0.74757284,\n",
       "        0.74757284, 0.74757284, 0.72815531, 0.68932039, 0.71844661,\n",
       "        0.69902915, 0.63106793, 0.71844661, 0.66990292, 0.68932039,\n",
       "        0.68932039, 0.72815531, 0.69902915, 0.63106793, 0.66990292,\n",
       "        0.66019416, 0.72815531, 0.75728154, 0.74757284, 0.64077669,\n",
       "        0.68932039, 0.69902915, 0.72815531, 0.68932039, 0.75728154,\n",
       "        0.74757284, 0.77669901, 0.72815531, 0.70873785, 0.73786408,\n",
       "        0.65048546, 0.72815531, 0.7669903 , 0.70873785, 0.63106793,\n",
       "        0.69902915, 0.74757284, 0.66019416, 0.74757284, 0.71844661,\n",
       "        0.70873785, 0.64077669, 0.73786408, 0.73786408, 0.66990292,\n",
       "        0.75728154, 0.7669903 , 0.71844661, 0.65048546, 0.72815531,\n",
       "        0.74757284, 0.64077669, 0.77669901, 0.77669901, 0.75728154,\n",
       "        0.69902915, 0.75728154, 0.68932039, 0.54368931, 0.71844661,\n",
       "        0.77669901, 0.75728154]),\n",
       " 'split3_test_score': array([0.70588237, 0.57843137, 0.70588237, 0.71568626, 0.72549021,\n",
       "        0.74509805, 0.7647059 , 0.7647059 , 0.69607842, 0.77450979,\n",
       "        0.75490195, 0.7647059 , 0.74509805, 0.70588237, 0.72549021,\n",
       "        0.74509805, 0.7352941 , 0.70588237, 0.7352941 , 0.7352941 ,\n",
       "        0.7352941 , 0.7647059 , 0.7647059 , 0.7352941 , 0.75490195,\n",
       "        0.74509805, 0.7352941 , 0.72549021, 0.67647058, 0.71568626,\n",
       "        0.71568626, 0.68627453, 0.78431374, 0.75490195, 0.70588237,\n",
       "        0.70588237, 0.75490195, 0.7352941 , 0.75490195, 0.7352941 ,\n",
       "        0.75490195, 0.75490195, 0.74509805, 0.7647059 , 0.78431374,\n",
       "        0.70588237, 0.75490195, 0.7647059 , 0.66666669, 0.7352941 ,\n",
       "        0.75490195, 0.78431374, 0.75490195, 0.77450979, 0.7647059 ,\n",
       "        0.75490195, 0.68627453, 0.64705884, 0.75490195, 0.69607842,\n",
       "        0.77450979, 0.74509805, 0.7352941 , 0.68627453, 0.7647059 ,\n",
       "        0.627451  , 0.69607842, 0.75490195, 0.7352941 , 0.68627453,\n",
       "        0.70588237, 0.71568626, 0.74509805, 0.70588237, 0.7647059 ,\n",
       "        0.77450979, 0.7647059 , 0.74509805, 0.78431374, 0.74509805,\n",
       "        0.7352941 , 0.7647059 , 0.75490195, 0.7352941 , 0.68627453,\n",
       "        0.71568626, 0.72549021, 0.75490195, 0.74509805, 0.70588237,\n",
       "        0.72549021, 0.68627453, 0.78431374, 0.80392158, 0.7647059 ,\n",
       "        0.7647059 , 0.77450979, 0.7647059 , 0.67647058, 0.7647059 ,\n",
       "        0.7647059 , 0.71568626, 0.75490195, 0.7647059 , 0.74509805,\n",
       "        0.72549021, 0.72549021, 0.72549021, 0.71568626, 0.79411763,\n",
       "        0.74509805, 0.72549021]),\n",
       " 'split4_test_score': array([0.67647058, 0.68627453, 0.69607842, 0.71568626, 0.69607842,\n",
       "        0.68627453, 0.65686274, 0.68627453, 0.61764705, 0.66666669,\n",
       "        0.67647058, 0.66666669, 0.66666669, 0.57843137, 0.71568626,\n",
       "        0.68627453, 0.627451  , 0.66666669, 0.65686274, 0.68627453,\n",
       "        0.58823532, 0.67647058, 0.67647058, 0.66666669, 0.65686274,\n",
       "        0.61764705, 0.64705884, 0.65686274, 0.65686274, 0.66666669,\n",
       "        0.70588237, 0.71568626, 0.69607842, 0.70588237, 0.65686274,\n",
       "        0.70588237, 0.63725489, 0.67647058, 0.67647058, 0.63725489,\n",
       "        0.67647058, 0.66666669, 0.70588237, 0.67647058, 0.65686274,\n",
       "        0.61764705, 0.67647058, 0.70588237, 0.67647058, 0.68627453,\n",
       "        0.52941179, 0.69607842, 0.66666669, 0.59803921, 0.66666669,\n",
       "        0.65686274, 0.65686274, 0.67647058, 0.69607842, 0.69607842,\n",
       "        0.66666669, 0.71568626, 0.69607842, 0.66666669, 0.66666669,\n",
       "        0.68627453, 0.67647058, 0.65686274, 0.65686274, 0.627451  ,\n",
       "        0.70588237, 0.69607842, 0.66666669, 0.66666669, 0.68627453,\n",
       "        0.67647058, 0.66666669, 0.7352941 , 0.65686274, 0.67647058,\n",
       "        0.71568626, 0.65686274, 0.67647058, 0.65686274, 0.65686274,\n",
       "        0.67647058, 0.67647058, 0.71568626, 0.70588237, 0.71568626,\n",
       "        0.70588237, 0.65686274, 0.68627453, 0.64705884, 0.67647058,\n",
       "        0.68627453, 0.68627453, 0.67647058, 0.67647058, 0.66666669,\n",
       "        0.66666669, 0.69607842, 0.66666669, 0.65686274, 0.65686274,\n",
       "        0.69607842, 0.63725489, 0.63725489, 0.68627453, 0.66666669,\n",
       "        0.70588237, 0.64705884]),\n",
       " 'mean_test_score': array([0.69590644, 0.66861599, 0.70565303, 0.71345028, 0.73099416,\n",
       "        0.72904484, 0.70955166, 0.70955166, 0.69980507, 0.72319689,\n",
       "        0.72904483, 0.72709553, 0.73879143, 0.69980507, 0.73684212,\n",
       "        0.72709553, 0.71150098, 0.72319689, 0.70760234, 0.72904483,\n",
       "        0.69785576, 0.72904483, 0.66471735, 0.74074075, 0.7270955 ,\n",
       "        0.70955166, 0.71734892, 0.72319688, 0.66081871, 0.68615985,\n",
       "        0.72124757, 0.70565303, 0.73294348, 0.72709552, 0.6920078 ,\n",
       "        0.69395712, 0.69785575, 0.73684209, 0.72709552, 0.72124756,\n",
       "        0.73489278, 0.73294347, 0.72124758, 0.71929824, 0.73294348,\n",
       "        0.69785575, 0.73294346, 0.74074076, 0.69980506, 0.72904484,\n",
       "        0.66471736, 0.74463938, 0.73099415, 0.71150097, 0.72709553,\n",
       "        0.72319688, 0.66276803, 0.68810917, 0.70955165, 0.69395711,\n",
       "        0.71929824, 0.73099415, 0.70955165, 0.67446394, 0.71539962,\n",
       "        0.69395712, 0.71150097, 0.73879142, 0.72124756, 0.67056532,\n",
       "        0.70175438, 0.71345029, 0.70565302, 0.68226121, 0.73684211,\n",
       "        0.73879142, 0.73879143, 0.73489279, 0.72709552, 0.73099415,\n",
       "        0.69980506, 0.72514619, 0.75243664, 0.71345028, 0.66081871,\n",
       "        0.69980507, 0.71150098, 0.67056529, 0.73099417, 0.72319688,\n",
       "        0.7134503 , 0.66276803, 0.73684211, 0.73684211, 0.6588694 ,\n",
       "        0.73489279, 0.73879142, 0.72319689, 0.67641325, 0.72514621,\n",
       "        0.72514621, 0.69785575, 0.74074073, 0.73099415, 0.73294347,\n",
       "        0.70955166, 0.72709552, 0.70955167, 0.62768031, 0.73489279,\n",
       "        0.7465887 , 0.73099416]),\n",
       " 'std_test_score': array([0.01912395, 0.04678028, 0.02861535, 0.01888321, 0.01919023,\n",
       "        0.02476313, 0.03456975, 0.03050685, 0.04575952, 0.03890988,\n",
       "        0.04615023, 0.03683625, 0.03860784, 0.06202226, 0.01356361,\n",
       "        0.03295477, 0.04381216, 0.03302658, 0.0280632 , 0.02915735,\n",
       "        0.05700569, 0.02887602, 0.0902583 , 0.04078373, 0.03661902,\n",
       "        0.04979728, 0.03728598, 0.03670138, 0.02456275, 0.04038252,\n",
       "        0.02395609, 0.01911463, 0.03606635, 0.03416282, 0.0370592 ,\n",
       "        0.03185789, 0.04937507, 0.03523852, 0.03412207, 0.04722148,\n",
       "        0.04375972, 0.03940022, 0.02487932, 0.02981015, 0.04421966,\n",
       "        0.04500071, 0.02994132, 0.02456225, 0.02548486, 0.02257198,\n",
       "        0.10857098, 0.03063384, 0.03364461, 0.06331008, 0.03361256,\n",
       "        0.03930133, 0.02607031, 0.02438569, 0.03168235, 0.00394814,\n",
       "        0.04061246, 0.02351735, 0.01379673, 0.02415387, 0.04153595,\n",
       "        0.05366567, 0.02469325, 0.04193878, 0.03598236, 0.03036718,\n",
       "        0.01661944, 0.01508101, 0.02917717, 0.02560433, 0.02997495,\n",
       "        0.03759   , 0.04122033, 0.01079084, 0.04250709, 0.0280773 ,\n",
       "        0.02875835, 0.03664499, 0.03925625, 0.03355903, 0.02352483,\n",
       "        0.02507754, 0.02401906, 0.08378239, 0.03982443, 0.02241424,\n",
       "        0.02254662, 0.02127335, 0.03602482, 0.05612049, 0.0931464 ,\n",
       "        0.03139014, 0.04173254, 0.03070028, 0.01548302, 0.03321065,\n",
       "        0.03433146, 0.02980336, 0.04101056, 0.0421798 , 0.04376415,\n",
       "        0.01117378, 0.05253383, 0.04186216, 0.07492674, 0.04351096,\n",
       "        0.02471418, 0.05549756]),\n",
       " 'rank_test_score': array([ 92, 104,  79,  65,  27,  33,  73,  72,  83,  50,  36,  38,   8,\n",
       "         84,  12,  38,  68,  49,  78,  37,  88,  35, 106,   5,  45,  75,\n",
       "         61,  54, 110,  98,  56,  79,  21,  42,  96,  94,  91,  16,  44,\n",
       "         58,  20,  23,  55,  59,  22,  89,  25,   4,  86,  34, 105,   3,\n",
       "         30,  69,  38,  53, 107,  97,  76,  95,  59,  29,  77, 101,  62,\n",
       "         93,  69,  11,  57, 102,  82,  64,  81,  99,  14,  10,   7,  17,\n",
       "         43,  30,  87,  48,   1,  66, 109,  85,  67, 103,  26,  52,  63,\n",
       "        107,  13,  14, 111,  19,   9,  50, 100,  46,  46,  90,   6,  30,\n",
       "         24,  73,  41,  71, 112,  18,   2,  28], dtype=int32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77        75\n",
      "           1       0.72      0.43      0.53        54\n",
      "\n",
      "    accuracy                           0.69       129\n",
      "   macro avg       0.70      0.65      0.65       129\n",
      "weighted avg       0.70      0.69      0.67       129\n",
      "\n",
      "[[66  9]\n",
      " [31 23]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/model_1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
